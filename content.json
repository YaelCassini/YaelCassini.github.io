{"meta":{"title":"Unknown Island","subtitle":"Cassini’s Blog","description":"赛博垃圾分离企划","author":"Cassini","url":"https://yaelcassini.github.io","root":"/"},"pages":[{"title":"","date":"2022-06-08T10:10:36.000Z","updated":"2024-01-26T07:53:13.416Z","comments":true,"path":"about/index.html","permalink":"https://yaelcassini.github.io/about/index.html","excerpt":"","text":"教育经历： 本科：浙江大学 数字媒体技术专业 计算机学院 硕士：浙江大学 计算机科学与技术专业 CAD&amp;CG实验室 其他主页及社交媒体账号：Githubhttps://github.com/YaelCassini 知乎https://www.zhihu.com/people/yael-88-59 CSDNhttps://blog.csdn.net/YaelCassini Bilibilihttps://space.bilibili.com/22531714/channel/seriesdetail?sid=1936988 小红书https://www.xiaohongshu.com/user/profile/60c9c44b000000000100b675?xhsshare=WeixinSession&appuid=60c9c44b000000000100b675&apptime=1695266999"},{"title":"所有分类","date":"2022-06-08T10:09:42.000Z","updated":"2023-09-06T10:09:53.440Z","comments":true,"path":"categories/index.html","permalink":"https://yaelcassini.github.io/categories/index.html","excerpt":"","text":""},{"title":"或许友链","date":"2022-06-08T10:11:00.000Z","updated":"2023-09-06T10:09:53.463Z","comments":true,"path":"friends/index.html","permalink":"https://yaelcassini.github.io/friends/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2022-06-08T10:10:12.000Z","updated":"2023-09-06T10:09:53.463Z","comments":true,"path":"tags/index.html","permalink":"https://yaelcassini.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"GaussianShader Environment","slug":"GaussianShader-Environment","date":"2024-03-18T14:29:03.000Z","updated":"2024-03-18T15:43:00.118Z","comments":true,"path":"2024/03/18/GaussianShader-Environment/","link":"","permalink":"https://yaelcassini.github.io/2024/03/18/GaussianShader-Environment/","excerpt":"","text":"最近由于科研需求，在学习3D Gaussian Splatting相关的内容，并有尝试跑源码，本来是在Windows系统下跑了Gaussian Splatting的源码，后续想跑Gaussian Shader的时候，发现依赖里很多包都是只有linux有的，原文作者的环境应该是在Linux下的，因此在自己的设备上装了Linux双系统，在实践的过程中遇到了诸多问题，故在此记录，望能帮助有缘人。（感谢我的同门唐同学对我的指导的帮助。） 3D Gaussian Splatting环境配置过程（Windows下）3D Gaussian Splatting的环境非常好配置，因为所需的依赖非常少且干净，只需要照着下面提供的参考资料视频逐步操作即可。我的电脑配置是：RTX 4090 + CUDA 11.8，environment.yml中给定的环境是py3.7 + pytorch1.12.0-cuda11.6，一开始其实cuda版本没有对应，但是跑代码本身没有问题，GPU调用也非常正常，CUDA toolkit应该是在编译时才会使用。后来重新装了一遍cuda11.6，对于cudnn库，我看到conda环境中的pytorch是： py3.7_cuda11.6_cudnn8_0，因此其对应的cudnn应该是8.0，但是官网的cudnn只有8.2.0及以上有对应cuda11.6的版本，因此我安装的是cudnn8.6.0。 3D GS Source Code: https://github.com/graphdeco-inria/gaussian-splatting Windows环境配置参考资料: https://www.youtube.com/watch?v=UXtuigy_wYc https://github.com/jonstephens85/gaussian-splatting-Windows 从数据处理到训练，查看结果的过程中用到的指令集： ffmpeg -i .&#x2F;David.mov -qscale:v 1 -qmin 1 -vf fps&#x3D;10 %04d.jpg python convert.py -s C:\\LPY\\GassianSplatting\\dataset_self\\David01 python train.py -s C:\\LPY\\GassianSplatting\\dataset_self\\DavidWide01 SIBR_gaussianViewer_app.exe -m C:\\LPY\\GassianSplatting\\gaussian-splatting\\output\\120f6889-4 Gaussian Shader环境配置，及Ubuntu+windows双系统诸多排雷记录这部分光前前后后各种卸载重装解决问题就消耗了我四天的时间，期间多次情绪崩溃，好在最后终于得以解决。 部分submodule及其安装GaussianShader的原作者似乎没有清理环境文件，感觉是linux下直接导出的，因此不确定有一些依赖是否没有用到，这部分时间原因不再深究，但是该项目用到了一些其他的项目，而这些是无法直接用conda安装找到的，包括： diff-gaussian-rasterization simple-knn nvdiffrast cutlass其中，前两个在clone仓库时就会作为submodule下载下来，只需要cd到其路径下，“pip install .”即可。nvdiffrast和cutlass需要自己去github上找到并下载，再使用“pip install .”安装。另外，cutlass我没有找到依赖中显示的0.0.1版本，最早的只找到了0.1.0。WSL尝试试图跑GaussianShader的时候发现它的代码是在Linux环境下的，有些包只有在linux下才有。一开始使用了WSL（Windows下的Linux，后来我觉得非常坑弃用了），但是发现在使用pip安装diff-gaussian-rasterization的时候会报错，具体错误为：（这里忘记记录了，但总之报错的大概含义是找不到CUDA）但是该报错中的环境变量路径是正确的CUDA路径，检查后发现“nvcc -V”也无法访问到cuda，尝试在~&#x2F;.bashrc中添加了环境变量，仍然没有解决问题，因此我考虑到有可能是cuda是安装的windows版本有关系，我上官网进行了查询，发现WSL有一个单独的CUDA版本。因此我换用了WSL专用的CUDA，这次nvcc -V可以正常访问，但是diff-gaussian-rasterization仍然不能安装。这个我感觉应该是wsl自己的锅了，后续请教了一下我的同门，最后得出的结论是，WSL下的CUDA有一些文件与linux版本放的位置不同，导致程序在链接的时候找不到这些文件，不能跑通，通过一个修改可以使得程度跑通： 但是这个发现也令我两天之后终于痛定思痛地放弃了WSL，这玩意太弱智了。。。。 投身Windows+Ubuntu双系统的怀抱 关于Ubuntu镜像文件制作，这里就是找了网上常见的教程，但是有一个很坑的点，不知道为什么我的balenaEtcher烧了几百遍就是每次烧Ubuntu20.04都失败，但是烧Ubuntu22.04就能成功，后来我换用了rufus制作镜像系统安装盘。 在装Ubuntu的时候首先的考虑是：不能用Ubuntu22.04，因为一开始看到GaussianShader里面的依赖对应cuda版本是11.1，但是CUDA toolkit 11.1没有Ubuntu22对应版本。坑的要死，谁懂那种好不容易装好了Ubuntu之后发现没有对应cuda版本的死亡感觉。 试图换用Ubuntu20.04，发现cuda11.1版本太低，在4090上会有问题（真的呕吐了），因此我直接cuda11.1限制了，把依赖里面的pytorch全部注释掉，回头自己装。 然后我试图用回Ubuntu22.04，配置过程如下： 先装Ubuntu虚拟机。 Ubuntu22.04 检查nvidia-smi，能调用到显卡。 装Clash梯子。 装anaconda。 装git git clone 下载example data并放在对的位置 把环境里面的子模块以及cutlass还有pytorch（由于cuda11.1在4090上有bug）注释掉，然后conda env create 安装cuda toolkit 11.8，报错，出现的问题：https://forums.developer.nvidia.com/t/cant-install-cuda-11-8-on-ubuntu-22-04-lts/263227 尝试重装nvidia-driver，无果，根本看不懂报错，是我太菜了。 最终因为一些稳定性的考虑，还是使用了Ubuntu20.04版本。配置过程如下： 换用Ubuntu 20.04 Desktop。 安装的时候没有让ubuntu安装显卡驱动。安装的时候选择与Windows并存。这里也导致我重装了一两次Ubuntu，因为之前按照网上的教程单独分区，总有些区用着用着就报low disk space，但是这样直接选共存，会所有的都在同一个连续的储存中，不会出现某一部分空间不足。 直接安装cuda11.8，会自动安装520版本的显卡驱动 nvidia-smi可以访问，nvcc -V需要自己配置环境变量- anaconda用最新版不行，无论如何配置环境变量都找不到conda，最后用的是2023.03 clash最新版1.3.8不行，直接就是一个安好了打不开，死活打不开。最后用的是clash1.3.6。 安装ibus中文输入法，不行，找不到拼音输入，重启解决问题 重启的时候发现ubuntu不能重启，解决方案如https://www.cnblogs.com/masbay/p/10718514.html conda环境安装时，pip那些包装不上 每次都。。。进行一个断网，conda的都装上了，因此把pip安装的依赖复制出来做成txt，使用pip install -r requirements.txt命令单独安装。后来发现就是因为open3D和scipy太大了，老是会响应时间太长然后直接中断了然后断网。 关于挂梯子代理的问题，请教了同门之后发现控制台和GUI是两个分开的代理，如果只用GUI的clash开启代理，控制台是访问不到的，因此最后使用了。 设置了pip install some-package –default-timeout&#x3D;100，增大pip的响应时间，最终终于把open3d下载下来了。 注意有一个问题是，这几个submodule的安装似乎是依赖于pytorch版本的，总之每次换了pytorch版本都要uninstall再install重新来一次。","categories":[],"tags":[]},{"title":"","slug":"Gaussian-Splatting-Notes","date":"2024-02-26T06:08:09.557Z","updated":"2024-02-27T07:18:55.439Z","comments":true,"path":"2024/02/26/Gaussian-Splatting-Notes/","link":"","permalink":"https://yaelcassini.github.io/2024/02/26/Gaussian-Splatting-Notes/","excerpt":"","text":"Source Code: https://github.com/graphdeco-inria/gaussian-splatting 需要展开的名词： Structure-from-Motion (SfM) [Snavely et al. 2006] Subsequent multi-view stereo (MVS) [Goesele et al. 2007] Pulsar [Lassner and Zollhofer 2021] achieves fast sphere rasterization which inspired our tile-based and sorting renderer.","categories":[],"tags":[]},{"title":"Blender4.0升级中遇到的Principled BSDF效果不对应问题","slug":"Blender4-Principled-BSDF-Upgrade","date":"2024-01-24T13:20:22.000Z","updated":"2024-02-26T06:06:38.632Z","comments":true,"path":"2024/01/24/Blender4-Principled-BSDF-Upgrade/","link":"","permalink":"https://yaelcassini.github.io/2024/01/24/Blender4-Principled-BSDF-Upgrade/","excerpt":"项目升级Blender4.0后发现Principled BSDF整个重构了，改动非常大，虽然使用Blender4.0打开之前版本的Blender文件时，会有一个自动转换的过程，但是该过程并没有完全达到相同的效果，因此对改动前后的Principled bsdf做了学习和研究，以期望达到之前做的资产在4.0中也可以经过转换后实现和之前差不多的效果的需求。","text":"项目升级Blender4.0后发现Principled BSDF整个重构了，改动非常大，虽然使用Blender4.0打开之前版本的Blender文件时，会有一个自动转换的过程，但是该过程并没有完全达到相同的效果，因此对改动前后的Principled bsdf做了学习和研究，以期望达到之前做的资产在4.0中也可以经过转换后实现和之前差不多的效果的需求。 学习资料过程中阅读了很多相关资料，又学了一遍Disney Principled BSDF，学习的相关资料如下： https://zhuanlan.zhihu.com/p/60977923，毛星云老师在我学习的路上真的称得上先生千古。 https://zhuanlan.zhihu.com/p/57771965 https://wiki.blender.org/wiki/Reference/Release_Notes/4.0/Shading https://docs.blender.org/manual/zh-hans/3.6/render/shader_nodes/shader/principled.html https://docs.blender.org/manual/en/4.0/render/shader_nodes/shader/principled.html Blender打开旧资产自动转换对应关系我用我们项目中的工程文件进行了测试，用Blender4.0打开Blender3.6的文件（Blender会进行一些自动转换），得到的Principled BSDF前后的参数对应关系如下表： 参数区别总结 3.6 Base Color 和Subsurface两个颜色输入，Subsurface是浮点数输入。4.0 只有一个Base Color，自动添加了Mix Color节点，混合之前的两个输入作为Base Color的输入，该节点混合的Factor为原来的Subsurface输入（Clamp Factor）。 Roughness和Normal连接不变。 3.6的Subsurface除了作为mix factor还会连接在4.0的Subsurface模块的Scale输入上。 3.6的Specular输入在4.0连接在Specular模块的IOR Level上。 3.6Sheen的值到4.0会有变化。 查看官方Release Notes和OSL Shader后发现的一些区别 3.6的bssrdf传入的参数直接是Roughness，4.0传入的是r2&#x3D; Roughness*Roughness。 Blender3.6中的Specular会参与到IOR的计算中，显式的IOR调节几乎没有效果，而Blender4.0中自动转换链接的IOR Level是一个线性放缩高光的接口。 Blender3.6的Coat和Sheen图层几乎没有作用效果，但是Blender4.0重构了BSDF的分层设计，这两种效果现在也都比较明显。 解决方案 如果要和之前的效果尽量对齐，可以尝试手动把Sheen和Coat值调为0。 高光方面，如果要物理意义对齐，应该要手动通过Speuclar值计算IOR并连接到4.0的IOR节点，然后将IOR Level置为0.5，经过测试，这样手动转换之后确实会让效果变好，但是由于3.6到4.0的跨越本来就比较大，修改后也无法实现完全对齐，且效果差别不大。转换公式： $ IOR &#x3D; \\frac{2}{1-\\sqrt{0.08*Specular}}-1 $。这里有一个0.08的系数是因为Blender3.6中就是把f0进行了这样的一个映射。 Blender4.0传入的Roughness参数是经过平方计算后的，而Blender3.6传入的则是原始Roughness，但是经过测试后，发现该值对Roughness的影响并不大，考虑到Blender4.0的release notes里面写设计更偏向于基于物理的真实，因此我觉得这个参数也不需要手动修改。 这次主要学习到和梳理清楚的新知识有： BRDF材质图像切片的空间原理（Slice Space） 接触到掠射逆反射的概念 Metallic这个参数是用来控制材质的金属度的，它的原理是对金属材质和非金属材质两种不同的计算方式得到的结果以该值为权重进行线性插值。 PBR在工业界有两种工作流程，在金属&#x2F;粗糙度工作流程中，只有一张BaseColor贴图，里面同时包含了电介质的漫反射颜色和金属的F0两种数据，而Metallic贴图相当于一张Mask，控制了哪些地方把它当成金属，哪些地方当成电介质计算。 Blender3.6中可以显式地控制Specular值，原理为“介电镜面反射量。指定面向（沿法线） 反射率在最常见的 0 - 8% 范围内。”，bsdf计算中通过该值计算得到ior。Blender4.0中取消了原来的Specular接口，而更物理地直接使用IOR控制，因此我在材质节点中手动增加节点组从原来的F0值计算得到ior。 Blender4.0对Principled BSDF进行了重新的分层建模，不同层之间有并列关系也有覆盖关系：","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Blender","slug":"Blender","permalink":"https://yaelcassini.github.io/tags/Blender/"},{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"BSDF","slug":"BSDF","permalink":"https://yaelcassini.github.io/tags/BSDF/"}]},{"title":"OpenGL学习笔记 & OpenGL项目代码整理","slug":"OpenGL-Learning-Notes","date":"2024-01-19T09:26:22.000Z","updated":"2024-01-26T07:36:16.820Z","comments":true,"path":"2024/01/19/OpenGL-Learning-Notes/","link":"","permalink":"https://yaelcassini.github.io/2024/01/19/OpenGL-Learning-Notes/","excerpt":"本篇记录一些OpenGL的学习笔记以及相关代码。","text":"本篇记录一些OpenGL的学习笔记以及相关代码。 在大学学习中接触到OpenGL的课程主要有两个：大二上的计算机图形学和大四上的基于GPU的绘制。在学习过程我发现本人边学边忘，不断需要反刍，特此记录。后面也有计划做一个基于OpenGL的简单的自己的渲染器，但这目前只是一个遥遥无期的flag。 基于GPU的绘制课程作业： codehttps://github.com/YaelCassini/GPUrendering_HW videohttps://www.bilibili.com/video/BV1uu411n7y7/ 基于GPU的绘制课程大程： codehttps://github.com/YaelCassini/Cloth_Real-Time-Rendering.git videohttps://www.bilibili.com/video/BV175411o7t1/ 计算机图形学课程作业： codehttps://github.com/YaelCassini/CG_HW videohttps://www.bilibili.com/video/BV17m4y1Z7JB/ OpenGL常用库 对于顶点着色器，输入有三类：1.uniform参数，此类参数在一次绘制中，所有顶点着色器的实例都相同，且为application传入引擎数据。2.attribute参数，此类参数不同顶点着色器的实例不同，单同一顶点着色器在不同绘制中都相同，且为application传入引擎数据。3.build－in参数，此类参数为opengl内建参数，可以看成是opengl的绘制上下文信息。顶点着色器的输出有两类：1.build－in参数，顶点着色器通过这些内建参数与控制后续计算框架的计算。2.varying参数，顶点着色器通过这些参数把数据传递给片段着色器。 对于片段着色器，输入有两类：1.build－in参数，此类参数为opengl内建参数，可以看成是opengl的绘制上下文信息。2.varying参数，顶点着色器通过这些参数把数据传递给片段着色器。输出只有一类：1.build－in参数，片段着色器通过这些内建参数与控制后续计算框架的计算。","categories":[],"tags":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/tags/Computer-Graphics/"}]},{"title":"PBRT-Notes","slug":"PBRT-Notes","date":"2024-01-11T09:03:50.000Z","updated":"2024-01-11T09:04:08.487Z","comments":true,"path":"2024/01/11/PBRT-Notes/","link":"","permalink":"https://yaelcassini.github.io/2024/01/11/PBRT-Notes/","excerpt":"","text":"Rendering is the process of producing an image from the description of a 3D scene.好精准的描述","categories":[],"tags":[]},{"title":"View Transformation","slug":"View-Transformation","date":"2024-01-05T12:28:32.000Z","updated":"2024-01-18T07:50:37.784Z","comments":true,"path":"2024/01/05/View-Transformation/","link":"","permalink":"https://yaelcassini.github.io/2024/01/05/View-Transformation/","excerpt":"","text":"Blender中相机平移旋转参数和相机变化矩阵的相互转换计算首先在讨论旋转矩阵的时候一定先区分手系，左手系和右手系的旋转矩阵是不一样的，常见的软件和框架使用的手系及默认朝上的坐标轴区别如下图（图源网络）： 渲染中的坐标变换： https://blog.csdn.net/sinat_34870723/article/details/113925012 https://zhuanlan.zhihu.com/p/115395322 绕坐标轴旋转罗德里格斯角旋转公式Look-Up Transformation法线的变换","categories":[],"tags":[]},{"title":"自制网站LOGO","slug":"Website-Logo","date":"2024-01-05T07:55:31.000Z","updated":"2024-01-05T09:25:58.464Z","comments":true,"path":"2024/01/05/Website-Logo/","link":"","permalink":"https://yaelcassini.github.io/2024/01/05/Website-Logo/","excerpt":"闲来无事，网上找了个参考图使用Adobe Illustrator重新制作了网站的LOGO，特此记录。","text":"闲来无事，网上找了个参考图使用Adobe Illustrator重新制作了网站的LOGO，特此记录。 参考图： 打开Illustrator，用基本图形描出轮廓线： 用形状生成器得到需要的边缘，删除不需要的区域： 制作圆角，清楚重复的线条： 上色： 填上眼睛： 完工！","categories":[],"tags":[]},{"title":"Github+Hexo+Volantis个人主页个性化搭建（进阶版）","slug":"Website-Building-Tutotrials-Futher","date":"2024-01-03T08:07:29.000Z","updated":"2024-01-05T07:43:09.783Z","comments":true,"path":"2024/01/03/Website-Building-Tutotrials-Futher/","link":"","permalink":"https://yaelcassini.github.io/2024/01/03/Website-Building-Tutotrials-Futher/","excerpt":"本篇文章为在第一篇搭建了基础的个人主页基础上，对主页进行个性化的修改和信息填充的过程记录。","text":"本篇文章为在第一篇搭建了基础的个人主页基础上，对主页进行个性化的修改和信息填充的过程记录。 参考教程： Volantis主题配置(转载)https://yaelcassini.github.io/2022/06/15/Volantis-Configuration/ 前置教程： Github+Hexo+Volantis个人主页搭建流程https://yaelcassini.github.io/2022/06/08/Website-Building-Tutorials/ 制作网站icon可以在网上找一个自己喜欢的图案，最好简单一点，我用的是一个小狐狸头，然后可以直接搜索在线转换，把jpg或者png格式的图片转化成ico格式，就可以作为网站的icon了，也是先上传到图床，然后用链接调用。 制作自己的个人头像可以在网上找一张图片，上传到图床，后面会作为在主页的个人头像出现在侧边栏。 配置个人主页Title 我给自己的主页起名叫不知岛，英文Unknown Island。 配置_config.yml，这部分代码包括title、subtitle、description、author、favicon的配置。1234567891011121314# Sitetitle: Unknown Islandsubtitle: &#x27;Cassini’s Blog&#x27;description: &#x27;赛博垃圾分离企划&#x27;keywords:author: Cassinilanguage: - zh-CN - en - zh-HK - zh-TWtimezone: &#x27;&#x27;# 网站图标，更多尺寸等图标请使用import方式批量导入favicon: https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/blog/logo_64.ico 配置主页封面在_config.volantis.yml文件中，这部分配置主要修改了title、subtitle以及features，features中是首页封面的跳转栏及其地址、icon配置。 12345678910111213141516171819202122232425262728293031323334353637383940414243############################### Cover ############################### &gt; startcover: height_scheme: full # full, half layout_scheme: dock # blank (留白), search (搜索), dock (坞), featured (精选), focus (焦点) display: home: true archive: true others: true # can be written in front-matter &#x27;cover: true&#x27; background: # https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/blog/liuyao.jpg logo: # https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/blog/logo_128_2.png title: &#x27;Unknown Island&#x27; subtitle: &#x27;Cassini’s Blog&#x27; search: A Wonderful Theme for Hexo # search bar placeholder features: - name: 主页 icon: # img: https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0.0/assets/svg/1f3d5.svg # https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0.2/assets/svg/1f3d8.svg # https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f389.svg url: / - name: 分类 icon: # img: https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0.2/assets/svg/1f4c2.svg # https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f516.svg url: categories/ - name: 标签 icon: # img: https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f516.svg # volantis-static/media/twemoji/assets/svg/1f516.svg url: tags/ - name: 归档 icon: # img: https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f5c3.svg # volantis-static/media/twemoji/assets/svg/1f5c3.svg url: /archives/ - name: 友链 icon: # img: https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0.0/assets/svg/1f37b.svg # https://cdn.jsdelivr.net/gh/twitter/twemoji@14.0.2/assets/svg/1faf1-1f3fc-200d-1faf2-1f3fe.svg # https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f389.svg url: friends/ - name: 关于 icon: # img: https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0.2/assets/svg/2139.svg # https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f5c3.svg url: about/ # - name: 源码 # icon: # # img: volantis-static/media/twemoji/assets/svg/1f9ec.svg # https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f9ec.svg # url: https://github.com/YaelCassini/YaelCassini.github.io############################### Cover ############################### &gt; end 配置侧边栏在_config.volantis.yml文件中，配置包括： position：侧边栏出现在页面左边还是右边 for_page：打开网页固有页面时（比如主页，关于页面）侧边栏显示类别，此处设置为显示博主卡片、分类卡片、标签卡片。 for_post：打开文章页面时侧边栏显示类别，此处设置为显示博主卡片、分类卡片、标签卡片。 avatar：侧边栏博主卡片的头像 social：侧边栏博主卡片下方的链接（邮箱、github等）1234567891011121314151617181920212223242526272829############################### Sidebar ############################### &gt; startsidebar: position: left # left right # 主页、分类、归档等独立页面 for_page: [blogger, category, tagcloud] # layout: docs/post 这类文章页面 for_post: [blogger, toc] # 侧边栏组件库 widget_library: # --------------------------------------- # blogger info widget blogger: class: blogger display: [desktop, mobile] # [desktop, mobile] avatar: https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/blog/avatar_1024.jpg shape: rectangle # circle, rectangle url: about/ title: Yael Cassini subtitle: jinrishici: true # Poetry Today. You can set a string, and it will be displayed when loading fails. social: - icon: fa-solid fa-home url: / - icon: fa-solid fa-envelope url: mailto:3247365200@qq.com - icon: fab fa-github url: https://github.com/YaelCassini - icon: fa-solid fa-headphones-alt url: / 配置Navbarnavbar是网页顶部的跳转栏，这里的配置主要有logo和menu，menu包括name、icon、url的配置，分别是显示文字，icon图标，和跳转链接。 12345678910111213141516171819202122232425262728navbar: visiable: auto # always, auto logo: # choose [img] or [icon + title] img: https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/blog/logo_128.png # icon: https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/blog/logo_256.ico # title: &#x27;Unknown Island&#x27; menu: - name: 主页 icon: fa-solid fa-home url: / - name: 分类 icon: fa-solid fa-folder-open url: categories/ - name: 标签 icon: fa-solid fa-tags url: tags/ - name: 归档 icon: fa-solid fa-archive url: archives/ - name: 友链 icon: fa-solid fa-users url: friends/ - name: 关于 icon: fa-solid fa-info-circle url: about/ - name: 暗黑模式 icon: fa-solid fa-moon toggle: darkmode 配置网站轮播背景提前找好喜欢的背景图片上传到图床，在_config.volantis.yml文件中的parallax标签把enable设置为true，配置images链接，duration表示轮播间隔，这里我也忘记为什么使用webp格式以及png格式行不行了。 123456789101112# 视差滚动效果 Slide Backgroundparallax: enable: true position: fixed # cover: sticky on the cover. fixed: Fixed as background for the site. shuffle: true # shuffle playlist duration: 10000 # Duration (ms) fade: 1500 # fade duration (ms) (Not more than 1500) images: # For personal use only. At your own risk if used for commercial purposes !!! - https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/blog/background/001.webp - https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/blog/background/002.webp - https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/blog/background/003.webp - ··· 配置网站歌单1. 创建歌单在网易云或者qq音乐新建歌单，并在歌单的分享链接中摘取歌单的id编号，比如本站使用的是qq音乐，歌单编号为：8849727324。 2. 配置到volantis在_config.volantis.yml文件中的aplayer标签下配置，以本站为例，需要： 把enable的值修改为true(这里我不记得默认是true还是false了) 把server的值修改为tencent 把type的值修改为playlist 把id修改为8849727324 但是该方法有一个问题是不能加入vip权限的音乐，并且由于图床是部署在github上面的，有时候需要外网访问，但是歌单都是内网，有时候会出现网络代理问题。 后面该歌单还是出现了问题，一直无法播放，报错信息为：”An auido error has occurred,player will skip forward in 2 seconds.”。最后无奈跟随一篇博客把原来的qq音乐歌单换成了网易云音乐歌单。 配置关于页面这部分我没有做很多设计，只简单写了一下自己的教育经历，放了一些其他平台的账号链接，不过每个平台的icon需要自己提前找好。链接格式为： 1&#123;% link Github::https://github.com/YaelCassini::https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/icon/github_rgba.png %&#125; Github为链接标题 后面跟跳转链接 链接后::再跟icon链接。","categories":[{"name":"Front-end","slug":"Front-end","permalink":"https://yaelcassini.github.io/categories/Front-end/"}],"tags":[{"name":"Github Pages","slug":"Github-Pages","permalink":"https://yaelcassini.github.io/tags/Github-Pages/"},{"name":"Hexo","slug":"Hexo","permalink":"https://yaelcassini.github.io/tags/Hexo/"},{"name":"Volantis","slug":"Volantis","permalink":"https://yaelcassini.github.io/tags/Volantis/"}]},{"title":"ToDo Lists","slug":"To-Do-Lists","date":"2024-01-03T07:57:52.000Z","updated":"2024-01-19T12:24:00.118Z","comments":true,"path":"2024/01/03/To-Do-Lists/","link":"","permalink":"https://yaelcassini.github.io/2024/01/03/To-Do-Lists/","excerpt":"这里放一些关于网站的todo-lists。","text":"这里放一些关于网站的todo-lists。 音乐播放一直不行，应该是github的网络问题。 个人主页添加知乎、bilibili、小红书跳转链接。 将个人主页设置的步骤包括头像和2.中的操作更新到个人主页搭建流程。 能不能找到在网页添加语言切换的方法。 自己搭一个场景，包括模型摆放，打光等，漫游录屏。 人物建模及打光 Nerf 去年的腾讯远程项目","categories":[],"tags":[]},{"title":"Useful Links","slug":"Useful-Links","date":"2024-01-03T07:50:24.000Z","updated":"2024-01-24T09:47:30.406Z","comments":true,"path":"2024/01/03/Useful-Links/","link":"","permalink":"https://yaelcassini.github.io/2024/01/03/Useful-Links/","excerpt":"","text":"Icon网站 https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0.0/assets/svg/ https://unpkg.com/browse/volantis-static@0.0.1649552113628/media/org.volantis/icon/1322024-social-media/ https://fontawesome.com/icons?d=gallery https://seeklogo.com/ 配色网站 https://mhg-lab.github.io/pages/color/ https://mycolor.space/ Jorge Jimenez主页 http://www.iryoku.com/ PBRT: https://pbrt.org/ https://www.pbr-book.org/3ed-2018/contents https://github.com/BachiLi/lajolla_public https://github.com/462cmu https://github.com/wjakob/nori https://github.com/HW140701/Book-list-of-computational-geometry-and-computer-graphics Chat GPT: https://zhuanlan.zhihu.com/p/666598196 https://www.gptapi.us/panel/topup https://www.gptacg.com/ Deep L(Pro) API: https://deepl-pro.com/#/translate?referral_code=OXmOi9yscE Zotero 安装 translate 插件可实现划词翻译","categories":[],"tags":[]},{"title":"环境光照相关知识","slug":"Environment-Lighting","date":"2023-12-21T12:07:01.000Z","updated":"2024-01-05T09:23:45.542Z","comments":true,"path":"2023/12/21/Environment-Lighting/","link":"","permalink":"https://yaelcassini.github.io/2023/12/21/Environment-Lighting/","excerpt":"","text":"Cube MapsSpherical MapsEquirectangular Maps Equirectangular Projection(ERP)： https://blog.csdn.net/lin453701006/article/details/71173090","categories":[],"tags":[]},{"title":"凹凸映射以及粗糙度贴图","slug":"Bump-Mapping-Roughness","date":"2023-11-15T12:02:23.000Z","updated":"2024-01-08T13:31:30.155Z","comments":true,"path":"2023/11/15/Bump-Mapping-Roughness/","link":"","permalink":"https://yaelcassini.github.io/2023/11/15/Bump-Mapping-Roughness/","excerpt":"本文摘自笔者的本科毕业论文，是在学习研究过程中一些对凹凸映射以及粗糙度贴图的知识的整理及个人理解。","text":"本文摘自笔者的本科毕业论文，是在学习研究过程中一些对凹凸映射以及粗糙度贴图的知识的整理及个人理解。 凹凸映射及切向空间凹凸映射（Bump Mapping）是一种通过对纹理贴图采样，扰动模型法线，从而表现出更多像素级别材质细节的技术。在渲染管线中计算片元着色时，三角形面片内部的法线最早是直接通过三个顶点的法线插值得到的。这样的方式保证了模型的平滑，但直接使用插值结果将使得我们无法表达出三角形面片内部的像素级凹凸细节，因此凹凸映射技术应运而生。凹凸映射最早使用的是高度图（Height Map），即通过采样高度图，修改片元的在模型表面的高度，因此模型表面的法线也会改变，从而影响着色，如下图。 目前行业中广泛使用的基于法线贴图（Normal Map）的Normal Mapping则是基于法线贴图的。法线贴图储存的是模型在切向空间（Tangent Space）的法线信息。切向空间（也可以称为TBN坐标系）是用来解决模型旋转或缩放造成的法线错误问题的。如果法线贴图中储存的是世界坐标下的法线，则模型的旋转和缩放等操作都会导致法线贴图错误，而切向空间可以保证法线不受模型这些变换干扰。切向空间中的Z轴取自顶点法线插值后得到的法线方向。另外两个轴则分别是模型切面上的切线方向（Tangent）和副切线方向（Bitangent），其中切线方向是模型的UV坐标中U分量增长的方向，而副切线方向则是V分量增长的方向。而法线贴图储存的数据就是该处法线相对于从顶点法线插值得到的法线的偏移量（在切向空间下），向量&lt;0,0,1&gt;代表直接使用插值得到的法线而不进行修改。 使用高度贴图提取法线的算法实现Normal Map其实就是高度场的归一化梯度，因此我们可以使用Lengyel在《Mathematics for 3D Game Programming and Computer Graphics》中提到的思路：通过求解高度图梯度，在切空间构造S向量和T向量，并将其叉乘来得到法线。当沿着U和V方向高度差都为零时，模型没有高度变化，此时法线为Normal(i,j)&#x3D; &lt;0,0,1&gt;，直接使用插值得到的法线而不对其进行修改。否则，法线就会朝U或者V方向偏移。设H(i,j)为高度图上(i,j)处像素的高度值，则S和T向量可以表示为：$$ S(i,j)&#x3D; &lt;1,0,aH(i+1,j)-aH(i-1,j)&gt; $$$$ T(i,j)&#x3D; &lt;0,1,aH(i,j+1)-aH(i,j-1)&gt; $$ 其中，a是一个用于放缩的控制参数，其取值取决于高度图的量纲，aH(i+1,j)-aH(i-1,j)表示模型表面沿着U方向的高度差，aH(i,j+1)-aH(i,j-1)表示模型表面沿着V方向的高度差。我们使用S_z和T_z来表示两个向量的Z分量，经过推导可以得到：$$ Normal(i,j)&#x3D; \\frac{S(i,j)×T(i,j)}{||S(i,j)×T(i,j)||} &#x3D; \\frac{&lt;-S_z,-T_z,1&gt;}{√S_z^2+T_z^2+1} $$通过测试比较不同方法的效果，在实践中笔者最终使用了Sobel算子，对图像进行滤波以计算图像梯度。Sobel_x和Sobel_y两个算子分别用于计算图像沿着x和y两个方向的梯度，整体梯度G可由x方向的梯度G_x和y方向的梯度G_y按以下公式求得：$$ sobel_x &#x3D; \\begin{bmatrix} 1 \\ 2 \\ 1 \\end{bmatrix} * \\begin{bmatrix} 1 &amp; 0 &amp;-1 \\end{bmatrix} &#x3D; \\begin{bmatrix} 1 &amp; 0 &amp; -1 \\ 2 &amp; 0 &amp; -2 \\ 1 &amp; 0 &amp; -1 \\end{bmatrix}$$$$ sobel_y &#x3D; \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\end{bmatrix} * \\begin{bmatrix} 1 \\ 0 \\ -1 \\end{bmatrix} &#x3D; \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\ 0 &amp; 0 &amp; 0 \\ -1 &amp; -2 &amp; -1 \\end{bmatrix}$$$$ G &#x3D; \\sqrt{G_x^2 + G_y^2} $$ Roughness 贴图的物理意义所有的PBR技术都基于微平面理论。这项理论认为，达到微观尺度之后任何平面都可以使用被称为微平面(Microfacets)的细小镜面来进行描绘。Roughness贴图主要控制表面的粗糙程度，根据平面粗糙程度的不同，这些细小镜面的朝向会有不同程度的随机。理论上来讲，微表面可以通过几何上的变换进行模拟，但是由于这些微平面尺度太小，渲染时已经无法在像素水平对其进行区分，因此PBR理论中引入了粗糙度(Roughness)，并通过统计学的方法来近似这些微平面。Roughness越低表示微表面法线分布越统一，反射光线表现更加趋近于镜面反射，而Roughness越高，则表示表面法线分布越混乱越随机，反射光线表现更趋近于漫反射。 具体到反射方程中，Roughness会影响到BRDF中的D（法线分布函数）和G（几何函数）的计算。 法线分布函数（NDF）被用来描述表面一点内微表面的法向分布。输入一个方向h，法线分布函数会返回法向是h的微平面占所有微表面的比例。法线分布函数有许多不同的模型，但都需要Roughness参与计算，其中目前最常使用的是由Bruce Walter和Kenneth Torrance提出的GGX-NDF，其中，Burley推荐以 α&#x3D;roughness^2,其中roughness∈[0,1] 的方式代入模型表面粗糙度数据，以让分布以更线性的方式变化：$$ NDF_{GGXTR} (n,h,α)&#x3D;\\frac{α^2}{\\pi((n·h)^2·(α^2-1)+1)^2} $$ 几何函数（GSF）则是用于描述由于微面的自阴影行为而导致的光衰减的函数。几何函数模拟了在给定点微面相互遮挡或光在多个微面上反弹的概率，在这些情况下，光在到达视点之前会失去能量，因此宏观上也就表现为我们观察到该处的反射强度会降低。BRDF中使用的几何函数一般指的是包含了在光照方向L上的阴影函数（shadowing function）和在观察方向V上的遮蔽函数（masking function）的联合遮蔽阴影函数。几何函数对于BRDF能量守恒至关重要,BRDF方程一个关键部分是有效表面积（指的是能将光线从光源方向反射到视点方向的表面所覆盖的面积与微面表面的总表面积之间的比率）。而如果不考虑几何函数，则该有效表面积可能会超过总面积，也就破坏了能量守恒。为了准确地生成GSF，大多数拟合公式需要对粗糙度进行采样以确定微平面分布，因此几何函数也与粗糙度Roughness有密切的联系。 Mipmap技术及其引入的高光走样问题简介为了避免高光走样问题，现代渲染通常会使用Mipmap技术，但在渲染中用Mipmap技术处理法线贴图会引入高光走样问题。为了解决该问题，NVIDIA提出了一种基于Mipmap的法线方差估计技术，通过计算法线贴图方差信息，修改材质的粗糙度信息，从而解决高光走样。我的毕业论文中在Blender中近似地实现了该效果，下面将对该问题的产生原因及解决原理做进一步阐述。 Mipmap技术现代渲染中必不可少的一个环节。图形学中使用纹理映射（Texture Mapping）将模型上每个点的颜色信息储存在二维的图像上。这种方式方便了美术工作者对模型着色的修改和控制，但贴图尺度过大或者过小都会引发一些渲染走样。当纹理相对于模型过小时，屏幕空间中多个像素点对应在纹理贴图上的坐标都集中在一个像素附近，如果简单地取最近邻的像素值，会导致渲染结果产生严重的走样。实际渲染中一般使用双线性插值来对坐标附近的像素值做一个混合，但这样得到的效果仍不足以弥补问题。 而当纹理相对于模型在屏幕上所占像素数过大时（模型离相机较远时），屏幕空间的一个像素，可能就对应了贴图中一整个区域，这个区域被称为屏幕像素在纹理空间的footprint。此时对于在屏幕空间上相邻的片元来说，如果仅采样贴图上一个点来作为着色值，就会导致屏幕上相邻像素采样得到的颜色是不连续的，从而导致了渲染的锯齿状走样。从信号的角度上来说，这是采样频率过低引起的信息丢失。而使用SuperSampling（超采样）计算量过大，因此Mipmap技术应运而生。 Mipmap技术最早由Lance Williams在他的论文Pyramidal parametrics中提出。Mipmap技术的主要原理就是提前计算像素对应的footprint的均值。具体做法是对贴图进行多次下采样，得到不同尺寸的贴图，在渲染时根据模型与相机的距离，选择不同尺度的贴图。 基于Mipmap的法线方差估计在Mipmap下采样的过程中，普通颜色贴图中储存的是线性数据，因此可以直接进行线性混合。但法线贴图中储存的是归一化后的方向信息，原理上应该在球面坐标系下做向量插值计算。直接对三个分量线性插值得到的结果会与球面向量插值有所差别。下图给出了二维法线float2(1,0)与float2(0,1)按照从0~1的权重使用两种插值方式得到结果的角度差异（渲染时我们仅关注法线方向）。两种插值结果差异并不大，但使用球面向量插值会大大增加计算量，因此实际渲染管线中通常也直接使用线性插值进行法线贴图的Mipmap。 且我们可以得到这样一个规律，如下图，插值后的向量长度越接近一，则插值前两向量夹角越小，反之，则插值前法线夹角越大。 下图提供了向量夹角与线性插值结果长度的关系。 但线性插值得到的Normal结果显然无法完全表达材质的细节，多个法线混合后得到一个法线结果，在这个过程中我们损失了该处混合前法线的变化剧烈程度信息，这部分信息可以用法线贴图的方差来表达。Nvidia借用微表面理论中的原理，假设法线在Mipmap时输入符合高斯分布，标准差为σ。如下图，Nvidia得出了一定范围内的法线标准差与插值后结果的长度关系。其中红色是其实际关系的曲线，而绿色是Nvidia对其的逼近，逼近公式如下：$$ |N_a | &#x3D; \\frac{1}{1+σ^2} ⇔σ^2 &#x3D; \\frac{1-|N_a |}{|N_a | } $$因此，只需要采样Mipmap之后的法线贴图，我们就可以使用上述公式估计法线的局部方差。 使用Roughness变化矫正法线Mipmap带来的高光走样及其理解在实践中我们发现，仅对法线贴图Mipmap仍然会带来高光走样问题，这是由于Mipmap后的法线贴图不能完全表达出之前的材质信息，Mipmap后的贴图只能采样到一个方向信息，却忽略了材质局部的法线变化程度。我们之所以在渲染中引入Roughness贴图，正是因为无法描述亚像素级别的微平面法线差异。因此从本质上来说，Roughness贴图储存的也是模型的一部分法线信息。而使用法线贴图来宏观表现还是使用粗糙度贴图来微观表现，其分界就在像素级别。一个像素仅可以对应一个法线方向，因此，所有在一个像素内的法线变化信息（不论其对应纹理空间多大的范围），都应该被包含在粗糙度贴图中。也就是说，当法线贴图生成Mipmap时，部分法线信息退化为表面粗糙度信息，我们需要提高模型的粗糙度以避免高光走样问题（如下图）。 在实践中，笔者将法线贴图的局部方差对应到材质粗糙度的改变，并借鉴了Nvidia提出的方法，通过对Mipmap之后的法线贴图采样，计算法线局部的方差，从而实时地实现了对人脸粗糙度的改变，避免了Mipmap带来的高光走样问题。","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Physically Based Rendering","slug":"Physically-Based-Rendering","permalink":"https://yaelcassini.github.io/tags/Physically-Based-Rendering/"},{"name":"Microfacet","slug":"Microfacet","permalink":"https://yaelcassini.github.io/tags/Microfacet/"},{"name":"Materials","slug":"Materials","permalink":"https://yaelcassini.github.io/tags/Materials/"}]},{"title":"一篇搞懂基于微表面模型的PBR材质(待完善)","slug":"PBR-BSDF-Based-Microfacet-Model","date":"2023-11-13T07:11:17.000Z","updated":"2024-01-26T08:47:54.398Z","comments":true,"path":"2023/11/13/PBR-BSDF-Based-Microfacet-Model/","link":"","permalink":"https://yaelcassini.github.io/2023/11/13/PBR-BSDF-Based-Microfacet-Model/","excerpt":"在当前的图形学前沿研究中，对人脸的真实感渲染，基本都是基于PBR理论的。基于物理的渲染（Physically-based rendering）指的是使用数学建模的方式，模拟物体表面各种材质对光线反射和折射的特性，从而达到逼近真实的渲染效果的技术。其主要特点是遵循真实物理规律，光与材质相分离，且材质参数取自真实生活中的材质特征。由于本身基于物理原理，使用PBR的渲染效果相较于简单的Phong等模型会更加真实，其基于物理的参数设置也使得美术工作者可以对材质进行可预见效果的调节。 渲染与材质息息相关，私以为如果说Rasterization Rendering Pipeline，Path Tracing是渲染的骨骼，那么Materials就是渲染的心脏，是决定Mesh表面着色，光线追踪中光线Bounce后的采样方向等重要环节的核心模块。而所谓的Physically Based Rendering，除了Path Tracing本身是Physically Based的一种想法之外，Physically Based Materials也是必不可少甚至于根本上反映Physically的一环。","text":"在当前的图形学前沿研究中，对人脸的真实感渲染，基本都是基于PBR理论的。基于物理的渲染（Physically-based rendering）指的是使用数学建模的方式，模拟物体表面各种材质对光线反射和折射的特性，从而达到逼近真实的渲染效果的技术。其主要特点是遵循真实物理规律，光与材质相分离，且材质参数取自真实生活中的材质特征。由于本身基于物理原理，使用PBR的渲染效果相较于简单的Phong等模型会更加真实，其基于物理的参数设置也使得美术工作者可以对材质进行可预见效果的调节。 渲染与材质息息相关，私以为如果说Rasterization Rendering Pipeline，Path Tracing是渲染的骨骼，那么Materials就是渲染的心脏，是决定Mesh表面着色，光线追踪中光线Bounce后的采样方向等重要环节的核心模块。而所谓的Physically Based Rendering，除了Path Tracing本身是Physically Based的一种想法之外，Physically Based Materials也是必不可少甚至于根本上反映Physically的一环。 我从本科学习时就曾经接触到Physically Based Rendering，但是直到做我的毕业论文课题时才对其有了一个较为全面的基础了解，但或许是我天资较差，相关的知识于我而言总是常看常新的，在至今的一两年中每次学习总是能发现自己之前理解的不对的地方，在最近做Blender和Mitsuba中材质模型的对齐工作时，我总算觉得自己对Physically Based Material有了一个自己认为还比较完整的理解，故将自毕业论文以来的学习和思考整理于此。（当然之后也可能再次进行学习并推翻现在的一些想法。 本篇的核心追求是完整地梳理PBR材质相关的知识线，因此相对来说可能会较为啰嗦，会引用一些我本科毕业论文中的原文，还望海涵。 基础概念的引入基于物理的渲染(PBR, Physically-Based Rendering)是计算机图形学中用数学建模的方式模拟物体表面各种材质散射光线的属性从而渲染照片真实图片的技术，是近年来渲染的大趋势。它主要的特点是遵循物理规律，光与材质是分离的，且控制材质的参数是与现实生活中的材质特征对应的。 由于PBR本身基于物理原理，因此，这种渲染方式相比于之前的Phong或者Blinn-Phong这样简单的模型来说，渲染结果会更加真实。另一方面，PBR也使得美术人员可以直接以物理参数为依据来调节和编辑材质，使得材质可以有基于物理性质可预见的视觉变化，并且无论光照条件如何，这样的材质都会是相对来说物理合理的。 BRDF（Bidirectional Reflectance Distribution Function，双向反射分布函数）是真实感图形学中最核心的概念之一，是用于描述光反射现象的基本模型，描述的是入射光线经过物体表面反射后如何在各个出射方向上分布。其输出是入射光线方向和出射光线方向，并且由于都是归一化的向量，因此输入其实是四维的，输出是出射光线占入射光线的比例。而PBR中使用的BRDF模型通过包含材质的各种几何及光学性质来尽可能精确的近似现实世界中的材料，它必须满足至少如下两条特性：能量守恒、亥姆霍兹光路可逆性（Helmholtz Recoprpcity Rule）。 BRDF：Bi-directional Reflective Distribution FunctionBTDF：Bi-directional Transmit Distribution FunctionBSDF：Bi-directional Scattering Distribution Function其中，BSDF中的Scattering是反射和折射的统称，实际使用时BSDF &#x3D; BRDF + BTDF 微表面和Cook-Torrance模型微表面模型（Microfacet）是PBR中的重要理论基础。该假设认为物体表面是由法线方向不同的众多微小表面组成的。目前业界大部分的实时渲染管线使用的都是Cook-Torrance BRDF模型，该模型的整体反射方程为：$ L_o (p,ω_o )&#x3D; \\int_\\Omega (k_d \\frac{c}{π} +k_s \\frac{DFG}{4(ω_o·n)(ω_i·n)} ) L_i (p,ω_i )n·ω_i dω_i $其中BRDF也就是反射部分的公式是：$ f(l,v)&#x3D; \\frac{D(h)F(v,h)G(l,v,h)}{(4(n·h)(n·v))} $ D: 法线分布函数（Normal Distribution Funtion）在BRDF模型中，法线分布函数（Normal Distribution Function，简写为NDF），也就是上述公式中的D(h)，被用来描述表面一点的所有微表面的法线分布概率。输入一个朝向h，NDF会返回朝向是h的微表面占所有微表面的比例。 在微表面模型的假设下，表面越粗糙，每个微面将沿着表面排列得越混乱，从而导致方向范围更广泛的镜面反射。相反，在光滑的表面上，光线更有可能沿大致相同的方向反射，从而产生更小、更清晰的反射。 理论上来讲，微表面可以通过几何上的面片进行模拟，但是由于这些微面过于小，我们无法在每个像素的基础上区分它们，因此在基于物理的渲染工作流中，业界一般使用的方法是：在给定粗糙度参数的情况下，在统计上近似这些微平面。通过对粗糙度贴图（Roughness）采样，以计算微平面归一化的法线分布函数，可以将需渲染的几何体细化到了微观尺度（Microscale）的亚像素层面，所以能够带来更加接近真实的渲染质量和更全面的材质外观质感把控。也就是说，Roughenss Map其实是亚像素级别的 Normal Map。 NDF函数有许多不同的模型，按照提出的时间可以总结为（本总结摘自毛星云大佬的知乎文章）： Berry[1923] Beckmann[1963] Phong [1973] Blinn-Phong[1977] ABC[1989] GGX[2007] Trowbridge-Reitz[1975] Shifted Gamma Distribution SGD[2012] Trowbridge-Reitz（GTR）[2012] Student’s T-Distribution STD[2017] Exponential Power Distribution EPD[2017]。 其中目前业界最常使用的是由 Bruce Walter 和 Kenneth Torrance提出的GGX NDF和Beckmann NDF。 GGX的公式：$ NDF_{GGXTR} (n,h,α)&#x3D; \\frac{α^2}{(π((n·h)^2·(α^2-1)+1)^2 )} $ Beckmann公式：$ NDF_{Beckmann} (n,h,\\alpha) &#x3D; \\frac{1}{\\pi \\alpha^2 (n·h)^4} e^{(\\frac{(n·m)^2-1}{\\alpha^2 (n·m)^2})} $ 下图是不同NDF公式的曲线可视化对比，其中红线为 $α_b&#x3D;0.2$ 时的Beckmann-NDF，蓝线为 $α_p&#x3D;48$ 时的Phong-NDF，绿线为 $α_g&#x3D;0.2$ 时的GGX-NDF。从图中不难看出，GGX分布函数拥有一个比Beckmann和Phong模型更大的拖尾，衰减更慢，因此在实际使用中使用GGX会使得高光衰减过渡更自然。 另外，Brent Burley在Physically-based shading at Disney中提出了一种叫做GTR的通用的NDF模型，其可以通过参数 γ 控制NDF曲线的形状，及其拖尾的大小，从而控制材质的光影过渡程度，当 γ 为2时等于GGX模型。 G: 几何遮蔽函数（Geometric Shadowing Function）BRDF模型中的几何遮蔽函数是用于描述由于微表面的自阴影行为而导致的光衰减的函数。这种近似模拟了在给定点微面相互遮挡或光在多个微面上反弹的概率。在这些情况下，光在到达视点之前会失去能量，因此宏观也就表现为我们观察到该处的反射强度会降低。 几何阴影函数对于 BRDF 模型是否满足能量守恒至关重要。如果没有几何阴影函数，可能会导致物体表面反射的光比接收的更多。BRDF 方程一个关键部分是有效表面积（指的是能将光线从光源方向反射到视点方向的表面所覆盖的面积与微面表面的总表面积之间的比率）。而如果不考虑几何阴影函数，则该有效表面积可能会超过总面积，也就破坏了能量守恒。 几何阴影也有不同的拟合公式，历史上主流的几何函数建模，按提出或归纳的时间进行排序，可以总结为（摘自毛星云知乎文章）： Smith [1967] V-cavity（Cook-Torrance）[1982] Schlick-Smith [1994] Neumann [1999] Kelemen [2001] Implicit [2010] [21] 其中，Smith遮蔽函数（Smith masking function）是现在业界所采用的主流遮蔽函数，Eric Heitz在2014年[4]将其拓展为Smith联合遮蔽阴影函数（Smith Joint Masking-Shadowing Function），该函数具有四种形式： 分离遮蔽阴影型（Separable Masking and Shadowing） 高度相关遮蔽阴影型（Height-Correlated Masking and Shadowing） 方向相关遮蔽阴影型（Direction-Correlated Masking and Shadowing） 高度-方向相关遮蔽阴影型（Height-Direction-Correlated Masking and Shadowing） 其中，高度相关遮蔽阴影型及其近似，是目前业界采用的主流遮蔽阴影函数。高度相关理论的准确性也由Eric Heitz在《Understanding the Masking-Shadowing Function in Microfacet-Based BRDFs》中证明[4]。 2014年之前，Disney在SIGGRAPH2012上提出的GSF参考了[Walter 2007]的近似方法，使用Smith GGX导出的G项，并将粗糙度参数进行重映射以减少光泽表面的极端增益，即将α 从[0,1]重映射到[0.5, 1]，α的值为 $(0.5+roughness&#x2F;2)^2$ 。从而使几何项的粗糙度变化更加平滑，更便于美术人员的使用。 UE4在SIGGRAPH 2013上公布的方案为基于Schlick近似，将k映射为 k&#x3D;a&#x2F;2 ,去匹配GGX Smith方程，并采用了Disney对粗糙度的重映射$(0.5+roughness&#x2F;2)^2$： $$ G_1 (v)&#x3D;(n·v)&#x2F;((n·v)(1-k)+k) $$$$ G(l,v,h)&#x3D;G_1 (l) G_1 (v) $$ 其中，G_1 (l) G_1 (v) 是因为我们需要将观察方向（几何遮蔽Geometry Obstruction）和光线方向向量（几何阴影Geometry Shadowing）都考虑进去。而在2014年之后，UE4、Frostbite和Unity等引擎都受到Heitz的启发，为了得到更精确的几何遮挡关系，开始考虑入射阴影和出射遮蔽之间的相关性（不考虑相关性会导致计算出的阴影偏多），并在后续更新中各自转向了Smith联合遮蔽阴影函数（The Smith Joint Masking-Shadowing Function）的高度相关遮蔽阴影形式（Height-Correlated Masking and Shadowing），并相应地都做了一些近似与优化。 F: 菲涅尔函数（Fresnel Function）菲涅尔效应（Fresnel effect）表示的是看到的光线的反射率与视角相关的现象，由法国物理学家奥古斯丁·菲涅尔率先发现：当垂直观察的时候，任何物体或者材质表面都有一个基础反射率F_0（Base Reflectivity），但是如果以一定的角度往平面上看的时候所有反光都会变得明显起来。如果从理想的90度视角观察，所有的平面理论上来说都能完全的反射光线。而菲涅尔方程作为基于物理的渲染理念中的核心理念之一，描述的是光线入射之后，光会部分反射且部分折射，反射的比例就是菲涅尔系数。菲涅尔系数满足：$ 0&lt;&#x3D;F_r&lt;&#x3D;1 $当光线垂直撞击表面时，该光线被反射（Reflected）为镜面反射光的比率被称为$F_0$。而折射（Refracted）到表面中的光量则为$1-F_0$。但需要注意的是，我们在宏观层面看到的菲涅尔效应实际上是微观层面微平面菲涅尔效应的平均值。也就是说，影响菲涅尔效应的关键参数在于每个微平面的法向量和入射光线的角度，而不是宏观平面的法向量和入射光线的角度。 菲涅尔系数可以由麦克斯韦方程组直接推导出来的，已知平面处两种介质的折射率分别为：$\\eta_i、\\eta_t$，则根据斯涅尔定理可得折射角和入射角的关系：$\\eta_i sin\\theta_i &#x3D; \\eta_t sin \\theta_t$根据麦克斯韦方程组计算推导，平行和垂直偏振光的菲涅尔反射公式：$$ r_{\\parallel} &#x3D; \\frac{\\eta_t cos \\theta_i - \\eta_i cos \\theta_t}{\\eta_t cos \\theta_i + \\eta_i cos \\theta_t} $$$$ r_{\\perp} &#x3D; \\frac{\\eta_i cos \\theta_i - \\eta_t cos \\theta_t}{\\eta_i cos \\theta_i + \\eta_t cos \\theta_t} $$ $$ F_r &#x3D; \\frac{1}{2} (r_{\\parallel}^2 + r_{\\perp}^2) $$ 上面这部分参考了：https://zhuanlan.zhihu.com/p/158025828 菲涅尔项的常见模型： Cook-Torrance[1982] Schlick[1994] Gotanta [2014]。目前业界在渲染时大多采用Fresel的Schlick近似[3]：$$ c &#x3D; \\frac{n·v}{a\\sqrt{1-(n·v)^2}} $$MERL材质[6]中的菲涅尔项如下图，为了方便观察这个曲线经过一定程度的放缩和偏移，在θ_d为90度时都有一定程度的增大。红色虚线部分是理论中的菲涅尔反应。 基础反射率$F_0$的求解方式需要用到材料的折射率：$$ F_0&#x3D;(\\frac{n_1-n_2}{n_1+n_2})^2 $$其中，n_1和n_2分别为两种介质的折射率。通常假设 n_1&#x3D;1 近似于空气的折射率，并用n替换n_2，于是，上式可以简化为：$$ F_0&#x3D;(\\frac{n-1}{n+1})^2 $$ 相对折射率(relative refractive index)在学习Mitsuba代码的时候，发现其折射率涉及到代码里两个变量：m_eta和m_k，查资料后知道其代表的分别是相对折射率的实部和虚部。折射率(refractive index)是用来描述光线在某介质内传播速度的比例。对于同一种光源在不同介质中的折射率,如果以真空为基准,就称为相对折射率。而相对折射率通常可以用一个复数来表示: $ n &#x3D; n’ + k * i $。其中: n’是相对折射率的实部,代表光线在该介质中的沿进速度。 k是相对折射率的虚部,代表光线在该介质中的衰减率。 工业界两种PBR工作流程 https://blog.csdn.net/u010281174/article/details/108964117 Disney Principled BSDFReference 不同N、G、F的公式可见：https://graphicrants.blogspot.com/2013/08/specular-brdf-reference.html B. Burley and W. D. A. Studios. Physically-based shading at disney. In ACM SIGGRAPH, pages 1–7, 2012.","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Physically Based Rendering","slug":"Physically-Based-Rendering","permalink":"https://yaelcassini.github.io/tags/Physically-Based-Rendering/"},{"name":"Microfacet","slug":"Microfacet","permalink":"https://yaelcassini.github.io/tags/Microfacet/"},{"name":"Materials","slug":"Materials","permalink":"https://yaelcassini.github.io/tags/Materials/"}]},{"title":"相机相关知识 - Fov、Focal Length和Sensor","slug":"Fov-FocalLength-Sensor","date":"2023-11-07T07:10:15.000Z","updated":"2024-01-05T12:30:54.897Z","comments":true,"path":"2023/11/07/Fov-FocalLength-Sensor/","link":"","permalink":"https://yaelcassini.github.io/2023/11/07/Fov-FocalLength-Sensor/","excerpt":"工作需求经常需要跟坐标系转换打交道，在学习过程中也接触到很多相机姿态相关知识，另外因为自己是摄影爱好者，对相机相关参数也比较有学习的兴趣，因此开坑在这里整理一些学习到的相机计算相关知识。","text":"工作需求经常需要跟坐标系转换打交道，在学习过程中也接触到很多相机姿态相关知识，另外因为自己是摄影爱好者，对相机相关参数也比较有学习的兴趣，因此开坑在这里整理一些学习到的相机计算相关知识。 Fov、Focal Length和Sensor首先是一个在对齐Relighting项目（里面主要用到了neural-renderer）和Blender的相机参数时发现的问题，在使用我自己的编写的从Blender导出calib数据，和从calib数据导入Blender代码时，发现同一个相机竟然在不同的Blender工程中视场不一样大（震惊），检查之后终于找到了问题点所在，再Blender的相机面板的Camera下面，可以选择拟合传感器的方式，Blender默认是Auto，而我之前的工程文件是Horizontal。 查找资料并咨询了同事之后知道其原因。首先，在渲染中都默认sensor模拟的是35毫米胶卷，指的是单格长高边为36MM×24MM的胶卷。最早是由莱卡公司发起的。35mm其实指的是胶卷高度，由于两边还有齿孔位置因此最后的感光高度只有24mm。而进入数码相机时代之后，相机使用ccd和cmos作为感光元件，全幅相机中的cmos也是36MM*24MM大小，全幅也就是比较标准的cmos规格，市面上的镜头说的焦距一般都是在全幅下的焦距，不同画幅的感光元件大小和焦距计算所乘的倍数如下图所示（图源网络）。全画幅和其他画幅如APSC画幅的对角线之比，成为该画幅相当于全画幅的裁切系数。很巧的时，在写下这些文字的当下，笔者正在考虑是否要把自己的残幅机身换成全幅机身（Canon R7换R62）。 不同画幅不止会带来视场大小的差异，也会带来画质和宽容度的差别，比如我现在使用的主力机R7，在残幅的大小下，包含了三千多万的像素，就会导致每个像素的感光面积很小，带来的体感差异也就是R7的高感效果一般，并且感觉在光线不足时拍照画面纯净度较低。 跑题了，说回Blender中的Sensor面板，关于Fov（视场），焦距，Sensor大小，有以下约束关系：数值计算公式: $fov(度)&#x3D; 2 * arctan(传感器尺寸&#x2F;2&#x2F;焦距)$ 视场取决于传感器大小和焦距。 相同焦距下，传感器越大，视场越宽。 相同传感器下，焦距越长，视场越窄；焦距越短,视场越宽。 如下图，可以把相机简化为一个小孔模型，镜头的光学中心点到成像平面的距离就是焦距。当更换画幅时，传感器大小变化，焦距不变，因此fov变化；当更换镜头时，传感器大小不变，焦距变化，fov变小，因此在相同的对焦距离下，视场更小。而之所以焦距变化，是镜头带来的固有光学属性，这样看来应该是对于机身来说，像平面不同，不同镜头改变了光学中心的位置从而改变焦距，因此也就可以解释为什么长焦镜头都是瘦高个。在影视飓风的视频里看到16mm镜头在全画幅下fov为108度，但我无论怎么计算都计算不到这个数字，后面查资料才发现在相机中如果只使用一个fov数值那一般是感光元件对角线长度除以焦距，而不是长或者宽。全画幅的对角线长度约为43MM。想到一个之前参加社团笔试的题目，用广角和长焦对着同一个主体拍摄：1、在同一距离，将广角拍摄得到的画面进行裁切后，保证主体大小相同，得到画面与长焦是否完全相同；2、改变拍摄距离距离，保证两种镜头主体大小相同，拍到的画面是否有区别。答案是第一问没有区别，第二问有区别。我对该问题的理解是，可以直接去思考相机与主体和背景的相对位置关系，同一距离下，相对位置完全相同，只有fov不同，因此只需要裁切就可以完全一样，但是不同距离下，当主体大小相同时，其实拍摄点与背景的相对位置关系已经发生了变化，因此画面已经完全不同。 又跑题了，说回Blender中的Sensor面板，当Sensor fit为Auto时，Blender会用下面的数值去拟合画面中较长的一个边，比如画面是横幅的就会拟合宽，竖幅的画面则会将这个数值对应到高。而下面的Horizontal和Vertical则是制定了以某一个固定的数值去拟合画面，Horizontal就是以指定的Width去拟合画面的宽，而高度是会根据我们设置的画面分辨率比例进行动态的计算调整的，不参与计算，也不显示动态变化（这里我觉得应该动态变化比较合理），Vertical则相反。至于Blender中的fov，我在观察实验后发现，在修改Sensor fit时，Blender是保持Focal Length不变，根据上面的计算规则去计算Fov的，但并不是使用的对角线fov，而只是单纯某个边的fov。","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Camera","slug":"Camera","permalink":"https://yaelcassini.github.io/tags/Camera/"}]},{"title":"基于Beckmann分布的Blender-Cycles与Mitsuba高光渲染效果对齐","slug":"Blender-Source-Code","date":"2023-10-24T08:21:36.000Z","updated":"2024-03-11T09:38:07.743Z","comments":true,"path":"2023/10/24/Blender-Source-Code/","link":"","permalink":"https://yaelcassini.github.io/2023/10/24/Blender-Source-Code/","excerpt":"由于工作需求，我们的采集流程中使用的是基于Mitsuba的可微渲染，而采集得到的高光贴图需要在Blender中进行渲染成图，两边的BSDF渲染效果不统一问题困扰了我们许久。因此本文的核心需求是，阅读Blender和Mitsuba的源码，找出其差异，并在源码级别实现在Blender中复现Mitsuba的高光渲染效果。最后本文对Blender源码做了修改和重编译，用新的Blender编译版本实现了该渲染效果对齐的需求。","text":"由于工作需求，我们的采集流程中使用的是基于Mitsuba的可微渲染，而采集得到的高光贴图需要在Blender中进行渲染成图，两边的BSDF渲染效果不统一问题困扰了我们许久。因此本文的核心需求是，阅读Blender和Mitsuba的源码，找出其差异，并在源码级别实现在Blender中复现Mitsuba的高光渲染效果。最后本文对Blender源码做了修改和重编译，用新的Blender编译版本实现了该渲染效果对齐的需求。 Blender和Mitsuba渲染场景及参数的对齐为了方便对齐两边的渲染效果，我需要首先把两边的渲染场景对齐，其中Mitsuba使用xml文件储存场景信息，而Blender则是工程文件，我具体进行的对齐有： 两边都取消所有点光源、面光源等，都只使用同一张exr格式的环境贴图，对贴图亮度的scale都设置为0.05，使用的环境贴图是Equirectangular Mapping格式。 两边camera的参数对齐，包括外参：相机的姿态矩阵和内参：相机的fov、cx、cy等，都使用perspective透视模式。（ 这部分其实包含很多具体的学习内容和计算，可以参考我的博客文章：https://yaelcassini.github.io/2023/11/07/Camera-Realted-Knowledge/ ） 两边渲染分辨率的对齐，都使用6960*4640。 两边spp（sample per pixel）的对齐，实验过程中都使用1024。 两边渲染结果都使用exr格式输出。（ 这里一开始由于Blender的颜色管理出问题导致误以为两边光照不相同，浪费了很多时间，具体可以参考我的博客文章：https://yaelcassini.github.io/2023/04/24/Color-Management/ ） 两边的最大bounce次数对齐，其中，Blender中Max Bounces都设置为0时，才是只有直接光照的结果，而不是设置为1时。 两边渲染使用的Mesh完全相同，（载入Blender时要注意Blender的坐标系是z轴朝上的，import obj会默认做一个绕x轴的90度旋转。） 模型贴图都使用exr格式输入，不做颜色空间转换避免出现问题。 Mistuba源码阅读及分析Mitsuba场景文件中的bsdf信息如下： 123456789101112&lt;bsdf id=&quot;obj_bsdf&quot; type=&quot;roughconductor&quot;&gt; &lt;boolean name=&quot;sample_visible&quot; value=&quot;false&quot;/&gt; &lt;string name=&quot;distribution&quot; value=&quot;beckmann&quot;/&gt; &lt;boolean name=&quot;fresnel_schlick&quot; value=&quot;true&quot;/&gt; &lt;boolean name=&quot;forward&quot; value=&quot;true&quot;/&gt; &lt;texture id=&quot;f0&quot; name=&quot;f0&quot; type=&quot;bitmap&quot;&gt; &lt;string name=&quot;filename&quot; value=&quot;/f0.exr&quot;/&gt; &lt;/texture&gt; &lt;texture id=&quot;alpha&quot; name=&quot;alpha&quot; type=&quot;bitmap&quot;&gt; &lt;string name=&quot;filename&quot; value=&quot;alpha.exr&quot;/&gt; &lt;/texture&gt;&lt;/bsdf&gt; 可以看到使用的是roughconductor模型，主要代码在mitsuba2\\src\\bsdfs\\roughconductor.cpp文件中，bsdf的相关计算在RoughConductor类的eval函数中，我们项目中使用的是学长修改过的mitsuba，因此可以支持fresnel_schlick近似的计算，学习源码后转化的公式为： $$ result &#x3D; \\frac{F * D * G}{4 * cos \\theta_i} $$ $$ D &#x3D; D_{NDF_Beckmann} (n,h,α)&#x3D;\\frac{1}{(\\pi α^2 (n·h)^4 )} e^{(\\frac{(n·h)^2-1}{α^2 (n·h)^2 })} $$ $$ G &#x3D; G_2(l,v,h) &#x3D; G_1(l) * G_1(v) $$ $$ G_1(v) &#x3D; G_{GGX_Beckmann}(v) &#x3D; \\left {\\begin{array}{l l} \\frac{ 3.535 c + 2.181 c^2 }{ 1 + 2.276 c + 2.577 c^2 } &amp; \\quad \\text{if $c &lt; 1.6$}\\ 1 &amp; \\quad \\text{if $c \\geq 1.6$}\\end{array} \\right. $$ $$ 其中：c &#x3D; \\frac{n·v}{ \\alpha \\sqrt{1 - (n·v)^2} } $$$$ F &#x3D; F_{Schlick}(v,h) &#x3D; f0 + (1 - f0) * (1-v·h)^5 $$ Blender源码阅读及分析（主要针对Glossy BSDF着色节点的跟踪）首先，放一下根据阅读源码和调试整理出的关于Blender一次渲染从顶端到底端调用的调用堆栈： Blender中“Principled BSDF”节点是没有Beckmann分布的，只提供GGX和Multiscatter GGX两个微表面模型，因此我们流程中使用的是提供Beckmann分布的“Glossy BSDF”节点。因此需求转化为分析“Glossy BSDF”节点的具体实现公式，因此在大致学习了Blender源码的编写结构之后就从“Glossy BSDF”结点入手进行具体分析。首先，Blender支持OSL(Open Shader Language)，源码中有内置shader nodes的osl实现版本。因此在一开始通过关键词检索源码的阶段我自然而然的找到了osl实现的部分，虽然后来发现只关注osl是显然不行的，但此处还是顺着我的探索历程来整理。(PS: 这里说一嘴，虽然osl模式有很多限制，但是胜在相比于普通渲染模式的代码阅读起来更类似GLSL等Shader语言，非常流畅，而且Blender应该是做了两种模式下渲染效果的对齐的，因此OSL可以作为辅助功能，比如想查看某个BSDF的具体计算过程，就可以先看OSL代码。) “Glossy BSDF”节点的底层实现使用OSL编写，在blender源码的intern\\cycles\\kernel\\osl\\shaders\\node_glossy_bsdf.osl文件中，其中使用到了microfacet函数。 接下来自然而然地去找microfacet函数的实现，找到intern\\cycles\\kernel\\osl\\closures_template.h文件中使用OSL_CLOSURE_STRUCT_系列关键字做了Microfacet、microfacet和用到的参数及其类型的声明。 由于工程里面没有找到其他的Microfacet关键字，因此下一步我选择搜索哪里用到了closures_template.h，找到了以下几个文件： closures_setup.h closures.cpp osl.h types.hBlender源码使用的方式是以上的每个文件里使用#define重新定义OSL_CLOSURE_STRUCT_系列关键字的含义，以减轻代码的重复性和冗余性。 closures_setup.h中引入template用于创建Closure结构体。 closures.cpp中引入了两次template，一次用于创建返回值为ClosureParam的函数，猜测是用于返回参数列表，另一次是用于注册闭包。 osl.h中引入template用于flatten_closure_tree函数中，根据函数名及函数体内容猜测，该函数用于展开OSL闭包树,将其转换为单一BSDF表示。 types.h中引入template用于在枚举类型OSLClosure中声明不同shading类型的名字和值。 根据关键词osl_closure_microfacet搜索只能找到closures_setup.h中的osl_closure_microfacet_setup函数。该函数体内，在判断distribution为beckmann时，分三种情况讨论，折射，glass和else，我们需要的显然是最后一种情况。 用正则表达式搜索osl_closure_microfacet_setup函数，发现在osl.h中使用了switch判断，case为OSL_CLOSURE_##Upper##ID时，调用了osl_closure##lower##setup函数，猜测调用的方式时渲染时，在flatten_closure_tree函数中判断closure-&gt;id（应该是一个枚举类型OSLClosureType的变量），发现节点的枚举值是OSL_CLOSURE##Upper##ID（types.h），调用osl_closure##lower##setup（osl.h）。而closures.cpp中的register_closures函数则把小写的shading node名字#lower，大写的OSL_CLOSURE##Upper##ID，返回参数列表的osl_closure##lower##_params()函数绑定了。 最后一种情况调用bsdf_microfacet_beckmann_setup函数，并把bsdf类的fresnel_type变量赋值为MicrofacetFresnel::NONE，变量赋值为CLOSURE_BSDF_MICROFACET_BECKMANN_ID，从这里开始不再出现CLOSURE_BSDF_MICROFACET_ID，而需要顺着CLOSURE_BSDF_MICROFACET_BECKMANN_ID找。 搜索CLOSURE_BSDF_MICROFACET_BECKMANN_ID找到的bsdf_sample函数，位于intern\\cycles\\kernel\\closure\\bsdf.h文件中，在判断ShaderClosure-&gt;type后调用bsdf_microfacet_beckmann_sample函数。 bsdf_eval函数中调用的bsdf_microfacet_beckmann_eval是计算bsdf的核心，位于intern\\cycles\\kernel\\closure\\bsdf_microfacet.h文件中。 位于intern\\cycles\\scene的shader_nodes.cpp中的NODE_DEFINE(GlossyBsdfNode)中定义了glossy_bsdf节点，并在其中进行了分布枚举类型的名字和ID注册对应，比如：distribution_enum.insert(&quot;beckmann&quot;, CLOSURE_BSDF_MICROFACET_BECKMANN_ID); 由于“Principled BSDF”节点是有Fresnel项的，因此看一下Pricipled BSDF的代码做一个对比，发现该节点的osl实现里面用到了generalized_schlick_bsdf函数，我发现该函数是可以输出beckmann并且有fresnel项的，因此我使用Blender的OSL模式，调用该函数进行渲染，在使用如下设置和参数时，实现了同光照同场景下和Mitsuba渲染效果的对齐： 1234567891011121314151617shader simple_material( string distribution = &quot;beckmann&quot;, color f0 = color(0.04, 0.04, 0.04), float roughness = 0.1, normal Normal = N, output closure color BSDF = 0)&#123; color reflection_tint = color(1, 1, 1); color transmission_tint = color(0, 0, 0); float roughness_x = roughness; float roughness_y = roughness; vector tangent = vector(0, 0, 1); color f90 = color(1, 1, 1); float exponent = 5; BSDF = generalized_schlick_bsdf(Normal, tangent, reflection_tint, transmission_tint, roughness_x, roughness_y, f0, f90, exponent, distribution);&#125; 在OSL模式下对齐渲染效果是一个巨大的进步，之后我就只需要对照osl的实现修改普通渲染模式下的实现。在微表面模型设置为beckmann，fresnel项使用schlick近似，使用generalized_schlick_bsdf渲染时，Blender中的bsdf计算可以转化为以下公式： $$ result &#x3D; \\frac{F * D}{4 * cos\\theta_i * (1 + G_{l} + G(v))} $$ $$ D &#x3D; D_{NDF_Beckmann} (n,h,α)&#x3D;\\frac{1}{(\\pi α^2 (n·h)^4 )} e^{(\\frac{(n·h)^2-1}{α^2 (n·h)^2 })} $$ $$ G(v) &#x3D; G_{GSF_Beckmann} &#x3D; \\frac{1.0 - 1.259c + 0.369c^2}{3.535c + 2.181c^2} $$ $$ 其中：c &#x3D; \\frac{n·v}{ \\alpha \\sqrt{1 - (n·v)^2} } $$$$ F &#x3D; F_{Schlick}(v,h) &#x3D; f0 + (1 - f0) * (1-v·h)^5 $$ 结论：目前通过对比Blender和Mitsuba源码得到的结论是：在我们的流程中，Blender使用的Glossy BSDF里面不包含Fresnel项的赋值和计算，因此Fresnel值在进行beckmann_setup的时候被设置为MicrofacetFresnel::NONE（BSDF计算对比如下图）。在修改时要注意两边的Roughness有没有进行平方映射要对齐，通过对源码的阅读，Mistuba的Roughness是不进行平方映射的，因此Blender中也要去掉平方映射。其中，G项的不同我本来以为是Blender写错了，后来才发现还是自己太无知了，Blender使用的是高度相关遮蔽阴影型，而Mitsuba使用的是分离遮蔽阴影型。虽然具体计算不同但原理相同，计算结果差异也可忽略。具体可以参考毛星云大佬的文章：https://zhuanlan.zhihu.com/p/81708753 Blender 调试流程 下载Blender源码最好在Blender官方Git项目上选择一个稳定的branch，比如我选择的是blender-v4.0-release和blender-v3.6-release。可以用命令行git clone也可以直接download zip。笔者由于当时git网络不好使都是直接下载代码压缩包解压的，主要用到的是blender-v4.0-release这个分支。 Blender仓库地址：https://github.com/blender/blender Git clone指定分支指令：git clone -b blender-v4.0-release https://github.com/blender/blender 下载SVN，并使用SVN下载Blender编译需要的库，SVN可以理解为另一种形式的git，具体的区别笔者也米有深入了解，主打一个能用就行。笔者用的是TortoiseSVN，下载的是LTS 64位版本。下载后就可以像git一样在文件资源管理器右键寻找svn使用。 TortoiseSVN下载地址：https://tortoisesvn.net/downloads.html 在Blender源码的同级路径新建lib文件夹，再在其中新建win64_vc15文件夹，之后文件资源管理器右键选择SVN Checkout，在URL of repository一栏输入Blender官方提供lib下载地址，在这里要注意，SVN也有版本管理，默认是HEAD revision，不同的Blender版本最好选择不同的revision，可以在SVN的GUI页面选择Show log，在其中查看自己下载的Blender版本对应的revision代号。比如，笔者下载的blender-v4.0-release分支，打开revision log之后，选择的是Message为“Windows: 4.0 Liabrary Update”的revision，代号为63491，所以直接把63491填到revision后面的框内点击ok就可以下载对应的lib。 Blender官方提供的lib下载地址：https://svn.blender.org/svnroot/bf-blender/trunk/lib/win64_vc15 完成源码和library下载后的文件夹结构：├────blender&#x2F;│ ├────.git&#x2F;│ ├────build_files&#x2F;│ ├────extern&#x2F;│ ├────intern&#x2F;│ ├────locale&#x2F;│ ├────release&#x2F;│ ├────scripts&#x2F;│ ├────tests&#x2F;│ ├────tools&#x2F;│ ├────make.bat│ ├────CMakeLists.txt│ ├────pyproject.toml│ ├────README.md│ └────···├────lib&#x2F;│ ├────win64_vc15&#x2F;│ │ ├────alembic│ │ ├────blosc│ │ ├────boost│ │ ├────brotli└────└────└────··· 编译构建，在blender源码目录下，使用cmd进行命令行操作。4.1.用命令行直接编译，生成文件在 build_windows_Full_x64_vc16_Release\\bin\\Release 命令：make 4.2. 生成IDE工程，在 build_windows_Full_x64_vc16_Release 文件夹中生成VS工程。打开 Blender.sln， 命令：make full nobuild4.2.1. CMakePredefinedTargets&#x2F;INSTALL 工程上右键，执行 Build，这步会将一些文件放到输出目录。这个只需执行一次，不过切换Debug&#x2F;Release，也要执行一次。4.2.2. blender工程是默认工程，直接点击绿色三角。 Blender 源码修改步骤 把输入的Color值作为f0传递给bsdf，Blender中用了一些很神奇的操作传值，主要的读值操作在intern\\cycles\\kernel\\svm\\closure.h的svm_node_closure_bsdf函数中，集中在函数体的开头，当时也读了一段时间才读懂，由于篇幅限制此处不做详细解释，后续可能会单独写一篇。而传值操作在intern\\cycles\\scene\\shader_nodes.cpp中的void GlossyBsdfNode::compile函数中，对该函数的修改: 1234567891011 closure = distribution; /* TODO: Just use weight for legacy MultiGGX? Would also simplify OSL. */ if (closure == CLOSURE_BSDF_MICROFACET_MULTI_GGX_ID) &#123; BsdfNode::compile( compiler, input(&quot;Roughness&quot;), input(&quot;Anisotropy&quot;), input(&quot;Rotation&quot;), input(&quot;Color&quot;)); &#125; else &#123;- BsdfNode::compile(compiler, input(&quot;Roughness&quot;), input(&quot;Anisotropy&quot;), input(&quot;Rotation&quot;));+ BsdfNode::compile(compiler, input(&quot;Roughness&quot;), input(&quot;Anisotropy&quot;), input(&quot;Rotation&quot;), input(&quot;Color&quot;)); &#125; 在intern\\cycles\\kernel\\svm\\closure.h的svm_node_closure_bsdf函数中添加Fresnel项的内存分配以及材质信息赋值，这个函数相当于是设置材质固有信息，比如roughness和Normal等，没有拿到入射光线出射光线等信息，并不直接进行bsdf计算。(这里由于我是和指定的mistuba模型对齐，使用schlick近似，因此直接把exponent设置为5，如果有别的需求也可以添加node输入节点后传值设置。) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778 case CLOSURE_BSDF_MICROFACET_GGX_ID: case CLOSURE_BSDF_MICROFACET_BECKMANN_ID: case CLOSURE_BSDF_ASHIKHMIN_SHIRLEY_ID: case CLOSURE_BSDF_MICROFACET_MULTI_GGX_ID: &#123;#ifdef __CAUSTICS_TRICKS__ if (!kernel_data.integrator.caustics_reflective &amp;&amp; (path_flag &amp; PATH_RAY_DIFFUSE)) break;#endif Spectrum weight = closure_weight * mix_weight; ccl_private MicrofacetBsdf *bsdf = (ccl_private MicrofacetBsdf *)bsdf_alloc( sd, sizeof(MicrofacetBsdf), weight);+ ccl_private FresnelGeneralizedSchlick *fresnel =+ (bsdf != NULL) ? (ccl_private FresnelGeneralizedSchlick *)closure_alloc_extra(+ sd, sizeof(FresnelGeneralizedSchlick)) : NULL;- if (!bsdf) &#123;+ if (!bsdf || !fresnel) &#123; break; &#125;- float roughness = sqr(param1);+ float roughness = param1;- bsdf-&gt;ior = 1.0f;+ bsdf-&gt;ior = 0.0f;+ kernel_assert(stack_valid(data_node.w));+ fresnel-&gt;f0 = rgb_to_spectrum(stack_load_float3(stack, data_node.w));+ fresnel-&gt;f90 = one_spectrum();+ fresnel-&gt;exponent = 5;+ fresnel-&gt;reflection_tint = one_spectrum();+ fresnel-&gt;transmission_tint = zero_spectrum();+ bsdf-&gt;ior = ior_from_F0(fresnel-&gt;f0.x); /* compute roughness */ float anisotropy = clamp(param2, -0.99f, 0.99f); if (data_node.y == SVM_STACK_INVALID || fabsf(anisotropy) &lt;= 1e-4f) &#123; /* Isotropic case. */ bsdf-&gt;T = zero_float3(); bsdf-&gt;alpha_x = roughness; bsdf-&gt;alpha_y = roughness; &#125; else &#123; bsdf-&gt;T = stack_load_float3(stack, data_node.y); /* rotate tangent */ float rotation = stack_load_float(stack, data_node.z); if (rotation != 0.0f) &#123; bsdf-&gt;T = rotate_around_axis(bsdf-&gt;T, bsdf-&gt;N, rotation * M_2PI_F); &#125; if (anisotropy &lt; 0.0f) &#123; bsdf-&gt;alpha_x = roughness / (1.0f + anisotropy); bsdf-&gt;alpha_y = roughness * (1.0f + anisotropy); &#125; else &#123; bsdf-&gt;alpha_x = roughness * (1.0f - anisotropy); bsdf-&gt;alpha_y = roughness / (1.0f - anisotropy); &#125; &#125; /* setup bsdf */ if (type == CLOSURE_BSDF_MICROFACET_BECKMANN_ID) &#123; sd-&gt;flag |= bsdf_microfacet_beckmann_setup(bsdf);+ bsdf_microfacet_setup_fresnel_generalized_schlick(kg, bsdf, sd, fresnel, false); &#125; else if (type == CLOSURE_BSDF_ASHIKHMIN_SHIRLEY_ID) &#123; sd-&gt;flag |= bsdf_ashikhmin_shirley_setup(bsdf); &#125; else &#123; sd-&gt;flag |= bsdf_microfacet_ggx_setup(bsdf); if (type == CLOSURE_BSDF_MICROFACET_MULTI_GGX_ID) &#123; kernel_assert(stack_valid(data_node.w)); const Spectrum color = rgb_to_spectrum(stack_load_float3(stack, data_node.w)); bsdf_microfacet_setup_fresnel_constant(kg, bsdf, sd, color); &#125; &#125; break; &#125; 加了上面的代码之后发现Blender无法正常渲染，整个人脸部分都是全黑色的，printf输出debug之后发现是上述增加的closure_alloc_extra无法为Fresnel项分配内存，到函数内部debug发现是sd-&gt;num_closure变量不够用，因此找到了设置该变量的位置：intern\\cycles\\scene\\shader_graph.cpp中的int ShaderGraph::get_num_closures()，修改如下： 1234567891011121314151617181920212223242526272829303132333435363738 int num_closures = 0; foreach (ShaderNode *node, nodes) &#123; ClosureType closure_type = node-&gt;get_closure_type(); if (closure_type == CLOSURE_NONE_ID) &#123; continue; &#125; else if (CLOSURE_IS_BSSRDF(closure_type)) &#123; num_closures += 3; &#125; else if (CLOSURE_IS_BSDF_MULTISCATTER(closure_type)) &#123; num_closures += 2; &#125; else if (CLOSURE_IS_PRINCIPLED(closure_type)) &#123; num_closures += 12; &#125; else if (CLOSURE_IS_VOLUME(closure_type)) &#123; /* TODO(sergey): Verify this is still needed, since we have special minimized volume storage * for the volume steps. */ num_closures += MAX_VOLUME_STACK_SIZE; &#125; else if (closure_type == CLOSURE_BSDF_MICROFACET_BECKMANN_GLASS_ID || closure_type == CLOSURE_BSDF_MICROFACET_GGX_GLASS_ID || closure_type == CLOSURE_BSDF_HAIR_CHIANG_ID || closure_type == CLOSURE_BSDF_HAIR_HUANG_ID) &#123; num_closures += 2; &#125;+ else if (closure_type == CLOSURE_BSDF_MICROFACET_BECKMANN_ID)+ &#123;+ num_closures += 2;+ &#125; else &#123; // printf(&quot;this is else, num_closures+1.\\n&quot;); ++num_closures; &#125; &#125; return num_closures; 修改之后，Blender可以正常渲染了，但是整体的高光效果非常暗，整体亮度偏低，这里我又做了很多对照实现，分层渲染分析高光的Color、直接光、间接光，最后发现高光部分的直接光和Ground Truth对照组（OSL渲染的generalized_bsdf）有一个大致的线性倍数关系，实验后发现倍数刚好是f0的值，查看glossy bsdf node的OSL代码后发现，Blender的逻辑似乎是在BSDF计算后再乘上Color值，而我把f0值直接输入Color就会导致错误产生，为了避免这种干扰，我选择修改Glossy BSDF Node的输入节点设置，增加一个f0输入接口，而Color值设为1.0，修改位置如下： intern\\cycles\\scene\\shader_nodes.cpp中的NODE(GlossyBsdfNode): 123456789101112131415161718192021222324 NodeType *type = NodeType::add(&quot;glossy_bsdf&quot;, create, NodeType::SHADER); SOCKET_IN_COLOR(color, &quot;Color&quot;, make_float3(0.8f, 0.8f, 0.8f)); SOCKET_IN_NORMAL(normal, &quot;Normal&quot;, zero_float3(), SocketType::LINK_NORMAL); SOCKET_IN_FLOAT(surface_mix_weight, &quot;SurfaceMixWeight&quot;, 0.0f, SocketType::SVM_INTERNAL); static NodeEnum distribution_enum; distribution_enum.insert(&quot;beckmann&quot;, CLOSURE_BSDF_MICROFACET_BECKMANN_ID); distribution_enum.insert(&quot;ggx&quot;, CLOSURE_BSDF_MICROFACET_GGX_ID); distribution_enum.insert(&quot;ashikhmin_shirley&quot;, CLOSURE_BSDF_ASHIKHMIN_SHIRLEY_ID); distribution_enum.insert(&quot;multi_ggx&quot;, CLOSURE_BSDF_MICROFACET_MULTI_GGX_ID); SOCKET_ENUM(distribution, &quot;Distribution&quot;, distribution_enum, CLOSURE_BSDF_MICROFACET_GGX_ID); SOCKET_IN_VECTOR(tangent, &quot;Tangent&quot;, zero_float3(), SocketType::LINK_TANGENT); SOCKET_IN_FLOAT(roughness, &quot;Roughness&quot;, 0.5f); SOCKET_IN_FLOAT(anisotropy, &quot;Anisotropy&quot;, 0.0f); SOCKET_IN_FLOAT(rotation, &quot;Rotation&quot;, 0.0f);+ SOCKET_IN_COLOR(f0, &quot;F0&quot;, make_float3(0.5f, 0.5f, 0.5f)); SOCKET_OUT_CLOSURE(BSDF, &quot;BSDF&quot;); return type; intern\\cycles\\scene\\shader_nodes.cpp中的void GlossyBsdfNode::compile，把原来的input(&quot;Color&quot;)改为input(&quot;F0&quot;): 1234567891011 closure = distribution; /* TODO: Just use weight for legacy MultiGGX? Would also simplify OSL. */ if (closure == CLOSURE_BSDF_MICROFACET_MULTI_GGX_ID) &#123; BsdfNode::compile( compiler, input(&quot;Roughness&quot;), input(&quot;Anisotropy&quot;), input(&quot;Rotation&quot;), input(&quot;Color&quot;)); &#125; else &#123;- BsdfNode::compile(compiler, input(&quot;Roughness&quot;), input(&quot;Anisotropy&quot;), input(&quot;Rotation&quot;));+ BsdfNode::compile(compiler, input(&quot;Roughness&quot;), input(&quot;Anisotropy&quot;), input(&quot;Rotation&quot;), input(&quot;F0&quot;)); &#125; intern\\cycles\\scene\\shader_nodes.h中的GlossyBsdfNode定义： 12345678910111213141516171819202122232425class GlossyBsdfNode : public BsdfNode &#123; public: SHADER_NODE_CLASS(GlossyBsdfNode) void simplify_settings(Scene *scene); ClosureType get_closure_type() &#123; return distribution; &#125; NODE_SOCKET_API(float3, tangent) NODE_SOCKET_API(float, roughness) NODE_SOCKET_API(float, anisotropy) NODE_SOCKET_API(float, rotation)+ NODE_SOCKET_API(float3, f0) NODE_SOCKET_API(ClosureType, distribution) void attributes(Shader *shader, AttributeRequestSet *attributes); bool has_attribute_dependency() &#123; return true; &#125; bool is_isotropic();&#125;; source\\blender\\nodes\\shader\\nodes\\node_shader_bsdf_glossy.cc中的static void node_declare函数中： 1234567891011121314151617 b.add_input&lt;decl::Color&gt;(&quot;Color&quot;).default_value(&#123;0.8f, 0.8f, 0.8f, 1.0f&#125;); b.add_input&lt;decl::Float&gt;(&quot;Roughness&quot;) .default_value(0.5f) .min(0.0f) .max(1.0f) .subtype(PROP_FACTOR); b.add_input&lt;decl::Float&gt;(&quot;Anisotropy&quot;).default_value(0.0f).min(-1.0f).max(1.0f); b.add_input&lt;decl::Float&gt;(&quot;Rotation&quot;) .default_value(0.0f) .min(0.0f) .max(1.0f) .subtype(PROP_FACTOR); b.add_input&lt;decl::Vector&gt;(&quot;Normal&quot;).hide_value(); b.add_input&lt;decl::Vector&gt;(&quot;Tangent&quot;).hide_value(); b.add_input&lt;decl::Float&gt;(&quot;Weight&quot;).unavailable();+ b.add_input&lt;decl::Color&gt;(&quot;F0&quot;).default_value(&#123;0.5f, 0.5f, 0.5f, 1.0f&#125;); b.add_output&lt;decl::Shader&gt;(&quot;BSDF&quot;); 增加输入节点后的Glossy BSDF： 为了保持OSL模式下渲染效果也一致，修改了intern\\cycles\\kernel\\osl\\shaders\\node_glossy_bsdf.osl，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051shader node_glossy_bsdf(color Color = 0.8, string distribution = &quot;ggx&quot;, float Roughness = 0.2, float Anisotropy = 0.0, float Rotation = 0.0, normal Normal = N, normal Tangent = 0.0,+ color F0 = 0.0, output closure color BSDF = 0)&#123; /* compute roughness */ float roughness = Roughness * Roughness; float roughness_u, roughness_v; float aniso = clamp(Anisotropy, -0.99, 0.99); /* rotate tangent around normal */ vector T = Tangent; if (abs(aniso) &lt;= 1e-4) &#123; roughness_u = roughness; roughness_v = roughness; &#125; else &#123; if (Rotation != 0.0) T = rotate(T, Rotation * M_2PI, point(0.0, 0.0, 0.0), Normal); if (aniso &lt; 0.0) &#123; roughness_u = roughness / (1.0 + aniso); roughness_v = roughness * (1.0 + aniso); &#125; else &#123; roughness_u = roughness * (1.0 - aniso); roughness_v = roughness / (1.0 - aniso); &#125; &#125; if (distribution == &quot;Multiscatter GGX&quot;) BSDF = Color * microfacet_multi_ggx_aniso(Normal, T, roughness_u, roughness_v, Color);+ else if (distribution == &quot;Beckmann&quot; || distribution == &quot;beckmann&quot;)+ &#123;+ color reflection_tint = color(1, 1, 1);+ color transmission_tint = color(0, 0, 0);+ float roughness_x = Roughness;+ float roughness_y = Roughness;+ color F90 = color(1, 1, 1);+ BSDF = generalized_schlick_bsdf(Normal, T, reflection_tint, transmission_tint, roughness_x, roughness_y, F0, F90, 5, distribution);+ &#125; else BSDF = Color * microfacet(distribution, Normal, T, roughness_u, roughness_v, 0.0, 0);&#125; Blender中创建ShaderData变量的位置在：intern\\cycles\\kernel\\integrator\\shader_surface.h的ccl_device int integrate_surface函数中 source\\blender\\nodes\\shader\\nodes\\node_shader_bsdf_glossy.cc文件中有一部分也用了glossy bsdf node的输入，不过这部分被包裹在#ifdef WITH_MATERIALX定义中，因此应该只有materialX时才会用到。 另一种可能的Blender源码修改方法在后面做其他工作的时候又想到因为Principled BSDF用的是generalized bsdf，是否可以直接在里面加一个beckmann分布，有了之前的经验，这次很快就把该分布加上了，但是渲染效果偏暗并不能对齐，这里由于牵扯的变量太多了，时间原因暂且不深究，只在下面记录在Principled BSDF加入beckmann分布选项的方法： source\\blender\\makesrna\\intern\\rna_nodetree.cc中：1234567891011static const EnumPropertyItem node_principled_distribution_items[] = &#123;+ &#123;SHD_GLOSSY_BECKMANN, &quot;BECKMANN&quot;, 0, &quot;Beckmann&quot;, &quot;&quot;&#125;, &#123;SHD_GLOSSY_GGX, &quot;GGX&quot;, 0, &quot;GGX&quot;, &quot;&quot;&#125;, &#123;SHD_GLOSSY_MULTI_GGX, &quot;MULTI_GGX&quot;, 0, &quot;Multiscatter GGX&quot;, &quot;GGX with additional correction to account for multiple scattering, preserve energy and &quot; &quot;prevent unexpected darkening at high roughness&quot;&#125;, &#123;0, nullptr, 0, nullptr, nullptr&#125;,&#125;; intern\\cycles\\blender\\shader.cpp中：1234567891011121314 else if (b_node.is_a(&amp;RNA_ShaderNodeBsdfPrincipled)) &#123; BL::ShaderNodeBsdfPrincipled b_principled_node(b_node); PrincipledBsdfNode *principled = graph-&gt;create_node&lt;PrincipledBsdfNode&gt;(); switch (b_principled_node.distribution()) &#123;+ case BL::ShaderNodeBsdfPrincipled::distribution_BECKMANN:+ principled-&gt;set_distribution(CLOSURE_BSDF_MICROFACET_BECKMANN_GLASS_ID);+ break; case BL::ShaderNodeBsdfPrincipled::distribution_GGX: principled-&gt;set_distribution(CLOSURE_BSDF_MICROFACET_GGX_GLASS_ID); break; case BL::ShaderNodeBsdfPrincipled::distribution_MULTI_GGX: principled-&gt;set_distribution(CLOSURE_BSDF_MICROFACET_MULTI_GGX_GLASS_ID); break; &#125; 前期学习阶段中使用到的阅读资料和学到的新知识点Cycles官方开发文档 https://www.cycles-renderer.org/development/ https://wiki.blender.org/wiki/Source/Render/Cycles Next Event Estimation（NEE） 在查看Blender源码的过程中发现了一个DEVICE_KERNEL_INTEGRATOR_SHADE_SURFACE_MNEE，查询后认为MNEE指的应该是Manifold Next Event Estimation，这是一种可以正确的渲染焦散（caustic）的路径追踪方式。 MNEE论文：https://dl.acm.org/doi/10.5555/2858834.2858844 相关讨论：https://www.zhihu.com/question/322343601 其中，NEE是Next Event Estimation的缩写，指的是次事件估计。次事件估计是一种多重重要性采样的方法，简而言之就是对于每次bounce，直接光照通过光源采样得到，间接光照通过BSDF采样得到，并且最后通过多重重要性采样结合起来。 HIPROCm平台是平行于CUDA的概念，是AMD的软件平台，用于A卡上面加速GPU计算，在源码级别支持CUDA程序。而HIP是在A卡上使用的编程模型，对标CUDA编程模型。HIP几乎是克隆CUDA，大多数情况下稍加修改就能转换，并且可以在N卡上运行。 参考资料：https://blog.csdn.net/chongbin007/article/details/124043701 clang-fromatclang-fromat是一种代码风格统一管理工具，Blender用其进行代码的风格统一和规范，所谓代码风格指的是：修饰符偏移，括号对齐，宏定义对齐等格式上的规范。 参考资料：https://blog.csdn.net/weixin_43717839/article/details/129382657 Open Shading Language（OSL）OSL是一种语法类似C语言的开放式着色语言，在blender中可以用OSL实现自己创建shading node。在渲染时.osl文件被编译为用于渲染的.oso文件，大多数支持OSL着色器的渲染引擎都附带OSL编译器。参考资料： https://docs.blender.org/manual/en/latest/render/shader_nodes/osl.html https://github.com/AcademySoftwareFoundation/OpenShadingLanguage/blob/main/src/doc/osl-languagespec.pdf https://juejin.cn/post/7147477548220776484 OptiXOpitX和Cuda都是NVidia的渲染框架，OptiX是专为光线追踪设计的，相比与Cuda在渲染更复杂的场景或者材质时可以提供更快的渲染时间。另外，目前在Blender中要使用OSL编程着色模型并且使用GPU渲染的话，似乎只支持OptiX不支持Cuda（截至2023.12.21，Blender4.0）。 参考资料：https://zhuanlan.zhihu.com/p/648965721 Cycles Kernel Language https://wiki.blender.org/wiki/Source/Render/Cycles/KernelLanguage Wavefront Path Tracing:Blender源码中，一种为了解决GPU编程时Kernel函数过大遇到的问题，把一个很大的Kernel拆分成很多小的Kernel的技术。 参考资料：https://www.cnblogs.com/Heskey0/p/15973546.html SIMDSIMD(Single Instruction Multiple Data)即单指令流多数据流，是一种采用一个控制器来控制多个处理器，同时对一组数据（又称“数据向量”）中的每一个分别执行相同的操作从而实现空间上的并行性的技术。简单来说就是一个指令能够同时处理多个数据。 参考资料：https://zhuanlan.zhihu.com/p/55327037 Open Shading Language 教程https://github.com/AcademySoftwareFoundation/OpenShadingLanguage/blob/main/src/doc/osl-languagespec.pdf 遇到的其他问题和尝试的其他方案 一开始不确定重编译Blender会不会遇到其他的问题，试图直接使用OSL模式渲染，就是在osl脚本里面调用generalized_schlick_bsdf，但是发现Blender对OSL的支持并不完备，使用GPU渲染只能选择OptiX框架，当时在OSL模式下无法渲染我们的材质球，或许是因为里面节点太多了，显示的报错是： 1Error: Requested OSL group data size (6456) is greater than the maximum supported with OptiX (2048) 之后尝试的解决方案是把用shader graph做的节点分模块改写为OSL，再进行渲染，这样的好处是可以通过OptiX编译限制，并且Shader Graph更简洁，缺点是不利于美术人员后续对材质继续修改。但是试验后发现，虽然这样改写后可以渲染，但是Blender4.0使用OptiX渲染SSS的效果是错误的，不能直接使用。 后面又考虑了把Diffuse（包括SSS）和Specular分开渲染再合起来，后面通过实践和思考证明这样行不通，一起渲染时，Specular部分的间接光照会带上Diffuse的颜色并且较亮，而分开渲染时Specular的间接光照则是纯黑白的，且比较暗。分开渲染是行不通的，因此综上所述，只能走重编译的道路。 Blender3.6到4.0升级遇到的Principled Bsdf节点变化以及自动转换的评估：3.6 Base Color 和Subsurface两个颜色输入，Subsurface是浮点数输入。4.0 只有一个Base Color，自动添加了Mix Color节点，混合之前的两个输入作为Base Color的输入，该节点混合的Factor为原来的Subsurface输入（Clamp Factor）。 Roughness和Normal连接不变。 3.6的Subsurface除了作为mix factor还会连接在4.0的Subsurface模块的Scale输入上。 3.6的Specular输入在4.0连接在Specular模块的IOR Level上。 源码中IOR的描述： 1234.description( &quot;Adjustment to the IOR to increase or decrease specular intensity &quot; &quot;(0.5 means no adjustment, 0 removes all reflections, 1 doubles them at normal &quot; &quot;incidence)&quot;); 自动转换后Specular的渲染会有一个很小的亮度差异，但我认为不影响最终效果。但是在测试的过程中发现Blender4.0的SSS效果和之前有很大的差异，但是不能判断该差异是变好了还是变坏了，需要美术人员测试决定。","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Blender","slug":"Blender","permalink":"https://yaelcassini.github.io/tags/Blender/"},{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Monte Carlo","slug":"Monte-Carlo","permalink":"https://yaelcassini.github.io/tags/Monte-Carlo/"},{"name":"Materials","slug":"Materials","permalink":"https://yaelcassini.github.io/tags/Materials/"},{"name":"BSDF","slug":"BSDF","permalink":"https://yaelcassini.github.io/tags/BSDF/"}]},{"title":"Quaternions四元数学习笔记（待补充","slug":"Quaternions","date":"2023-10-12T06:32:14.000Z","updated":"2023-10-24T08:32:10.515Z","comments":true,"path":"2023/10/12/Quaternions/","link":"","permalink":"https://yaelcassini.github.io/2023/10/12/Quaternions/","excerpt":"","text":"参考资料： https://www.bilibili.com/video/BV1fx41187tZ https://www.bilibili.com/video/BV1SW411y7W1 万向结死锁问题（Gimbal Lock）万向结死锁问题指的是，在使用Euler欧拉角进行旋转的表达时，由于沿着中间轴旋转90度导致的自由度丢失问题。我们在使用欧拉角描述旋转时，x,y,z三个轴互相垂直，以物体本身的坐标系来看，绕某一个轴旋转会导致顺序更靠前的轴旋转，但是不会导致顺序更靠前的轴旋转，可以使用万向结模型来思考这个问题，从外到内依次是xyz，当转动最外圈时，里面两个轴向都会跟着转动。因此，一旦沿y轴旋转了90度，就会导致x轴和z轴完全重合，旋转丧失了一个自由度。 球极投影（Stereographic Projection）球极投影是一种","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Quaternions","slug":"Quaternions","permalink":"https://yaelcassini.github.io/tags/Quaternions/"},{"name":"Math","slug":"Math","permalink":"https://yaelcassini.github.io/tags/Math/"}]},{"title":"Blender插件开发相关知识（待补充","slug":"Blender-Plugins","date":"2023-10-11T08:28:04.000Z","updated":"2024-01-04T06:57:21.210Z","comments":true,"path":"2023/10/11/Blender-Plugins/","link":"","permalink":"https://yaelcassini.github.io/2023/10/11/Blender-Plugins/","excerpt":"","text":"从去年七月接收公司的Blender插件至今也有一年多的时间了，期间断断续续地进行了很多Blender工具的开发，用于制作本科毕业的Demo以及满足流程中美术工作人员的需求，工具也进行了很多次迭代，但是最近在满足新的需求时，发现由于学习时主要是面向尽快投入使用的，自己在工具开发的基础仍然有些薄弱，因此准备再反刍学习一下基础的一些概念，开一个新帖在这里记录一下。(其实是因为当初准备学习的时候没有任何实践看不懂理论orz)参考： https://zhuanlan.zhihu.com/p/413506846 https://zhuanlan.zhihu.com/p/418293645 一、 bl_info 插件信息，即在Blender加载插件界面显示的信息。 register 启用插件时会执行的函数 unregister 取消启用时会执行的函数 在Blender环境下安装需要的python包到Blender Python 需要的包：numpy-quaternion1234567891011121314import subprocessimport sysimport os# 2. path to python.exepython_exe = os.path.join(sys.prefix,&#x27;bin&#x27;, &#x27;python.exe&#x27;)# 3. upgrade pipsubprocess.call([python_exe, &quot;-m&quot;, &quot;ensurepip&quot;])subprocess.call([python_exe, &quot;-m&quot;, &quot;pip&quot;, &quot;install&quot;, &quot;--upgrade&quot;, &quot;pip&quot;])# 4. install required packagessubprocess.call([python_exe, &quot;-m&quot;, &quot;pip&quot;, &quot;install&quot;, &quot;package_name&quot;])#注：若没有换pip源可将此句改为#subprocess.call([python_exe, &quot;-m&quot;, &quot;pip&quot;, &quot;install&quot;, &quot;package_name&quot;, &quot;-i&quot;, &quot;https://pypi.tuna.tsinghua.edu.cn/simple&quot;])","categories":[{"name":"Tool Development","slug":"Tool-Development","permalink":"https://yaelcassini.github.io/categories/Tool-Development/"}],"tags":[{"name":"Blender","slug":"Blender","permalink":"https://yaelcassini.github.io/tags/Blender/"},{"name":"Plugins","slug":"Plugins","permalink":"https://yaelcassini.github.io/tags/Plugins/"}]},{"title":"Python Numpy中的常见用法学习","slug":"Python-Useful-Function","date":"2023-09-20T08:37:47.000Z","updated":"2024-01-04T06:55:55.290Z","comments":true,"path":"2023/09/20/Python-Useful-Function/","link":"","permalink":"https://yaelcassini.github.io/2023/09/20/Python-Useful-Function/","excerpt":"","text":"参考： https://zhuanlan.zhihu.com/p/562082459 Python中的特殊索引方式以a = [1,2,3,4,5,6,7,8]为例 [- n]，倒着数第n个元素 [-1]，最后一个元素 同样的[-2]表示倒数第二个元素。 [n : m]，从第n项到第m-1项（前闭后开） [:-1]，从第一项到倒数第二项 [:5]，从第1个到第5个(idx从0开始)元素。 [2:5]，从第3项到第5项元素。 [n : m : k]，从第n项开始取，每隔k个取一项，截止到第m-1项（前闭后开），当k为正的时候起始索引应该小于结束索引；当k为负的时候起始索引应该大于结束索引，因为在倒序来看，首先是索引值大的被取到，然后才是索引值小的。 [::-1]，全列表倒序 [4::-1]，从第5项倒序取到第0项 逗号表示维度的分割线 [n:m, j:k, g:h]，第0维从n到m，第1维从j到k，第2维从g到h（均为前闭后开） [:,:,0]： 前两个维度全选，最后一个维度只取0号索引。 […,-1]：…省略维度，表示前面所有维度 […,::-1]： 对最后一个维度进行逆序。 [:,::-1,:]：第二个维度逆序。 Tensor交换维度transpose()可以交换tensor的任意两个维度，但是该函数一次只有两个参数，即一次只能交换两个维度。 123import torchx = torch.randn(8, 6, 5, 4)y = x.transpose(1,2) # 交换第二与第三维度 permute()该函数可以随意交换任意维度，并且可以重新排列整合维度 123import torchx = torch.randn(8, 6, 5, 4)y = x.permute(3,0,2,1) Numpy交换维度transpose()12import numpy as npimg = np.transpose(img, (1, 2, 0)) Numpy挤出维度123456789101112x = np.arange(8).reshape(2, 4) # 添加第0维,输出shape -&gt; (1, 2, 4)x1 = x[np.newaxis, :]x1 = x[np.newaxis, ...]x1 = x[None, :]x1 = x[None, ...]print(x1.shape) # 添加第1维, 输出shape -&gt; (2, 1, 4)x2 = np.expand_dims(x, axis=1)print(x2.shape)","categories":[{"name":"Others","slug":"Others","permalink":"https://yaelcassini.github.io/categories/Others/"}],"tags":[{"name":"Pytroch","slug":"Pytroch","permalink":"https://yaelcassini.github.io/tags/Pytroch/"},{"name":"Python","slug":"Python","permalink":"https://yaelcassini.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://yaelcassini.github.io/tags/Numpy/"}]},{"title":"Vue.js学习及实践笔记","slug":"Vue-js-Learning","date":"2023-09-14T11:59:50.000Z","updated":"2023-09-21T06:34:05.251Z","comments":true,"path":"2023/09/14/Vue-js-Learning/","link":"","permalink":"https://yaelcassini.github.io/2023/09/14/Vue-js-Learning/","excerpt":"学校社团有做网站的计划，之前刚好接触过一丢丢前端，遂开始摸鱼。","text":"学校社团有做网站的计划，之前刚好接触过一丢丢前端，遂开始摸鱼。 参考资料： https://zhuanlan.zhihu.com/p/349318513 https://cn.vuejs.org/guide/quick-start.html https://element.eleme.cn/#/zh-CN/component/installation https://blog.csdn.net/weixin_46591962/article/details/109145467 首先在Node.js官网安装Node.js: https://nodejs.org/en 安装后新建路径，在cmd分别运行： npm create vue@latestcd npm installnpm run dev测试没有问题之后Ctrl+C退出。npm install -g vue-clinpm install webpack -gnpm install element-ui -Snpm install vue-router vue-resource –Snpm install moment -Snpm run dev","categories":[{"name":"Front-end","slug":"Front-end","permalink":"https://yaelcassini.github.io/categories/Front-end/"}],"tags":[{"name":"Vue.js","slug":"Vue-js","permalink":"https://yaelcassini.github.io/tags/Vue-js/"},{"name":"Element-UI","slug":"Element-UI","permalink":"https://yaelcassini.github.io/tags/Element-UI/"}]},{"title":"GPU 显存分析(待补充)","slug":"GPU-Memory-Analysis","date":"2023-09-05T06:42:16.000Z","updated":"2024-01-05T09:22:47.413Z","comments":true,"path":"2023/09/05/GPU-Memory-Analysis/","link":"","permalink":"https://yaelcassini.github.io/2023/09/05/GPU-Memory-Analysis/","excerpt":"前情提要：在做Relighting项目的时候，每次训练图像分辨率增大到512就会报错，显示无法分配显存，但是控制台报错显示的剩余显存是完全足够的，为了训练更高分辨率的Ground Truth图像，不得已开始学习更加细致的GPU显存分析。","text":"前情提要：在做Relighting项目的时候，每次训练图像分辨率增大到512就会报错，显示无法分配显存，但是控制台报错显示的剩余显存是完全足够的，为了训练更高分辨率的Ground Truth图像，不得已开始学习更加细致的GPU显存分析。 参考资料： https://zhuanlan.zhihu.com/p/424512257 Pytorch官方的profiler教程：https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html 线上Profile可视化：edge:&#x2F;&#x2F;tracing&#x2F; 一. 使用Torch内置函数而不是Nvidia-smi在对GPU占用情况进行分析时，通常会使用Nvidia官方提供的控制台命令：Nvidia-smi。但是对于深度学习来说，Pytorch有自己的GPU显存分配机制，Pytorch的机制是使用缓存分配器来管理缓存分配的(因为这样速度快)，但是在缓存分配器的机制下, 一个Tensor就算被释放了，进程也不会把空闲出来的显存还给GPU，而是等待下一个Tensor来填入这一片被释放的空间(即只要一个Tensor对象在后续不会再被使用，那么PyTorch就会自动回收该Tensor所占用的显存，并以缓冲区的形式继续占用显存，所以在nvidia-smi&#x2F;gpustat中看到的显存并没有减少)。因此使用Nvidia-smi并不能准确地实时查看GPU状态，需要使用Pytorch的内置函数： torch.cuda.memory_allocated() torch.cuda.memory_reserved() 或者 torch.cuda.memory_cached() torch.cuda.memory_summary()需要注意的是，上面两个函数输出的结果都是以Bytes为单位的，如果要以MB或者GB为单位需要自己进行换算。 二. Pytorch的显存层级分配：在PyTorch中，显存是按页为单位进行分配的，这可能是CUDA设备的限制。就算我们只想申请4字节的显存，pytorch也会为我们分配512字节或者1024字节的空间。即就算我们只想申请4字节的显存，pytorch也会先向CUDA设备申请2MB的显存到自己的cache区中，然后pytorch再为我们分配512字节或者1024字节的空间。这个在使用torch.cuda.memory_allocated()的时候可以看出来512字节；用torch.cuda.memory_cached()可以看出向CUDA申请的2MB。Pytorch分配逻辑： pytorch中的reserved_memory以block的形式存在。 一个allocation的显存被释放后，他所在的block可以被重新被allocate. 分配器尝试寻找能满足requested size的最小cached block，如果这个block 的大小大于requested size，那么这个block可以被split. 如果没有block了，那么分配器就会调用cudaMalloc向CUDA设备申请显存。 如果cudaMalloc失败了，分配器会先尝试释放掉一个足够大的，且没有被split的cached block，并重新尝试allocate。 大于1MB的allocation和小于等于1MB的allocation会被存储在不同的pool中。小的请求会放进2MB的buffer里，大的请求会先尝试使用最小的可用free block，或者用cudaMalloc申请一个新的block。 为了减小碎片化，在所有可用block都没有充足的大小的时候，1MB到10MB的allocation会使allocator申请一个20MB的block，并在上面进行split；为了进一步减小碎片化，大于200MB的块则不能够被split。大于200MB的超大cached blocks仍可满足小于20MB的请求。 三. 变量拷贝到显存上时使用.to(device)和cuda()的区别在实践中我发现对于一个相同的Tensor，使用to.(device)和cuda()两种方式将其移动的GPU上，造成的显存占用略有不同。dbq我是蠢比，只用x.to(device)当然是不行的，因为之后没有用到过这个变量，Pytorch会自动将其释放，但是改成x&#x3D;x.to(device)就没有问题了。 四. 尝试使用Nsight进行可视化分析。首先尝试控制台调用nsys，参考该帖中的指令：https://dev-discuss.pytorch.org/t/using-nsight-systems-to-profile-gpu-workload/59：nsys profile -w true -t cuda,nvtx,osrt,cudnn,cublas -s cpu --capture-range=cudaProfilerApi --stop-on-range-end=true --cudabacktrace=true -x true -o my_profile python main.py后面根据我本机上的报错更换了指令， unrecognised option ‘–cudabacktrace&#x3D;true’， 删除该命令行参数 –sample&#x3D;cpu requires administrative privileges.， 以管理员方式打开vscode Illegal –trace argument ‘osrt’, Possible –trace values are one or more of ‘cuda’, ‘nvtx’, ‘opengl’, ‘opengl-annotations’, ‘vulkan’, ‘vulkan-annotations’, ‘dx11’, ‘dx11-annotations’, ‘dx12’, ‘dx12-annotations’, ‘wddm’ or ‘none’， 把不在possible value里面的都删除。 Program not found: python，这个不知道是为什么，猜测与anaconda封装不同的python环境有关，因此增加python的绝对路径进行调用。所以最后的控制台指令变为：nsys profile -w true -t cuda,nvtx -s cpu --capture-range=cudaProfilerApi --stop-on-range-end=true -x true -o my_profile C:\\Users\\face\\anaconda3\\envs\\py39\\python.exe train_rnr_analysis.py 五. 网络映射盘的管理员权限问题：但是又遇到了新的问题：在win10环境下，管理员权限下无法正确访问到网络映射盘。原因可能是因为：win10 的uac隔离更严格，普通用户权限创建的网络映射盘，管理员权限是无权访问的。请教同学之后发现该服务器windows启动默认打开的是名为face的账户，真正的管理员用户Administrator是默认禁用的，可以在计算机管理取消禁用该用户后重新挂载网络映射盘，也可以管理员权限开启控制台，输入net use Y: \\\\192.168.16.73\\exchange命令进行重新映射。现在nsys终于跑起来了（orz。 六. The application terminated before the collection started.遇到了新的问题：程序正常运行，但运行结束后输出：The application terminated before the collection started. No report was generated.决定先用https://dev-discuss.pytorch.org/t/using-nsight-systems-to-profile-gpu-workload/59中的示例来解决这个问题，再到训练程序上跑。 七. 换用nsight system gui用nsight compute gui一直出错，最后改用nsight systems gui，版本为2022.1.3，运行命令即为简单的python train_rnr.py，在服务器上本地运行nsight。唉但是发现使用Nsight的问题是，在timeline上展示出的调用函数都太过底层了，因此我只能把迭代次数和timeline上的重复单元对应起来，却不能很好的进行更细致的分析。但是使用Nsight可以可视化显存占用的变化曲线，可以比较直观的感受到显存的占用情况。 八. 编写memory进行模块化显存占用输出最后我使用Nsight进行整体的显存占用变化可视化，用自己编写的memory类调用pytorch的内置函数输出分析步骤级的GPU占用，唯一的问题是：假如某一个步骤中GPU最大占用了4个G，但是最后释放完成后只占用了2个G，并且最大占用没有大到改变到pytorch的max_allocated，则不能准确得到这个最大占用的4个G，想知道这个信息只能将该步骤进一步切分分析。Memory类代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import torch# torch.cuda.empty_cache()class MemoryInfoGPU: def __init__(self, device_idx = 0): torch.cuda.empty_cache() self.device = device_idx self.last_allocated = 0 self.last_cached = 0 self.last_max_allocated = 0 self.last_max_cached = 0 self.now_allocated = 0 self.now_cached = 0 self.max_allocated = 0 self.max_cached = 0 self.queryGPU() def queryGPU(self): self.last_allocated = self.now_allocated self.last_cached = self.now_cached self.last_max_allocated = self.max_allocated self.last_max_cached = self.max_cached self.now_allocated = torch.cuda.memory_allocated(device=self.device) self.now_cached = torch.cuda.memory_reserved(device=self.device) self.max_allocated = torch.cuda.max_memory_allocated(device=self.device) self.max_cached = torch.cuda.max_memory_cached(device=self.device) def printMemoryInfo(self): print(str(self.device) + &quot; GPU Memory Info: &quot;) print(&quot;\\tNow Allocated:\\t&quot;, self.now_allocated/1024.0/1024.0, &quot; MB&quot;, &quot;\\tNow Cached:\\t&quot;, self.now_cached/1024.0/1024.0, &quot; MB&quot;) print(&quot;\\tMax Allocated:\\t&quot;, self.max_allocated/1024/1024.0, &quot; MB&quot;, &quot;\\tMax Cached:\\t&quot;, self.max_cached/1024.0/1024.0, &quot; MB&quot;) return def printConsume(self, message): print(message) print(&quot;Consume:\\t&quot;, (self.now_allocated - self.last_allocated)/1024.0/1024.0, &quot; MB&quot;) if(self.max_allocated &gt; self.last_max_allocated): print(&quot;But need:\\t&quot;, (self.max_allocated - self.last_allocated)/1024.0/1024.0, &quot; MB&quot;) # 如果之前的最大分配非常大，这次没有超过，是不能得出准确的本进程最大分配的。 def _before(self): self.queryGPU() def _after(self, message = &quot;&quot;): self.queryGPU() self.printMemoryInfo() self.printConsume(message)","categories":[{"name":"Relighting Project","slug":"Relighting-Project","permalink":"https://yaelcassini.github.io/categories/Relighting-Project/"}],"tags":[{"name":"GPU","slug":"GPU","permalink":"https://yaelcassini.github.io/tags/GPU/"},{"name":"Pytroch","slug":"Pytroch","permalink":"https://yaelcassini.github.io/tags/Pytroch/"},{"name":"Machine Learing","slug":"Machine-Learing","permalink":"https://yaelcassini.github.io/tags/Machine-Learing/"},{"name":"Nerual Rendering","slug":"Nerual-Rendering","permalink":"https://yaelcassini.github.io/tags/Nerual-Rendering/"}]},{"title":"Neural Rendering相关学习笔记(待补充)","slug":"Neural-Rendering-Notes","date":"2023-07-26T10:20:33.000Z","updated":"2024-01-22T13:43:49.366Z","comments":true,"path":"2023/07/26/Neural-Rendering-Notes/","link":"","permalink":"https://yaelcassini.github.io/2023/07/26/Neural-Rendering-Notes/","excerpt":"记录一些关于Neural Rendering的学习笔记，可能有点乱orz。","text":"记录一些关于Neural Rendering的学习笔记，可能有点乱orz。 Neural Rendering其他参考： https://www.youtube.com/watch?v=otly9jcZ0Jg https://www.youtube.com/watch?v=aboFl5ozImM ICLR 2023：《Light Sampling Field and BRDF Representation for Physically-based Neural Rendering》 https://www.researchgate.net/publication/369974931_Light_Sampling_Field_and_BRDF_Representation_for_Physically-based_Neural_Rendering https://www.youtube.com/watch?v=qpIgS11DlJE https://docs.unrealengine.com/4.26/en-US/RenderingAndGraphics/Lightmass/VolumetricLightmaps/#:~:text=The%20Volumetric%20Lightmap%20allows%20previewing%20of%20objects%20with,the%20Volumetric%20Lightmap%20until%20lighting%20is%20built%20again. NeRF： https://www.matthewtancik.com/nerf NeRV： https://pratulsrinivasan.github.io/nerv/ NeRD： https://pratulsrinivasan.github.io/nerv/ State of Art of Neural Rendering https://arxiv.org/abs/2004.03805 2023.7.26，终于通读了一遍大名鼎鼎的Nerf，然后准备看一看源码。 Paper: https://dl.acm.org/doi/10.1145/3503250 Code: 参考：https://zhuanlan.zhihu.com/p/630948914 环境配置： 删除新建的nerf环境：conda remove -n nerf –all 新建nerf环境：conda create -n nerf python&#x3D;3.7 conda install tensorflow-gpu&#x3D;&#x3D;1.15 conda install numpy conda install matplotlib conda install imageio pip install imageio-ffmpeg conda install configargparse 遇到的问题： vscode不能使用 conda activate： https://blog.csdn.net/weixin_45646006/article/details/115066805 tensorflow 和 tensorflow-estimator版本不一致 conda install tensorflow-estimator&#x3D;&#x3D;1.15.1 不要uninstall， uninstall会把tensorflow也uninstall conda install tensorboard&#x3D;&#x3D;1.15.0 其他需要的数据处理 下载bash中需要的data，并放到对应的文件夹。 logs文件夹下新建summaries文件夹 在NeRF（Neural Radiance Fields）出现之前，辐射度场（Radiance Fields）的概念已经在计算机图形学中被广泛应用。以下是一些主要的方法： 光线追踪（Ray Tracing）：这是一种计算机图形学技术，用于生成图像，通过追踪光线从视点出发并穿过每个像素在2D视图平面上的路径来工作。光线追踪可以用于计算光线与物体的交互，包括反射、折射和散射，这使得它能够生成具有复杂光照和阴影的高质量图像。 光线铸造（Ray Casting）：这是一种更简单的技术，它只计算光线与物体的第一次交互，而不是追踪光线的完整路径。光线铸造通常用于生成硬阴影和简单的反射，但不能处理更复杂的光照效果。 体渲染（Volume Rendering）：这是一种用于渲染3D体数据的技术，例如医学或科学图像。体渲染通过在每个像素上积分一条线（或光线）通过体数据的贡献来工作。这使得它能够生成半透明的效果，例如雾或云。 光场渲染（Light Field Rendering）：光场是一个四维函数，描述了一个场景中所有可能的光线。光场渲染使用预先计算的光场数据来生成图像，这使得它能够快速地从任何视点和方向渲染场景。 这些技术都可以被视为辐射度场方法，因为它们都涉及到在3D空间中的某些位置和方向计算光的辐射度。然而，它们通常需要显式的3D模型或大量的预计算数据，而NeRF等新的方法则使用神经网络来隐式地表示辐射度场，从而能够处理更复杂的场景和光照条件。","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Neural Rendering","slug":"Computer-Graphics/Neural-Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Neural-Rendering/"}],"tags":[{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Neural Rendering","slug":"Neural-Rendering","permalink":"https://yaelcassini.github.io/tags/Neural-Rendering/"},{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","permalink":"https://yaelcassini.github.io/tags/Artificial-Intelligence/"}]},{"title":"Games101 课程学习实践笔记(待补充)","slug":"Games101-Notes","date":"2023-07-20T06:45:04.000Z","updated":"2024-01-05T09:21:33.989Z","comments":true,"path":"2023/07/20/Games101-Notes/","link":"","permalink":"https://yaelcassini.github.io/2023/07/20/Games101-Notes/","excerpt":"Games101做作业的过程中遇到的问题及解决。","text":"Games101做作业的过程中遇到的问题及解决。 virual box 共享文件夹设置： https://blog.csdn.net/jumpingpig/article/details/104109395 二维三角形内部判定: https://blog.csdn.net/KimHyunA4minute/article/details/40079819 Howework2: Super Sample部分，只对Depth Buffer进行细分会导致出现两个三角形覆盖交界处出现黑边，应该吧frame buffer也进行细分，输出时直接下采样。 Homework3： view_pos插值出了问题，view_pos语义应该是在view space的三角形三个点的坐标，但我感觉这个用什么坐标只要统一就可以，比如如果要传入world space就灯光、相机、mesh都传入world space的坐标，或者都传入view space的坐标。思考：Model matrix的变换是应该体现出来的，但是View Matrix的变换是否收到相机横竖比例不同的影响？（不影响，因为View Matrix里面只有内参，都是刚性变换。） 灯光衰减系数要使用距离的平方，用距离就不太行，太亮了。 Texture采样的时候因为加了1.0&#x2F;w会溢出，修改Texture类函数，加了：u &#x3D; (u + width)%width; v同理。 这里我觉得网上的很多代码选择采样hmap后normalize很没有道理，看上去这个hmap更像是一张normal map，所以我取了采样后的z值作为高度。 还有一个不明白的点：为什么注释里面要把kn和kh都乘到dU上面，在我看来算dUdV的时候乘kh，算displacement顶点位移的时候乘kn比较合理，但是不乘效果不佳，跟题目设置有关系。 在写作业的过程中重新学习推导了TBN矩阵，并学习Displacement原理。 Displacement造成的顶点坐标位移应该是沿着插值得到的法线方向，这里我取的值仍然是z分量，然后在bump shader中计算得到的新法向其实是顶点位移造成的法线变换，所以应该先变换顶点坐标，再赋予新的法向值，这也解释了前面我认为只乘kh是不对的，因为这个法向是通过坐标位移得到的，坐标位移的过程中要乘kn。 在Displacement Shader为了和示例靠近把diffuse计算的*0.5+0.5去掉了。 用Z值的Displacement效果不对，改成norm就对了，不准备深究了，因为真正的Displacement Texture应该在一开始mvp之前就参与到修改顶点坐标中？起码应该在view space加入计算。 还有一个易错点：采样texture的时候先v再u。 image.at采样得到的数据结构里面是int，直接统一用auto会出问题。 悲惨的de了很久bug，发现是加权权重搞错了，左边的距离应该作为右边的权重。","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"}],"tags":[{"name":"Games101","slug":"Games101","permalink":"https://yaelcassini.github.io/tags/Games101/"},{"name":"Notes","slug":"Notes","permalink":"https://yaelcassini.github.io/tags/Notes/"}]},{"title":"计算机视觉HW3 - Harris角点检测","slug":"Harris-Corner-Detection","date":"2023-06-02T07:42:44.000Z","updated":"2023-09-18T08:07:14.434Z","comments":true,"path":"2023/06/02/Harris-Corner-Detection/","link":"","permalink":"https://yaelcassini.github.io/2023/06/02/Harris-Corner-Detection/","excerpt":"课程名称：计算机视觉实验项目名称：harris角点检测实验日期：2020 年 12 月 16 日","text":"课程名称：计算机视觉实验项目名称：harris角点检测实验日期：2020 年 12 月 16 日 一、实验目的和要求 读入摄像头，回放视频。按一下空格键，则暂停回放，并将当前帧图像做 Harris Corner 检测 ，并将检测的结果叠加在原来图像上。1.需要自己写代码实现 Harris Corner 检测算法，不能直接调用OpenCV 里面与 Harris 角点检测相关的函数；2.显示中间的处理结果及最终的检测结果，包括最大特征值图、最小特征值图、R 图 、原图上叠加检测结果等，并将这些中间结果都输出保存为图像文件。 二、实验原理本实验中主要使用了 Harris 角点检测算法(Harris Corner Detection)。1）算法简介匹配问题 Harris角点检测是Chris Harris和Mike Stephens在1988年提出的。主要用于运动图像的追踪。当时的普遍想法是利用边缘进行追踪，但边缘匹配很难达到预期的效果。即使是当时最优秀的边缘检测算子Canny算子，它的边缘检测也依赖于阈值的选取。所以Harris等人放弃了匹配边缘，转而寻找一些特殊的点来匹配，这些点是边缘线段的连接点，它们表征了图像的结构，代表了图像局部的特征。 什么是角点 直观的说就是图像轮廓的连接点。不管视角怎么变换，这些点依然存在，是稳定的；它们与领域的点差别比较大。所以角点是一种优良的特征点。 角点往往是两条边缘的交点，它是两条边缘方向变换的一种表示，因此其两个方向的梯度变换通常都比较大并且容易检测到。 Harris角点检测是通过数学计算在图像上发现角点特征的一种算法，而且其具有旋转不变性的特质。 OpenCV中的Shi-Tomasi角点检测就是基于Harris角点检测改进算法。 2）基本原理人们通常通过在一个小的窗口区域内观察点的灰度值大小来识别角点，如果往任何方向移动窗口都会引起比较大的灰度变换那么往往这就是我们要找的角点。角点是一幅图像上最明显与重要的特征，对于一阶导数而言，角点在各个方向的变化都比较大，而边缘区域在只是某一方向有明显变化。一个直观的图示如下： 3） 数学原理基本数学公式如下：$$E(u,v)&#x3D;\\sum _{x,y} w(x,y)[I(x+u,y+v)-I(x,y)]^2$$ 其中$I(x, y)$表示像素灰度值强度，范围为0～255，$W(x, y)$表示移动窗口窗函数，可以是加权函数，也可以是高斯函数。 对 $f(x,y)$ 进行二维泰勒展开： 略去二阶及更高阶项，上式可近似为：$$f(x+u,y+v) \\approx f(x,y)+uf_x(x,y)+vf_y(x,y)$$于是对于$E(u,v)$，我们有以下的推导： 对于较小的位移，$E(u,v)$ 可以近似为：$$E(u,v) \\simeq \\begin{bmatrix} u &amp; v \\end{bmatrix} M\\begin{bmatrix} u \\v \\end{bmatrix}$$ 其中M为：$$M&#x3D;\\sum_{x,y}w(x,y) \\begin{bmatrix} I_x^2 &amp; I_xI_y \\I_xI_y &amp; I_y^2 \\end{bmatrix}$$ 二次项本质上可以看成一个椭圆函数，矩阵M有特征值$\\lambda_1 ,\\lambda_2$，如下图，根据 $\\lambda_1 ,\\lambda_2$ 的值我们可以把其分为三类： λ1，λ2都很小且近似，E在所有方向接近于常数； λ1&gt;&gt;λ2,或者λ2&gt;&gt;λ1, E将在某一方向上较大，其他方向较小； λ1，λ2都很大且近似，E将在所有方向上都较大； 如下图，上述三种情况，分别对应图像中的： 变换不大，较为平缓的部分 边缘 角点 最后我们通过计算角点响应值R来判断其属于哪个区间，也就是属于平缓区，边缘，还是角点：$$R&#x3D;detM - k (trace M)^2$$ $$其中，det M &#x3D; \\lambda_1 \\cdot \\lambda_2 trace M&#x3D;\\lambda_1 + \\lambda_2$$ 其中k一般为常数，一半取在0.04~0.06。 4）算法详细步骤 计算图像X方向与Y方向的梯度也就是一阶偏导数： $I_x , I_y$ $$I_x&#x3D;G_{\\sigma}^x * I I_y&#x3D;G_{\\sigma}^y * I$$ 根据第一步的结果计算每个像素点的梯度平方： $I_x^2,I_y^2,I_xI_y$ $$I_x^2&#x3D;I_x \\cdot I_x I_y^2&#x3D;I_y \\cdot I_y I_xI_y&#x3D;I_x \\cdot I_y$$ 高斯模糊第二步三个值得到Sxx, Syy, Sxy $$S_{xx}&#x3D;G_{\\sigma’}*I_{x}^2 S_{yy}&#x3D;G_{\\sigma’}*I_{y}^2 S_{xy}&#x3D;G_{\\sigma’}*I_x I_y$$ 定义在每个像素点的矩阵H，也就是前面的M矩阵 $$H(x,y)&#x3D;\\begin{bmatrix} S_{xx}(x,y) &amp; S_{xy}(x,y) \\ S_{xy}(x,y) &amp; S_{yy}(x,y) \\end{bmatrix}$$ 计算每个像素的角点响应值R $$R&#x3D;Det(H)-k(Trace(H))^2$$ 设置阈值找出可能点并进行非极大值抑制 三、实验内容和过程分析1）实现从摄像头读入视频并回放，以及根据按键进行不同的操作。读入摄像头，回放视频。按一下空格键，则暂停回放，并将当前帧图像做一次 Harris Corner 检测 ，并将检测的结果叠加在原来图像上。 123456789101112131415161718192021222324252627282930313233343536373839404142434445int main()&#123; VideoCapture capture(0); //打开一个默认的相机 if (!capture.isOpened()) return -1; //检查是否成功打开 bool show = false; //是否有角点检测结果正在展示 while (true) &#123; //从相机连续读取图像 Mat frame; capture &gt;&gt; frame; Mat src = frame.clone(); if (!src.data) return -1; imshow(&quot;video&quot;, src); int c = waitKey(30); //空格键操作 if (c == 32) &#123; if (!show) &#123; //按下空格键后会对当前帧图像做角点检测 string addr_pre=Harris(src, 0.05, 0.001); imshow(&quot;result&quot;, src); imwrite(addr_pre + &quot;Result.png&quot;, src); &#125; else &#123; //如果当前已经有角点检测结果窗口在展示, 则按空格关闭展示窗口 destroyWindow(&quot;corner&quot;); destroyWindow(&quot;max&quot;); destroyWindow(&quot;min&quot;); destroyWindow(&quot;result&quot;); destroyWindow(&quot;R&quot;); &#125; show = !show; &#125; else if (c == &#x27;q&#x27; || c == &#x27;Q&#x27;|| c==27) //按Q/q或者Esc键关闭结果展示窗口 &#123; destroyWindow(&quot;corner&quot;); destroyWindow(&quot;max&quot;); destroyWindow(&quot;min&quot;); destroyWindow(&quot;result&quot;); destroyWindow(&quot;video&quot;); destroyWindow(&quot;R&quot;); return 0; &#125; &#125; return 0;&#125; 2）Harris Corner Detection 计算图像X方向与Y方向的梯度也就是一阶偏导数： $I_x , I_y$ $$I_x&#x3D;G_{\\sigma}^x * I I_y&#x3D;G_{\\sigma}^y * I$$ 根据第一步的结果计算每个像素点的梯度平方： $I_x^2,I_y^2,I_xI_y$ $$I_x^2&#x3D;I_x \\cdot I_x I_y^2&#x3D;I_y \\cdot I_y I_xI_y&#x3D;I_x \\cdot I_y$$ 12345678910111213141516171819202122//转灰度图Mat gray;cvtColor(I, gray, CV_BGR2GRAY);//计算图像X方向与Y方向的一阶偏导Ix、Iy以及Ix^2,Iy^y,IxIyMat IxIx(gray.rows, gray.cols, CV_32FC1);Mat IyIy(gray.rows, gray.cols, CV_32FC1);Mat IxIy(gray.rows, gray.cols, CV_32FC1);//初始化为0 (此部分在报告中省略)//计算偏导数及Ix^2,Iy^y,IxIyfor (int y = 1; y &lt;= I.rows - 2; y++)&#123; for (int x = 1; x &lt;= I.cols - 2; x++)&#123; float ix = (float)gray.at&lt;uchar&gt;(y + 1, x) - (float)gray.at&lt;uchar&gt;(y - 1, x); float iy = (float)gray.at&lt;uchar&gt;(y, x + 1) - (float)gray.at&lt;uchar&gt;(y, x - 1); IxIx.at&lt;float&gt;(y, x) = (float)ix * (float)ix; IyIy.at&lt;float&gt;(y, x) = (float)iy * (float)iy; IxIy.at&lt;float&gt;(y, x) = (float)ix * (float)iy; &#125;&#125; 高斯模糊第二步三个值得到Sxx, Syy, Sxy $$S_{xx}&#x3D;G_{\\sigma’}*I_{x}^2 S_{yy}&#x3D;G_{\\sigma’}*I_{y}^2 S_{xy}&#x3D;G_{\\sigma’}*I_x I_y$$ 123456789//计算图像X方向与Y方向的一阶偏导Ix、Iy以及Ix^2,Iy^2,IxIyMat Sxx(gray.rows, gray.cols, CV_32FC1);Mat Syy(gray.rows, gray.cols, CV_32FC1);Mat Sxy(gray.rows, gray.cols, CV_32FC1);//高斯滤波GaussianBlur(IxIx, Sxx, Size(5, 5), 0, 0);GaussianBlur(IyIy, Syy, Size(5, 5), 0, 0);GaussianBlur(IxIy, Sxy, Size(5, 5), 0, 0); 定义在每个像素点的矩阵H，也就是前面的M矩阵 $$H(x,y)&#x3D;\\begin{bmatrix} S_{xx}(x,y) &amp; S_{xy}(x,y) \\ S_{xy}(x,y) &amp; S_{yy}(x,y) \\end{bmatrix}$$ 计算每个像素的角点响应值R $$R&#x3D;Det(H)-k(Trace(H))^2$$ 1234567891011121314151617181920212223242526272829303132333435363738//R值和最大最小特征值矩阵Mat R(gray.rows, gray.cols, CV_32FC1);Mat Max(gray.rows, gray.cols, CV_32FC1);Mat Min(gray.rows, gray.cols, CV_32FC1);//最大响应值Rmaxfloat maxResponse = 0.0f;//初始化为0 （此部分在此省略）//计算最大最小特征值以及harris响应值Rfor (int y = 0; y &lt;I.rows; y++) &#123; for (int x = 0; x &lt;I.cols; x++) &#123; float aa = 0; float bb = 0; float cc = 0; aa = Sxx.at&lt;float&gt;(y, x); bb = Syy.at&lt;float&gt;(y, x); cc = Sxy.at&lt;float&gt;(y, x); //计算当前像素的harris响应值 float t = (aa * bb - cc * cc) - k * (aa + bb) * (aa + bb); //计算最大最小特征值 float po1 = pow(1.0 * aa - bb, 2); float po2 = 4.0 * cc * cc; float sq = sqrt((double)(po2 + po1)); float max = 0.5 * (aa + bb + sq); float min = 0.5 * (aa + bb - sq); R.at&lt;float&gt;(y, x) = t; Max.at&lt;float&gt;(y, x) = max; Min.at&lt;float&gt;(y, x) = min; //记录最大响应值 if (t &gt; maxResponse) maxResponse = t; &#125;&#125; 设置阈值找出可能点并进行非极大值抑制 12345678910111213Mat localMax; //进行局部非最大值抑制localMaxFilter(R, localMax, max_size);//剔除部分局部极大值Mat Corner=localMax;threshold(localMax, Corner, thres_hold * maxResponse, 255, THRESH_BINARY);//在原始图像上绘制角点检测结果for (int y = 0; y &lt; Corner.rows - 1; y++) for (int x = 0; x &lt; Corner.cols - 1; x++) if (Corner.at&lt;float&gt;(y, x)) circle(I, Point2i(x, y), 2, Scalar(255, 242, 0)); 123456789101112131415161718//非局部极大值抑制void localMaxFilter(Mat&amp; in, Mat&amp; out, int size=3)&#123; Mat dilated; dilate(in, dilated, Mat()); //对输入进行膨胀操作 if (out.empty()) out.create(in.rows, in.cols, in.type()); for (int y = 0; y &lt; in.rows; y++) &#123; for (int x = 0; x &lt; in.cols; x++) &#123; //如果像素点的值和膨胀操作前相同，证明该点为局部极大值点 if (in.at&lt;float&gt;(y, x) == dilated.at&lt;float&gt;(y, x)) out.at&lt;float&gt;(y, x) = in.at&lt;float&gt;(y, x); else out.at&lt;float&gt;(y, x) = 0.0f; &#125; &#125;&#125; 四、实验结果展示1）使用本地图像检测Harris Corner Detection效果 原图 最大特征值图 最小特征值图 响应值R图 角点检测结果 角点检测结果与原图叠加 原图 最大特征值图 最小特征值图 响应值R图 角点检测结果 角点检测结果与原图叠加 五、实验思考和感想​ 通过本次实验，我更加深入地学习和体会了Harris角点检测的算法，在实践的过程中，我发现了很多在学习过程中没有注意到的细节，都需要在实践进行调整。 ​ 在实验初期，调整角点检测的R值阈值给我造成了一定的困扰，对于不同的图像，似乎需要不同的阈值，才能得到较为合理较为优秀的结果，后期，我发现这个阈值由于是一个绝对值，而图像的性质不同会使得R值的范围变化非常大，因此，我将这个阈值设置成为一个函数，在计算图像中每个像素点的R值时，记录下最大的R值，在后续的处理中，以关于这个最大值的一个比例函数，例如K*MaxValue，作为选择角点的阈值，这样处理之后，算法对于不同图像的适应度增强了很多，但由于只获取了最大R值的信息，因此还是不能完全做到自适应，在某些情况下需要对阈值函数进行微调。 ​ 在实验中，我还发现，计算R值和最大最小特征值时，由于结果数据可能溢出八位，因此不能再采用位深度为8的图像格式变量，因此，我将图像深度改为了32位，float类型，才得以储存原始数据。 ​ 由于实验需要要求保存进行角点检测的中间结果，且我在本次试验中实现了可以进行通过空格键在一次程序运行期间进行多次的角点检测（具体操作方式见ReadMe），因此我调用了函数，在每次进行角点检测时，得到系统时间，转化成字符串，作为图像输出文件名前缀，后缀则代表着该图像的属性，如Max代表该图像是最大特征值图，Corner代表该图像是得到的角点检测结果图。","categories":[{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://yaelcassini.github.io/categories/Computer-Vision/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://yaelcassini.github.io/tags/Computer-Vision/"},{"name":"Harris Corner","slug":"Harris-Corner","permalink":"https://yaelcassini.github.io/tags/Harris-Corner/"}]},{"title":"基于GPU的渲染Project - 布料真实感实时渲染","slug":"Cloth-Rendering-Project","date":"2023-05-31T14:42:55.000Z","updated":"2024-01-04T06:56:39.755Z","comments":true,"path":"2023/05/31/Cloth-Rendering-Project/","link":"","permalink":"https://yaelcassini.github.io/2023/05/31/Cloth-Rendering-Project/","excerpt":"课程名称：基于GPU的渲染项目主题名称：布料真实感实时渲染日期：2022 年 1 月 10 日 PS: 当时还比较年轻，有些问题略弱智。","text":"课程名称：基于GPU的渲染项目主题名称：布料真实感实时渲染日期：2022 年 1 月 10 日 PS: 当时还比较年轻，有些问题略弱智。 codehttps://github.com/YaelCassini/Cloth_Real-Time-Rendering videohttps://www.bilibili.com/video/BV175411o7t1/ reporthttps://yaelcassini.github.io/2023/05/31/GPUrendering-Porject/ 〇. Part Zero 基本概述及project组织架构基本概述：​ 本次大程为了实现布料的实时渲染，我的主要思路是使用PBR的渲染方式，通过使用Albedo、Normal Map、Roughness Map等贴图，完成布料的基本着色。 ​ 阴影部分采用ShadowMap算法实现，使用PCF算法完成对阴影锯齿状走样的消除和处理，得到软阴影。 ​ 实验中用到的贴图均为本人使用Substance Painter绘制后烘焙导出。另外为了使工程文件格式统一，我还对模型进行了一些预处理。 ​ 在后文我将对本次大程中的几个重要部分的原理分别阐述。 Project组织架构： 实验环境及用到的库： Visual Studio 2019 GLFW GLAD GLM Assimp stb_image FreeType 请使用 Release x86 生成解决方案和调试。 需要的头文件、lib文件已经打包在项目目录下，并在项目属性配置中用相对路径引用。 需要的dll文件放在项目目录下。 main.cpp为主要源文件，主函数入口在其中，核心的渲染过程也在该源文件中。 Fonts文件夹下是几个字体，字体用于显示Text（比如FPS显示）。 include文件夹是需要的头文件，主要是Glad、GLFW等库的头文件 lib文件夹是用到的库的lib文件 Headers文件夹下是工程中一些模块的头文件，比如Camera模块、Shader模块等等。 Models文件夹下是用到模型文件，编号表示模型内容、所属人物和姿势。比如”body1_1“表示第一个人物的第一个姿势，”cloth1_1“表示第一件衣服的第一个姿势，cloth1-cloth3属于第一个人物，cloth4-cloth6属于第二个人物。 Shaders文件夹下是需要的shader源文件，其中PBRShader是本次项目主要使用的shader，RenderTexture是将ShadowMap展示在窗口使用的shader。 Textures文件夹下是使用的贴图，background为前缀的贴图是背景幕布的贴图。set1文件夹下存放女孩模型使用的贴图，set2文件夹下存放男孩模型使用的贴图，其中，两个body的渲染使用的是一样的贴图。每套贴图共有5张，编号从0到4分别是Albedo、Normal Map、Metallic Map、Roughness Map、AO Map。其中由于没有使用到Metallic和AO贴图，因此有些地方直接将这两张贴图省略了。 Ⅰ. Part One PBR基本原理​ PBR（Physically Based Rendering），指的是基于物理的渲染，更符合物理学规律，看上去更真实。并且由于其与真实的物理性质非常接近，可以直接用物理参数为依据来编写表面材质。由于基于物理的渲染旨在以一种物理上合理的方式模拟光，因此与我们的原始照明算法（如Phong和Blinn-Phong）相比，它通常看起来更真实，并且非常接近实际物理，我们可以根据物理参数编写表面材料，而不必求助于廉价的技巧和调整来使灯光看起来正确。基于物理参数编写材质的一个更大的优点是，无论照明条件如何，这些材质都会看起来正确。​ 满足基于物理渲染的三个条件： 基于微平面（Microfacet）的表面模型 能量守恒 应用基于物理的BRDF 微平面模型 达到微观尺度之后，任何平面都可以用被称为微平面的细小镜面来描绘。 微平面的取向排列的不一致程度，与平面粗糙程度有关。平面越粗糙，微平面排列越混乱。 对于粗糙平面，入射光线更趋向于向完全不同的方向发散，光滑平面上，入射光线大体上趋向于向同一个方向发射。 PBR中一般基于光线向量l和视线向量v的中间向量h与微平面平均取向方向的一致性计算镜面反射。 中间向量计算公式：$h &#x3D; \\frac{l+v}{||l+v||}$ 微平面无法逐像素区分，因此应该假设一个粗糙度参数，并使用统计学方法估算微平面的取向方向。 粗糙度系数取值为0-1之间，可以估算微平面的取向情况。 粗糙度越高，镜面反射轮廓越大，反之轮廓越小但边缘更锐利。 能量守恒 微平面近似法中的能量守恒：出射光线的能量永远不能超过入射光线的能量（发光面除外）。 一束光线碰撞到一个表面时，会分离成一个折射部分和一个反射部分。反射部分不进入平面直接反射，成为镜面光照。折射部分会进入表面并被吸收，成为漫反射光照。 金属表面上所有折射光都会被直接吸收而不会散开，因此金属表面不会显示出漫反射颜色。 折射光与反射光二者是互斥的关系。能量总和永远不会超过入射光线的能量。 反射率方程 反射率方程是PBR中一种渲染方程的特化版本 反射率方程：$L_0(p,\\omega_0) &#x3D; \\int _\\Omega f_r(p,\\omega_i,\\omega_0)L_i(p,\\omega_i)n·\\omega_i d \\omega_i$ $L$是辐射率，用来量化单一方向上发射来的光线的大小和强度 辐射通量$\\Phi$：一个光源输出的能量，以瓦特为单位，可以视为这个光源中包含的所有波长的一个函数。 立体角：三位立体空间中的角度，可以描述为投射到单位球体上的截面大小。 辐射强度：单位球面上，一个光源向每个单位立体角所投放的辐射通量。计算公式： $I&#x3D;\\frac{d\\Phi}{d\\omega}$。 辐射率L：一个拥有辐射强度的光源在单位面积A，单位立体角上辐射出的总能量。也就是：$L&#x3D;\\frac{d^2\\Phi}{dAd\\omega cos\\theta}$ 。如果把立体角和面积看作无穷小，就可以用辐射率来表示单束光线穿过空间中一个点的通量。 反射率方程$L_0(p,\\omega_0) &#x3D; \\int _\\Omega f_r(p,\\omega_i,\\omega_0)L_i(p,\\omega_i)n·\\omega_i d \\omega_i$中： $L_i(p,\\omega_i)$表示通过无限小的立体角（可以近似看作一个入射方向向量）投射到点p上的光线总和。 $n·\\omega_i$也就是余弦值$cos\\theta$。 $\\omega_0$表示观察方向，也就是光线的出射方向。 $L_0(p,\\omega_0)$表示了从$\\omega_0$方向上观察时，光线投射到点p上之后反射出来的辐照度 $\\Omega$表示以点p为球心，以平面法向n为轴所环绕的半球体。为 $d \\omega_i$积分元，在计算中按照一定的步长对反射率方程离散求解。 $f_r(p,\\omega_i,\\omega_0)$为双面反射分布函数，也就是BRDF，它的作用时基于表面材质属性来对入射辐射度进行缩放和加权 BRDF 输入参数：入射光方向，出射光方向$\\omega_0$，平面法向$n$，表示微平面粗糙程度的参数$\\alpha$ 当平面为理想镜面时，BRDF只对符合反射定律（即入射光、出射光、平面法向在同一平面，入射角等于出射角）的出射方向返回值为1，其他方向返回值都为0。 Blinn-Phong模型也可以认为是一个BRDF，但他不能保证能量守恒，因此不是基于物理的渲染。 Cook-Torrance BRDF（包括漫反射和镜面反射两部分）： $f_r &#x3D; k_d f_{lambert} + k_s f_{cook-torrance}$ $k_s$表示入射光线中被折射部分的比例， $k_d$表示入射光线中被反射部分的比例。 漫反射部分：$f_{lambert} &#x3D; \\frac{c}{\\pi}$ ，其中$c$表示表面的颜色。 镜面反射：$f_{cook-torrance} &#x3D; \\frac{DFG}{4(\\omega_0·n)(\\omega_i·n)}$ $D$：正态分布函数估算在当前的表面粗糙度下，取向方向与中间向量一致的微平面的数量。 $G$：几何函数描述了微平面自成阴影的属性，当平面较粗糙时，微平面可能会互相遮挡从而减少表面所反射的光线。 $F$：菲涅尔方程描述不同表面角下表面所反射的光线所占比例 正态分布函数 也称为镜面分布，从统计学上近似地表示了与某向量（一般是中间向量h）取向一致的微平面的比例。 计算公式：$NDF_{GGXTR}(n.h,\\alpha) &#x3D; \\frac{\\alpha^2}{\\pi((n·h)^2 (\\alpha_2-1) + 1)^2}$ 其中：$h$表示中间向量， $\\alpha$表示表面粗糙度 几何函数 从统计学上近似求得微平面之间相互遮挡的比例，这种遮挡会损耗光线能量。 计算公式：$G_{SchlickGGX}(n,v,k) &#x3D; \\frac{n·v}{(n·v)(1-k)+k}$ 其中，$k$是粗糙度$\\alpha$的重映射 针对直接光照：$k_{direct} &#x3D; \\frac{(\\alpha+1)^2}{8}$ 针对IBL（image based lighting，一种间接光照技术）光照：$k_{IBL} &#x3D; \\frac{\\alpha^2}{2}$ 微平面相互遮挡包括： 观察方向上：几何遮蔽 光线方向上：几何阴影 同时考虑两种遮挡的几何函数计算公式： $G(n,v,l,k) &#x3D; G_{sub}(n,v,k)G_{sub}(n,l,k)$ 菲涅尔方程 描述被反射的光线对比光线被折射部分所占的比例，该值会随着观察角度的不同而不同。 菲涅尔方程根据观察角度得出被反射的光线所占的百分比。 垂直观察时，任何物体和材质表面都有一个基础反射率，而如果从和法线夹角近似90度的方向观察，理论上所有的平面都能完全反射光线，因此反光会变得明显很多。 菲涅尔方程的近似解公式：$F_{Schlick}(h,v,F_0) &#x3D; F_0 + (1-F_0)(1-(h·v))^5$ 该近似只对电解质或者说非金属表面有定义，因为使用IOR计算基础反射率对导体表面并不能计算出正确结果。 对金属材质需要预先计算平面对法向入射的反应，然后基于相应观察叫的近似对这个值进行插值 $F_0$：平面基础反射率，利用折射指数IOR算出，用RGB三原色来表示，因为对于道题该基础反射率一般是带有颜色的。 因为金属表面会吸收所有折射光线而没有漫反射，因此可以直接使用表面纹理来作为他们的基础反射率。 Cook-Torrance反射率方程 计算公式：$L_0(p,\\omega_0) &#x3D; \\int _\\Omega (k_d\\frac{c}{\\pi} + k_s \\frac{DFG}{4(\\omega_0·n)(\\omega_i·n)})L_i(p,\\omega_i)n·\\omega_i d \\omega_i$ PBR渲染管线中的纹理列表 反照率（Albedo）：每一个金属的纹理像素，指定表面的颜色或者基础反射率 法线（Normal）：使得我们可以逐片段值得独特的法线，制造表面的起伏感。 金属度（Metallic）：逐个像素指定是否是金属质地。 粗糙度（Roughness）：以纹理像素为单位指定表面的粗糙度，粗糙度数值会影响微平面统计学上的取向度。 环境光遮蔽（AO）：为表面和周围潜在的几何图形指定了一个额外的阴影因子。 PBR渲染管线中的纹理列表（Metal&#x2F;Roughness Workflow）​ 在本流程中，金属的反射率值和电解质的反射颜色一起被放置在Base color贴图中。金属贴图就像一个Mask一样来区分Base color中的金属和电介质数据。 ​ 常见介电材料的F0被硬编码为0.04。 反照率（Albedo） 每一个金属的纹理像素，指定表面的颜色或者基础反射率。在色调上比较平坦，对比度低于传统的漫反射贴图。亮度范围最低不应该低于30-50sRGB，最高不应该高于240sRGB。 法线（Normal） 使得我们可以逐片段计算得到独特的法线，制造表面的起伏感。 金属度（Metallic） 金属贴图用于定义材料的哪些区域表示原始的金属，它类似于一个遮罩。0.0表示非金属，1.0表示金属。 原始金属的灰度范围在金属贴图中定义为235-255sRGB，落在此范围内的金属需要在Base color中有70%-100%的反射率范围。金属上的涂层或者污垢等远低于金属70%-100%的反射率所需要的值，因此在金属贴图低于235sRGB的范围内，可以在介电和金属反射率值之间创建适当的混合。 粗糙度（Roughness） Roughness贴图以纹理像素为单位指定表面的粗糙度，描述了表面的不规则性，粗糙度数值会影响微平面统计学上的取向度。反射光方向会根据表面粗糙度变化，但强度保持不变。粗糙度高的表面具有范围更大看起来更暗的高光，而较光滑的表面则有范围较小而看起来更亮的高光。 黑色（0.0）表示光滑的表面，白色（1.0）表示粗糙的表面。 环境光遮蔽（AO）：为表面和周围潜在的几何图形指定了一个额外的阴影因子。 Ⅱ. Part Two Bump Mapping基本原理​ Bump Mapping（也叫Normal Mapping）也就是法线映射，简单的讲就是通过读取一张存储着法线信息的纹理来计算光照（而不直接简单地通过顶点法线的插值），这样可以明显增强图像的真实感。 法线贴图（Normal Map） 法线贴图是存储法线的一张贴图，法线的 xyz 的值经过归一化之后再被映射成为对应的 RGB 值。归一化的法线值范围为[-1,1]，而RGB的每一个分量为无符号的8位组成，范围为[0,255]。即法线的分量需要从由[-1，1]映射成[0，255]。法线贴图一般呈蓝色，因为大多数朝向 (0, 0, 1) 的法线被映射成为了 (0, 0, 255)。 切空间及其变换矩阵 我们需要注意的是，法线贴图中储存的法线是在切空间中的法线值。切空间是在某一点由顶点法向和切向量组成的线性空间。在模型每个顶点中，都存在这样的一个切空间坐标系，以模型顶点为中心，以TBN三个方向分别为为3个轴（Tangent，Binormal，Normal）。其中，N是顶点的法线方向，T、B两个向量是顶点切平面的2个向量，一般T的方向是纹理坐标u的方向，B的方向（副切线方向）通过TN叉乘计算得到。 ​ 从切空间到模型空间的变换矩阵，由T、B、N三个向量组成，也叫TBN矩阵。Tangent，Binormal，Normal三个向量中，我们在模型顶点中已知Tangent和Normal的值，则Binormal可以通过前2个向量的叉乘来取得。特别的，我们需要首先将Tangent进行Gram-Schmidt向量正交化，使之与法线垂直。 Normal Mapping主要流程​ 因此，我们进行Normal Mapping的主要流程就是： 根据顶点的Normal和Tangent计算TBN矩阵 根据顶点UV从Normal Map采样，并将其映射回到[-1,1]，从而得到切空间下的法线信息。 使用TBN矩阵将法线信息变换到模型空间 进行后续的光照计算（或许需要对法线做进一步变换转换到世界空间） Ⅲ. Part Three Shadow Map基本原理​ （本部分由于是课堂学习内容，因此在此不再赘述，只描述基本原理。） ​ 阴影图(Shadow Map)算法是渲染时用于计算阴影的算法，也是现在使用最为广泛的阴影计算方法。 ​ Shadow Map算法计算阴影的基本原理是：从光源可以看到场景中所有的被光照亮的表面。在光源方向不可见的表面都处于阴影区域。 为了判断Fragment是否对于光源是可见的，需要分三步： 以光源的位置作为视点，对场景进行一次渲染，这次绘制不会将着色显示在屏幕上，而只取深度信息，得到一张深度图Shadow Map。这张纹理上的每一个像素都记录了第一个可见表面的深度值（也就是与光源的距离）。 从真实的视点对场景进行渲染，在渲染的过程中，逐片元进行矩阵变换，求出当前片元在光源为视点的空间下的深度值和UV值（也就是xy坐标值）。 使用xy坐标值从第一步生成的Shadow Map中采样，并与当前片元深度值比较。如果当前深度值大于采样得到的深度值，则证明当前片元应该是阴影，反之则证明当前片元可以被光源照亮。 其中，第一步中以光源为视点进行渲染时，如果使用的是平行光则应该采用正交投影，如果使用的是点光源则应该采用透视投影。 使用上述方法得到的阴影会有明显的锯齿状，因此在项目中我还使用了老师上课介绍的PCF算法，以期望得到软阴影，柔化阴影边缘，消除锯齿状走样。 PCF方法的主要原理是，在从Shadow Map采样时，不仅采样当前UV，还要采样周围的像素（比如一个以当前UV为中心的3*3的窗口），将当前片元的深度值分别与这个窗口内的每一个深度值比较，如果大于当前片元深度值就取值为1，否则取值为0。之后再对这样得到的一个由0和1组成的窗口进行卷积操作（一般是求平均），从而得到当前片元的阴影系数，这样就实现了软阴影。 Ⅳ. Part Four 模型处理及贴图烘焙对模型的预处理： 使用Maya对模型的大小和旋转方向做了预先处理，这部分在代码里实际上也能通过ModelMatrix来实现，但是由于加入了其他的模型（比如点光源、背景幕布），为了统一，便使用了在Maya中预先处理好的方法。 两个模型的人体部分是硬边，也就是每个顶点有多个法线，这样会使得最终的渲染效果皮肤表面有棱角，不够平滑，因此我对两个模型的身体部分在Maya中进行了软化边操作。（下图展示软化边操作前后的模型效果及顶点法线） 如上图，没有做软化边的模型每个顶点有多个法线，软化边之后的模型每个顶点只有一个法线 自行建模得到了一个幕布，并同样为其制作贴图，对其进行PBR流程渲染。（见上图） 有些模型的UV没有展开（比如身体部分），对这些模型进行了UV自动展开（因为皮肤部分对UV排布方式的要求不高） 其他模型（衣物等）虽然有展开好的UV，但是该UV并没有在0-1的范围内，因此使用Maya将该展开后的UV放在0-1之内的范围内。 贴图的烘焙制作： 自行使用Substance Painter完成模型贴图的制作，PBR流程中导出的贴图有Albedo、Normal Map、Metallic Map、Roughness Map、Height Map五张。其中每个模型都使用的有Albedo、Normal Map、Roughness Map。由于本次渲染实验中没有模型有金属度，因此所有的Metallic Map都是一张黑色贴图，可以直接不添加该帖图，Shader会自动使用默认值0。另外，本次实验中也暂时没有烘焙和使用AO贴图。 Ⅴ. Part Five 效果展示​ 工程运行效果可以查看”录屏展示“文件，本处展示一些运行截图。（截图效果可能因为截图软件分辨率不够等因素，效果并没有直接看的好。）由于设备显卡比较陈旧，渲染FPS似乎较低。 Ⅵ. Part Six 参考资料 LeanOpenGL CN官网的PBR理论教程 Adobe官方提供的PBR Guide Shadow Map算法原理 Shadow Map算法及其延伸 三种Shadowmap改进算法的原理","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"GPU","slug":"GPU","permalink":"https://yaelcassini.github.io/tags/GPU/"},{"name":"Real-Time Rendering","slug":"Real-Time-Rendering","permalink":"https://yaelcassini.github.io/tags/Real-Time-Rendering/"},{"name":"PBR","slug":"PBR","permalink":"https://yaelcassini.github.io/tags/PBR/"}]},{"title":"场景设计课程作业 - 个性化场景建模","slug":"Scene-Design","date":"2023-05-31T09:01:48.000Z","updated":"2024-01-04T06:54:21.041Z","comments":true,"path":"2023/05/31/Scene-Design/","link":"","permalink":"https://yaelcassini.github.io/2023/05/31/Scene-Design/","excerpt":"课程名称：场景设计","text":"课程名称：场景设计 videohttps://www.bilibili.com/video/BV1hb4y1778m/ reporthttps://yaelcassini.github.io/2023/05/31/Scene-Design/ 参考原画 高模在maya中的展示效果 在substance painter中设置材质球后的展示 将painter中的贴图导出后在maya中设置材质球的效果 配置好贴图的低模在场景中的效果 整个场景截图展示","categories":[{"name":"Design&Art","slug":"Design-Art","permalink":"https://yaelcassini.github.io/categories/Design-Art/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Art","slug":"Art","permalink":"https://yaelcassini.github.io/tags/Art/"},{"name":"Scene Degign","slug":"Scene-Degign","permalink":"https://yaelcassini.github.io/tags/Scene-Degign/"},{"name":"Modeling","slug":"Modeling","permalink":"https://yaelcassini.github.io/tags/Modeling/"}]},{"title":"Git管理常用指令以及常见问题解决","slug":"Git-Management-Problems","date":"2023-05-23T06:29:45.000Z","updated":"2024-01-22T09:01:01.278Z","comments":true,"path":"2023/05/23/Git-Management-Problems/","link":"","permalink":"https://yaelcassini.github.io/2023/05/23/Git-Management-Problems/","excerpt":"git 管理相关问题及解决","text":"git 管理相关问题及解决 git 常见指令clone指定分支 git clone -b branch url 示例：git clone -b blender-v4.0-release https://github.com/blender/blender 查看用户名 ：git config user.name 查看密码： git config user.password 查看邮箱：git config user.email 查看配置信息： $ git config –list 修改用户名git config –global user.name “xxxx(新的用户名)” 修改密码git config –global user.password “xxxx(新的密码)” 修改邮箱git config –global user.email “&#x78;&#x78;&#x78;&#120;&#x40;&#120;&#120;&#120;&#x2e;&#99;&#x6f;&#x6d;(新的邮箱)” git submodule 如何push 代码 cd your_submodule git checkout master git commit -a -m “commit message” git push cd .. git add your_submodule git commit -m “Update submodule” git submodule update –remote git pull –recurse-submodules 在一台新的电脑上使用exchange服务器无法git pull git push 操作 git config –global –add safe.directory 打开新的电脑上用户名文件夹下的config文件，查看其中的路径是否正确。示例：%(prefix)&#x2F;&#x2F;&#x2F;192.168.16.73&#x2F;exchange&#x2F;DDBlender插件&#x2F;3.3&#x2F;ddblender。其中%(prefix)应该是服务器路径的一种语法规定，要按照这种形式输入才有效，另外，中文路径注意编码问题。 出现访问受限无法push的情况，可以使用git config --system --unset credential.helper重置git的认证设置，在push时手动输入用户名和密码，然后再使用git config --global credential.helper store保存用户密码。 hexo d报错无法连接到远程主机 报错：ssh: connect to host github.com port 22: Connection timed outfatal: Could not read from remote repository. Please make sure you have the correct access rightsand the repository exists. 解决参考： https://blog.csdn.net/qq_36408085/article/details/104117293，没用","categories":[{"name":"Others","slug":"Others","permalink":"https://yaelcassini.github.io/categories/Others/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://yaelcassini.github.io/tags/Git/"},{"name":"Submodule","slug":"Submodule","permalink":"https://yaelcassini.github.io/tags/Submodule/"}]},{"title":"动画设计作业 - 动画短片《戒猎》","slug":"Animation-short-film","date":"2023-05-22T12:35:53.000Z","updated":"2024-01-04T06:52:58.330Z","comments":true,"path":"2023/05/22/Animation-short-film/","link":"","permalink":"https://yaelcassini.github.io/2023/05/22/Animation-short-film/","excerpt":"课程名称：动画设计制作日期：2021 年 6-7 月","text":"课程名称：动画设计制作日期：2021 年 6-7 月 videohttps://www.bilibili.com/video/BV1rV4y1e7U3/ reporthttps://yaelcassini.github.io/2023/05/22/Animation-short-film/ 一 、课程目的制作30-60秒的三维动画短⽚。 二 、使用软件 前期-动画分镜： PhotoShop 中期-动画制作（包括人物动作设置及镜头移动实现）： Unity 后期-动画剪辑（包括动画录屏的剪辑和音效的添加）： Premiere Pro 三 、制作流程 前期 构想剧本，灵感来源于野生动物遭受猎杀的新闻，希望能够表达爱护野生动物，禁止猎捕野生动物，人与自然和谐共生的愿景。因此我设置了一个猎人的角色，他在捕猎野生动物的任务中跌下山崖，但却被一只小狐狸所救，因此她被深深地感动，最终改邪归正，成为了森林的守护者。由于时间限制，无法做到所有的资源都由自己制作，因此我在Unity的官方资源网站下载了一些符合 故事情节的资源文件，并根据剧情需要对他们进行了修改和重新整理。比如说对人物的贴图进行修改，和使用Unity状态机对人物的动作状态（如下图）进行修改等。 中期 使用Unity引擎进行动画的制作，其中，人物的动画完成和动作切换使用Unity提供的Animator动画 状态机完成，镜头的移动和拉伸使用C#代码编写镜头移动路径及改变相机参数完成。由于不同场景下需 要的人物动画差异较大，整体较难控制，因此我以分镜为单位对动画进行切割，对每个镜头进行分开的 录制。录制成果如下图： 后期 使用Premiere完成对之前录制的动画镜头的剪辑和后期处理，并自行寻找合适的音频素材添加，最 终合成演示短片。工作截图： 四 、总结和心得通过这次作业，我学习了动画的一些基本概念，对三维动画的整体制作流程有了一个全面的认识和了解，学习了在Unity中控制人物状态机来制作流畅连贯的人物动画以及镜头的切换和拉伸。 在制作中，我遇到的最大问题就是不知如何在短暂有限的镜头中完成自己想进行的表达，由于我采用的是Unity录制的方法，经常在镜头变换的过程中，使得分镜的市场大大超出自己的预期，只能回头调整分镜时长，另外，我也意识到，自己表达和提炼故事核心要点的能力还是不够强，会容易在一些可能不是特别重要的地方浪费短片时长。由于时间限制，在这次作业中一些流程并没有完全由自己完成，而是一定程度上借用了网络上的开源素材完成自己的故事展现，因此我认为今后有机会的话，还应该深度地学习流程中的每一个细节，在练习中精进自己的能力。","categories":[{"name":"Design&Art","slug":"Design-Art","permalink":"https://yaelcassini.github.io/categories/Design-Art/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Computer Animation","slug":"Computer-Animation","permalink":"https://yaelcassini.github.io/tags/Computer-Animation/"},{"name":"Art","slug":"Art","permalink":"https://yaelcassini.github.io/tags/Art/"},{"name":"Design","slug":"Design","permalink":"https://yaelcassini.github.io/tags/Design/"},{"name":"Unity","slug":"Unity","permalink":"https://yaelcassini.github.io/tags/Unity/"}]},{"title":"造型基础课程作业 - 平面构成绘画","slug":"Design-and-From","date":"2023-05-22T07:30:37.000Z","updated":"2024-01-04T03:48:43.087Z","comments":true,"path":"2023/05/22/Design-and-From/","link":"","permalink":"https://yaelcassini.github.io/2023/05/22/Design-and-From/","excerpt":"课程名称：造型基础绘制日期：2019 年","text":"课程名称：造型基础绘制日期：2019 年 HW1 HW2 HW3 HW4","categories":[{"name":"Design&Art","slug":"Design-Art","permalink":"https://yaelcassini.github.io/categories/Design-Art/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Art","slug":"Art","permalink":"https://yaelcassini.github.io/tags/Art/"},{"name":"Degign","slug":"Degign","permalink":"https://yaelcassini.github.io/tags/Degign/"},{"name":"Hand-painted","slug":"Hand-painted","permalink":"https://yaelcassini.github.io/tags/Hand-painted/"}]},{"title":"计算机视觉HW2 - 直线检测和圆检测","slug":"Hough-Circle","date":"2023-05-19T08:54:10.000Z","updated":"2023-09-18T08:07:21.308Z","comments":true,"path":"2023/05/19/Hough-Circle/","link":"","permalink":"https://yaelcassini.github.io/2023/05/19/Hough-Circle/","excerpt":"课程名称：计算机视觉实验项目名称：直线检测和圆检测","text":"课程名称：计算机视觉实验项目名称：直线检测和圆检测 一、实验目的和要求对输入的一张彩色图像，检测其中的圆形与直线，并将检测结果显示在原图上。 检测算法的核心功能需要自己 写代码实现， 不能调用 OpenCV 或其他SDK里与圆形直线检测 相关的函数；如果要用到边缘检测，这个可以调用 OpenCV 函数。 在原图上显示最终的检测结果。 单独显示一些关键的中间结果 必须对指定的三张测试图像（ coin 、seal 、highway ）调试结果。此外，自己还可以自愿加一些测试图像。 二、实验原理1）Hough 变换$$$y&#x3D;mx+c \\Rightarrow c&#x3D;-xm+y$$$如上图，对于笛卡尔坐标系内的一条直线：$y&#x3D;mx+c$ 以$(x_0,y_0)$点为例，固定$x_0,y_0$为自变量，$(m,c)$为变量，则每个点$(x_0,y_0)$对应于空间$(m,c)$上的一条直线：$c&#x3D;-xm+y$ 通过变换坐标系，将直线和点相互转换，从而将求直线转化为求多条直线的交点。 但是上述转换存在直线垂直时，斜率是无穷大的情况，因此我们换用极坐标系。 直角坐标系中的点是极坐标系中的线，直角坐标系中的线是极坐标系中的点。 如下图所示，想要检测图像中的直线，可以使用Hough变换，转化为检测极坐标系中的点 $(\\theta, \\rho)$ 。 2）直线Hough变换笛卡尔坐标系中的直线，由斜率和截距表示，而极坐标中用 $(\\theta, \\rho)$ 表示，并且存在下式关系：$$$\\rho &#x3D; cos(\\theta)\\cdot x + sin(\\theta)\\cdot y$$$对于点 $(x_0,y_0)$，代入上式，在极坐标中就是一条线（很多对 $(\\theta, \\rho)$ 点）：$$$r &#x3D; cos(\\theta)\\cdot x_0 + sin(\\theta)\\cdot y_0$$$ $(\\theta, \\rho)$ 就是一对Hough空间的变量表示。一个点 $(x_0,y_0)$, 就是一个正弦曲线。 如下图，直角坐标系中的多个点，对应于 $\\rho - \\theta$ 空间的多条正弦曲线。 直角坐标系的三点共线，对应于 $\\rho - \\theta$ 空间的多线共点。 因此，我们可以通过检测 $\\rho - \\theta$ 空间的交集点，来检测原始空间的线段。 接下来，就是要考虑 将 $\\rho - \\theta$ 离散化，形成离散化的Hough空间，用于统计交集点的个数。 3）累加器 将参数空间离散化，从而得到一个二维数组累加器，记录 $\\rho - \\theta$ 空间每对参数 $(\\theta, \\rho)$ 出现的次数，大于某个阈值的，就证明有线相交于该点，也就证明原笛卡尔坐标系中有直线。 4）圆的Hough变换给定一个圆弧有三个参数，$a,b$用来确定圆心位置，$\\rho$确定半径。$$$b&#x3D;atan\\theta-xtan\\theta+y$$$ 类似直线，将$(x_0,y_0)$固定，而将$(a,b,\\rho)$作为变量：$$$x&#x3D;a+\\rho cos \\theta \\Rightarrow a&#x3D;x-\\rho cos \\theta \\y&#x3D;b+\\rho sin \\theta b&#x3D;y-\\rho sin \\theta$$$因此可以创建hough三维累加器，对于圆图像中的每一个点计算对应的$(a,b,\\rho)$点对。 但由于是三维累加器，会大大增加计算量。因此我们采用霍夫梯度法，先找出圆心的坐标。 我们令$\\rho$为边缘点处的梯度角，则上面的公式可以变换为：$$$b &#x3D; a tan\\theta-x tan\\theta+y$$$如下图，圆的边缘点切线的垂直方向,也就是梯度方向经过圆点。所以我们可以建立关于$(a,b)$的二位累加器，遍历图像的所有点，对每个像素点计算梯度（本实验中使用Sobel算子），对该直线上的所有像素点进行投票，最后选取超过阈值的像素点作为阈值，为了避免选取过多的圆心，把距离小于某一个阈值的圆心当做同一个圆心。 下一步，对于每一个投票选出的圆心，遍历整个图像，计算他们与该圆心的距离，然后将距离值排序，在某一个距离范围区间内，点超过一定数量的，就可以将该距离作为该圆心对应的一个半径。 全部遍历完成后，就可以得到$(a,b,\\theta)$点对表示的圆检测结果。 三、实验内容和过程分析1) 主函数及图像读入和预处理流程分析本实验中，读入图像后我对图像做了一下预处理： 转化为灰度图 高斯滤波以及均值滤波，图像去噪，防止噪声干扰边缘检测 使用Canny算子计算图像边缘并展示 将边缘图像作为掩码拷贝源图像，从而展示彩色的边缘图像 预处理之后进入正式的直线和圆形检测，调用“HoughLine”以及“HoughCircle”模块中的函数 使用Hough变换检测直线并返回结果，在源图像上绘制结果直线 使用Hough梯度法检测原型并返回结果，在源图像上绘制结果圆 以下是简化版的主函数代码，其中包括图像预处理以及直线和圆检测函数的调用（篇幅限制，仅展示主要内容）： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263vector&lt;Vec3f&gt; circles;vector&lt;Line&gt; lines;//读入图像Mat src = imread(&quot;1.jpg&quot;, 1);if (!src.data)&#123; cout &lt;&lt; &quot;图像不存在！&quot; &lt;&lt; endl; return -1;&#125;imshow(&quot;source&quot;, src); //展示源图像waitKey(0);Mat src_edge; cvtColor(src, src_gray, CV_BGR2GRAY); //转换为灰度图//高斯滤波，减弱噪声，避免检测时产生干扰GaussianBlur(src_gray, src_gray, Size(9, 9), 2, 2);imshow(&quot;guass&quot;, src_gray);waitKey(0);//对灰度图再做一次均值滤波blur(src_gray, src_edge, Size(3, 3));imshow(&quot;mean&quot;, src_edge);waitKey(0);//使用Canny算子计算图像边缘并展示Mat edges;int canny_threshold = 40;Canny(src_edge, edges, MAX(canny_threshold / 2, 1), canny_threshold, 3);imshow(&quot;edges&quot;, edges);waitKey(0);//使用Canny算子输出的边缘图，edges作为掩码，//来将原图image拷贝到目标图dst中，从而显示彩色的边缘图像Mat image = src.clone();Mat dst;dst.create(image.size(), image.type());dst = Scalar::all(0);image.copyTo(dst, edges);imshow(&quot;colorful_edge&quot;, dst);waitKey(0);//hough检测圆形并返回结果houghcircles(src_gray, edges, circles, 10, 40, 30, 0, 0);//在原图像上绘制检测到的圆形并输出结果for (size_t i = 0; i &lt; circles.size(); i++)&#123; Point center(cvRound(circles[i][0]), cvRound(circles[i][1])); int radius = cvRound(circles[i][2]); circle(src, center, 3, Scalar(0, 255, 0), -1, 8, 0); //圆心 circle(src, center, radius, Scalar(255, 0, 0), 2, 8, 0); //圆&#125;//hough检测直线并返回结果houghlines(edges, lines, 110);//在原图像上绘制检测到的直线并输出结果for (size_t i = 0; i &lt; lines.size(); i++)&#123; Point s = lines[i].start; Point e = lines[i].end; line(src, s, e, Scalar(0, 0, 255));&#125;//展示绘制结果后的图像namedWindow(&quot;Result&quot;, CV_WINDOW_AUTOSIZE);imshow(&quot;Result&quot;, src);waitKey(0); 2）Hough变换检测直线 HoughLine模块结构体及函数原型 1234567891011121314151617181920// ρ-θ空间累加器struct Polar&#123; int x; int y; int count;&#125;;//用于返回直线两端的坐标struct Line&#123; Point start; Point end;&#125;;bool polar_order(Polar a, Polar b); //用于排序int get_position(Mat img, int ii, int jj, int flag); //对于水平和垂直的直线，找回Hough变换时损失的信息//hough变换检测直线//img：输入的边缘图像（灰度图，只有0,255两个值）//lines：储存最后检测出的直线起始点//threshold：累加器阈值，只有累加器中的值大于该值，该参数对才会被选中//rho：ρ参数的分辨率（遍历步长）//theta：θ参数的分辨率（遍历步长）void houghlines(Mat img,vector&lt;Line&gt;&amp; lines, int threshold, double rho = 1, double theta = 1); 适当地量化参数空间（合适的精度即可） 根据图像大小及分辨率（精度）计算累加器大小 12345678//图像长宽int w = img.cols;int h = img.rows;//累加器大小int add_w = 180/theta;int add_h = 1.5 * (w + h) /rho ;//消除值为负的ρint center_h = add_h / 2; 假定参数空间的每一个单元都是一个累加器，把累加器初始化为零 123456789//为累加器分配空间 int** add = (int**)malloc(add_h * sizeof(int*)); for (int i = 0; i &lt; add_h; i++) add[i] = (int*)malloc((add_w + 1) * sizeof(int)); //累加器赋值为0 for (int i = 0; i &lt; add_h; i++) for (int j = 0; j &lt; add_w; j++) add[i][j] = 0; 对图像空间的每一点，在其所满足的参数方程对应的累加器上加1 123456789101112//累加器投票 int threshold_pix = 200; for (int i = 0; i &lt; h; i++) for (int j = 0; j &lt; w; j++) if ((int)img.at&lt;uchar&gt;(i, j) &gt; threshold_pix) for (int k = 0; k &lt; 180; k=k+theta) &#123; double angle = (double)k / 180 * PI; //角度制转换为弧度值 double dr = (double)j * cos(angle) + (double)i * sin(angle); int r = round(dr)/rho; int kk = k/theta; add[r + center_h][kk]++; //r可为负值，加上矩阵中心 &#125; 累加器阵列的超过阈值的点对应直线的参数 在这里对原算法进行了改进，判断累加器是，需要该点同时满足值超过阈值和大于自身周围的点的累加器值，才将该点选中。 并且在选中点之后，对其做一个聚合操作，即将其周围一定区间内的累加器的值也看做是一条直线，同时累加给该点。 （原理相似处代码此处省略） 123456789101112131415161718192021222324252627282930313233//遍历累加器，选出符合规定的ρ-θ点对作为检测到的直线参数vector&lt;Polar&gt; v; for (int y = 1; y &lt; add_h - 1; y++)//模长&#123; for (int x = 0; x &lt; add_w; x++)//角度 &#123; int flag = 0; //如果当前点在累加器边界处 if (x == 0) if (add[y][x] &gt; threshold &amp;&amp; add[y][x] &gt; add[y][x + 1] &amp;&amp; add[y][x] &gt; add[y - 1][x] &amp;&amp; add[y][x] &gt; add[y + 1][x]) flag = 1; else if (x == add_w - 1) //此处省略 //如果当前的值大于阈值，并在4邻域内它是最大值，则该点被认为是圆心 else if (add[y][x] &gt; threshold &amp;&amp; add[y][x] &gt; add[y][x - 1] &amp;&amp; add[y][x] &gt; add[y][x + 1] &amp;&amp; add[y][x] &gt; add[y - 1][x] &amp;&amp; add[y][x] &gt; add[y + 1][x]) flag = 1; //选择该点表示的参数作为一条直线的参数 if (flag) &#123; Polar po; po.x = y; //ρ po.y = x; //θ po.count = add[y][x]; //聚合，如果当前参数对被选中，则把相邻(-5,5)区间内的累加器值都加给它 for (int p = y - 5; p &lt;= y + 5; p++) for (int q = x - 5; q &lt;= x + 5; q++) if (p &gt;= 0 &amp;&amp; p &lt;= add_h - 1 &amp;&amp; q &gt;= 0 &amp;&amp; q &lt;= add_w - 1) po.count += add[p][q]; v.push_back(po); //当前点符合要求，作为圆心 &#125; &#125;&#125; 将结果记录到lines 对已经被选中的点降序排列后，反推计算出其在原图像中对应的直线的起始点坐标，并记录到lines中。（此处代码简化） 在这里分四种情况处理： 水平直线 垂直直线 $\\theta$ 较小 $\\theta$ 较大 1234567891011121314151617181920212223242526272829//对检测到的参数对按照累加器中的值大小降序排列 sort(v.begin(), v.end(), polar_order); //将投票数最多的直线转换到笛卡尔坐标系计算出起始点坐标并存入名为lines的vector vector&lt;Polar&gt;::iterator iter; for (iter = v.begin(); iter != v.end(); iter++) &#123; if (iter-&gt;y == 0) &#123; y1 = 0; y2 = h - 1; x1 = x2 = get_position(img, iter-&gt;x, iter-&gt;y, false); Line temp; temp.start = Point(x1, y1); temp.end = Point(x2, y2); lines.push_back(temp); &#125; else if (iter-&gt;y == 90)&#123;//此处省略&#125; else if (iter-&gt;y &gt;= 45 &amp;&amp; iter-&gt;y &lt;= 135) &#123;//在这个范围内sin值比较大，使用sin做分母误差较小 x1 = 0; y1 = (iter-&gt;x - center_h) / si; //加上之前为了消除ρ的负值减去的值 x2 = w - 1; y2 = ((iter-&gt;x - center_h) - (double)x2 * co) / si; Line temp; temp.start = Point(x1, y1); temp.end = Point(x2, y2); lines.push_back(temp); &#125; else &#123; //在这个范围内cos值比较大，使用cos做分母误差较小 //此处省略 &#125; &#125; 3）Hough梯度法检测圆形 HoughCircle模块结构体及函数原型 1234567891011121314151617181920212223242526272829303132333435#define PI 3.14159265358979#define HOUGH_CIRCLE_RADIUS_MIN 10 //圆最小半径#define HOUGH_CIRCLE_RADIUS_MIN_DIST 2 //同心圆两个半径最小差#define HOUGH_CIRCLE_INTEGRITY_DEGREE 0.6 //用于判断圆周上的点是否足够多（是否能成圆）#define HOUGH_CIRCLE_SAMEDIRECT_DEGREE 0.99 //用于梯度检测#define HOUGH_CIRCLE_GRADIENT_INTEGRITY_DEGREE 0.9 //用于梯度检测//记录圆心struct Centers2&#123; int x; int y; int count;&#125;;bool center_order(Centers2 a, Centers2 b); //用于排序//记录其他点与圆心的距离和内积struct Radius&#123; double dist2; double inner_product;&#125;;bool radius_order(Radius a, Radius b); //用于排序float normalization(float x); //用于归一化圆心检测图像并放大差异，从而使圆心识别效果更好//hough梯度法检测圆形//src_gray：灰度图像//edges：边缘图像//circles：储存结果圆参数//min_dist：两圆心之间的最小距离，小于该距离两圆心将被合并//add_threshold：阈值，累加器中大于该值的点才能被选定为圆心//min_Radius：圆最小半径//min_Radius：圆最大半径void houghcircles(cv::Mat&amp; src_gray, Mat edges, std::vector&lt;cv::Vec3f&gt;&amp; circles, double min_dist, int param2, int minRadius = 0, int maxRadius = 0); 量化关于a，b的参数空间到合适精度，创建并初始化累加器 12345678910111213//根据分辨率计算累加器的大小 dp为分辨率，此处为1int add_rows = (double)src_gray.rows / dp + 0.5;int add_cols = (double)src_gray.cols / dp + 0.5;//创建累加器矩阵并为累加器分配内存int** add = (int**)malloc(add_rows * sizeof(int*));for (int i = 0; i &lt; add_rows; i++) add[i] = (int*)malloc((add_cols) * sizeof(int));//累加器赋值为0for (int i = 0; i &lt; add_rows; i++) for (int j = 0; j &lt; add_cols; j++) add[i][j] = 0; 计算图像空间中边缘点的梯度幅度和角度，遍历边缘图像，若边缘点参数坐标满足则该参数坐标对应的累加器加1 使用Sobel算子计算边缘图像梯度，并根据分辨率遍历边缘图像计算累加器（篇幅限制，部分细节代码省略）。 12345678910111213141516171819202122232425262728293031323334353637383940//使用Sobel算子计算水平梯度和垂直梯度cv::Sobel(src_gray, dx, CV_16SC1, 1, 0, 3);cv::Sobel(src_gray, dy, CV_16SC1, 0, 1, 3);Point pt;//记录累加器中的最大值 int accum_max = 0;//遍历边缘图像for (int y = 0; y &lt; rows; y++)&#123; for (int x = 0; x &lt; cols; x++) &#123; //如果当前的像素不是边缘点，或者水平梯度值和垂直梯度值都为0 if (!edges_row[x] || (dx_now == 0 &amp;&amp; dy_now == 0))continue; //计算当前点的梯度模长 float length = sqrt(dx_now * dx_now + dy_now * dy_now); //单位梯度向量所对应的水平和垂直的位移，作为遍历时的步长 sx = cvRound((dx_now / dp) / length * ONE ); sy = cvRound((dy_now / dp) / length * ONE ); //当前点的坐标按照相同比例映射到累加器坐标 int x_now = cvRound((x / dp) * ONE); int y_now = cvRound((y / dp) * ONE); //在梯度向量的正反两个方向分别计算累加器 for (int times = 0; times &lt; 2; times++) &#123; //初始化坐标值，最小半径对应的位移 x1 = x_now + minRadius * sx; y1 = y_now + minRadius * sy; //控制圆的半径在一定范围之内 for (r = minRadius; r &lt;= maxRadius; x1 += sx, y1 += sy, r++) &#123; int x2 = x1 &gt;&gt; SHIFT, y2 = y1 &gt;&gt; SHIFT; //按照比例缩放回真实大小 add[y2][x2]++; //在累加器的相应位置上加1 if (add[y2][x2] &gt; accum_max) accum_max = add[y2][x2]; //记录累加器中最大的值 &#125; sx = -sx; sy = -sy; //把位移量设置为反方向 &#125; pt.x = x; pt.y = y; points.push_back(pt); //记录边缘图像中的当前点 &#125;&#125; 选出累加器的值大于一定阈值且局部最大的点，所在的坐标即为图像空间中的圆心之所在，并展示圆心选择结果 12345678910111213141516171819202122232425262728//对累加器做归一化和放大差异for (int y = 1; y &lt; add_rows - 1; y++) for (int x = 1; x &lt; add_cols - 1; x++) add[y][x] = normalization((float)add[y][x] / accum_max) * 256;//遍历累加器for (int y = 1; y &lt; add_rows - 1; y++) for (int x = 1; x &lt; add_cols - 1; x++) //当前值是阈值且局部最大 if (add[y][x] &gt; add_threshold &amp;&amp; add[y][x] &gt; add[y][x - 1] &amp;&amp; add[y][x] &gt; add[y][x + 1] &amp;&amp; add[y][x] &gt; add[y - 1][x] &amp;&amp; add[y][x] &gt; add[y + 1][x]) &#123; Centers2 temp; //将当前点作为圆心 temp.x = x; temp.y = y; temp.count = add[y][x]; centers2.push_back(temp); &#125;//展示选择圆心的图像Mat center_img = Mat(add_rows, add_cols, CV_32SC1);for (int i = 0; i &lt; rows; i++) int* ptmp = center_img.ptr&lt;int&gt;(i); for (int j = 0; j &lt; cols; j++) center_img.at&lt;int&gt;(i, j) = add[i][j];cv::normalize(center_img, center_img, 0, 255, cv::NORM_MINMAX);center_img.convertTo(center_img, CV_8UC1);imshow(&quot;centers&quot;, center_img);waitKey(0); 得到圆心坐标之后，反求圆心对应的半径ρ 外层遍历得到的圆心，内层遍历所有参与计算的边缘图像中的点，计算他们与当前圆心的距离，并记录所有距离数据在名为Radius的vector中，对vector进行排序，之后遍历vector，对于在参数min_Radius范围内，圆周上的点数目大于一定阈值的半径，则作为该圆心对应的半径之一（考虑同心圆）。（代码部分省略） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677//将圆心序列按照累加器中的数目降序排序sort(centers2.begin(), centers2.end(), center_order);//最小距离的平方min_dist *= min_dist;//按照累加器中的值由大到小的顺序遍历整个圆心序列for (i = 0; i &lt; centers2.size(); i++)&#123; radius.clear(); int y = centers2[i].y; int x = centers2[i].x; //计算圆心在输入图像中的坐标位置 float cx = (float)((x + 0.5f) * dp), cy = (float)((y + 0.5f) * dp); float start_dist, dist_sum; //判断当前的圆心是否之前已经输出过（如果距离小于min_dist，则判定为同一个圆心） for (j = 0; j &lt; circles.size(); j++)&#123; cv::Vec3f center = circles[j]; if ((center[0] - cx) * (center[0] - cx) + (center[1] - cy) * (center[1] - cy) &lt; min_dist) break; &#125; if (j &lt; circles.size())continue; //遍历之前记录的边缘图像中的所有点 for (j = k = 0; j &lt; points_count; j++)&#123; cv::Point pt; pt = points[j]; //计算边缘图像中的点与当前圆心的距离 float _dx = cx - pt.x; float _dy = cy - pt.y; float _r2 = _dx * _dx + _dy * _dy; short sx = dxdy_row[0]; short sy = dxdy_row[1]; //记录所有在范围内的距离 if (minRadius2 &lt;= _r2 &amp;&amp; _r2 &lt;= maxRadius2)&#123; k++; Radius temp; temp.dist2 = _r2; radius.push_back(temp); &#125; &#125; //k表示一共有多少个圆周上的点 int point_cnt1 = k, start_idx = point_cnt1 - 1; if (point_cnt1 == 0) continue; //求平方根 for (int t = 0; t &lt; point_cnt1; ++t) radius[t].dist2 = pow(radius[t].dist2, 0.5); //对圆半径进行排序，按累加器中的值降序排列 sort(radius.begin(), radius.end(), radius_order); start_dist = radius[0].dist2; //遍历之间计算的半径，选择符合条件的半径 for (j = 0; j &lt;point_cnt1; j++) &#123; float dist2 = radius[j].dist2; float inner_product = radius[j].inner_product; if (dist2 &gt; maxRadius) break; if (dist2 - start_dist &lt; HOUGH_CIRCLE_RADIUS_MIN_DIST * dr)&#123; cur_r_count++; //记录圆周点个数 cur_r_dist_sum += dist2; &#125; //边缘图像上的圆周点足够多，判断圆是否合格 else &#123; float r_mean = cur_r_dist_sum / cur_r_count; //计算平均半径 if (cur_r_count &gt;= HOUGH_CIRCLE_INTEGRITY_DEGREE * 2 * PI * r_mean) &#123; cv::Vec3f c; c[0] = cx; //圆心的横坐标 c[1] = cy; //圆心的纵坐标 c[2] = (float)r_mean; //所对应的圆的半径 circles.push_back(c); //压入序列circles内 &#125; cur_r_count = 1; cur_r_dist_sum = dist2; start_dist = dist2; &#125; &#125;&#125; 四、实验结果展示1）直线检测（以highway图像为例）​ 该图像由于噪点较多，影响检测，因此实际实验时将高斯滤波和均值滤波的参数调大。 源图像 滤波结果（此处仅展示高斯滤波结果，提交的压缩包中将含有高斯滤波和均值滤波） 边缘图像（此处仅展示黑白边缘图像，提交的压缩包中将含有黑白和彩色两种格式） 直线检测结果 2）圆形检测（以coins图像为例） 源图像 滤波结果（此处仅展示高斯滤波结果，提交的压缩包中将含有高斯滤波和均值滤波） 边缘图像（此处仅展示黑白边缘图像，提交的压缩包中将含有黑白和彩色两种格式） 圆心累加器结果 圆形检测结果 3）同时检测直线和圆（以seal图像为例）1.源图像 滤波结果（此处仅展示高斯滤波结果，提交的压缩包中将含有高斯滤波和均值滤波） 边缘图像（此处仅展示黑白边缘图像，提交的压缩包中将含有黑白和彩色两种格式） 圆心累加器结果 直线和圆形检测结果 五、实验思考和感想​ ​ 通过本次实验，我更加深入地学习和体会了hough变换检测图形的算法，在实践的过程中，我发现了很多在学习过程中没有注意到的细节，都需要在实践进行调整。 ​ 在实验初期，调整hough变换检测的阈值是一件非常困难的事情，不合适的阈值对检测结果的影响非常大，后期，我发现这个阈值由于是一个绝对值，而图像大小会导致不同的图像适合的阈值有非常大的差别，因此我将其中的highway图像大小进行了调整，使其与其他两张图像大小差别缩小，因此最后的实验结果中，不必人为调整阈值，就可以同时对三张图像进行检测。 ​ 在实验中，我还发现，在进行直线检测时，由于hough变换时转换计算有误差，可能会导致变换后的线（对应原来的共线的点）不准确相交于一个点，而是在一个很小的范围内波动，因此我对算法进行了改进，在检测到累加器中的局部极大值后，在一个小范围区间内，对累加器的值做一个聚合，就会很大程度上避免这种情况，也能使得检验结果更加清晰准确。 ​ 另外，由于highway图像较模糊，清晰度较低，因此两旁的数目对检测结果的影响非常大，这是因为树木范围中很多点都被识别成了边缘点，因此，对于这张图像，我增大了均值滤波的参数，成功降低了树木中的边缘点数目，也最终非常明显地改善了检测结果。 ​ 在识别圆形时，我发现算法对于同心圆的检测效果不是那么优秀，我对算法进行了一定的改进，调整了宏定义的 “HOUGH_CIRCLE_RADIUS_MIN_DIST” 参数，使得计算半径时的半径区间范围稍微放大一些，从而使得半径的容错率更高，改善了半径计算不准确导致的无法识别出圆，将其舍弃的情况。但是该参数调整反馈非常敏感，稍微调整一点都会很明显地影响到检测结果（可能识别出一些不合适的结果，如下图），因此最后很遗憾地是还是没能识别出胶带最外圈的圆形，而只识别出了两圈（见上文图片）。但是经过对原图像和边缘图像的分析，我们也可以看出，出现这种结果的原因可能是因为：胶带内圈的两个圆太密集，从而使得算法可能检测出小圆的左半圈和右半圈为一个整圆，才会出现下图的结果。因此最后还是将该参数调回了原来的值。","categories":[{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://yaelcassini.github.io/categories/Computer-Vision/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://yaelcassini.github.io/tags/Computer-Vision/"},{"name":"Hough Transformation","slug":"Hough-Transformation","permalink":"https://yaelcassini.github.io/tags/Hough-Transformation/"}]},{"title":"虚拟现实课程报告 - 眼球追踪技术","slug":"EyeTracking","date":"2023-05-18T08:32:27.000Z","updated":"2023-09-18T07:59:33.735Z","comments":true,"path":"2023/05/18/EyeTracking/","link":"","permalink":"https://yaelcassini.github.io/2023/05/18/EyeTracking/","excerpt":"课程名称：虚拟现实与数字娱乐报告名称：眼球跟踪技术日期：2021 年 5 月 20 日","text":"课程名称：虚拟现实与数字娱乐报告名称：眼球跟踪技术日期：2021 年 5 月 20 日 一、简介​ 眼球追踪是一项科学应用技术，主要是研究眼球运动信息的获取、建模和模拟。实现眼球追踪有三种方式：一是根据眼球和眼球周边的特征变化进行跟踪，二是根据虹膜角度变化进行跟踪，三是主动投射红外线等光束到虹膜来提取特征。获取眼球运动信息的设备可以是红外设备之外，也可以是图像采集设备，甚至可以是一般电脑或手机上的摄像头。 ​ 目前的虚拟现实和增强现实交互方式仍然存在一些比较大的局限。3D手势操作很有前景，但手臂和肩膀很快就会感觉很累。疲惫的手臂会让人们的交互慢下来，并丢失追踪精度。声控适合于某些场景，但这种控制方式的响应速度很慢和不准确。头部运动现在正作为主要的控制方式，但不停地转动头部和倾斜脖子也会让人感到疲惫，并可能会造成脖子损伤。而眼球运动的精细肌肉则对疲劳免疫。并且眼动追踪技术的响应速度很快，对视线的追踪很准确。 ​ 在VR领域中，对人眼位置的检测能够为当前所处视角提供最佳的3D效果，使VR头显呈现出的图像更自然、延迟更小。同时，由于眼球追踪技术可以获知人眼的真实注视点，从而得到虚拟物体上视点位置的景深。眼球追踪与头部转动协同控制视角变化，可让人摆脱不自然头部转动产生的画面晃动。因此，眼球追踪技术被大部分VR研究者认为，这是解决VR头显设备眩晕问题的突破之处。 ​ 通过“注视点渲染技术”（Foveated Rendering），眼动追踪技术可以节省设备的运算资源。在现实生活中，我们观看事物的时候，通常都是聚焦于某一个事物上，而边缘环境的分辨率则会大幅度降低。虚拟现实和增强现实系统可以通过对注视点的获取，只渲染焦点的全分辨率，对于其他边缘区域则以较低分辨率进行渲染，从而大幅度节省了运算资源。 ​ 并且眼球追踪可以生成凝视数据，提供用户状态和眼动行为的信息。凝视数据可以用来准确地理解用户如何互动以及互动的原因，可以实现用户通过眼睛注视位置的移动和凝视时间来控制设备实现点击、滚动等功能（Gaze Interface）；也可以通过凝视数据分析用户的注意力集中点以及分析用户的兴趣点等（Gaze Analysis）。 二、基本原理​ 人看向不同方向时，眼部会有细微的变化，这些变化会产生可以提取的特征，计算机可以通过图像捕捉或扫描等方式，提取这些特征，从而实时追踪眼睛的变化。 ​ ​ 人类的眼球结构决定了，单眼的实现方向可以通过眼球中心和瞳孔的连线来得到，而瞳孔的位置可以通过对虹膜识别和提取中心点得到。而同时得到两只眼睛的实现方向，就可以通过两线交点得到用户的注视点。 ​ 对于VR中的注视点提取，还有一个关键的问题，如下图，用户的成像屏幕可能在离自己较近的地方，但由于VR中立体视觉的应用，用户真正的注视点可能并不在成像屏幕上，我们可以通过结合虚拟现实环境中虚拟物体的深度信息，构建一条虚拟线，可以从眼睛的方向追踪到虚拟世界中用户正在注释的物体上。 三、应用领域​ 视线追踪技术在VR领域的应用方式有： 1. 图形渲染资源分配：​ 通过使用VR中的眼动跟踪信息，可以执行所谓的“中心凹形渲染”，即在用户注视的方向分配更多的图形渲染资源。这样可以使得给定的渲染功率可以提供更高质量的输出，降低所需的处理能力，还可以创建一个更加身临其境的环境，在其中虚拟世界可以更紧密地表示现实世界。同时，这样的渲染方式还可以在VR虚拟环境中实现景深效果，更贴近人眼在现实世界中的成像特点。 2. 数据预取：​ 某些VR数据的读取和修改等操作需要一定的时间才能完成。如果用户在特定方向上扫视，那在用户选择要与之交互之前，数据读取可以在后台提前进行。 3. 多模式智能3D对象选择：​ 对于VR中的虚拟场景，用户很难在杂乱的环境中选定特定的小对象。通过把视线信息与控制器输入组合结合，可以一定程度上消除选择歧义，让用户更准确地选择对象。 4. 自动头显校准：​ 获取用户眼睛注视位置，可以使得头显设备可以更好地调整自己的图像输出参数，以获得最佳的用户舒适度。 5. 平衡操作：​ 前庭眼反射是一种众所周知的自动反应，会把眼球运动与前庭系统的变化联系起来。获取眼睛运动和头显运动将可以对用户前庭系统的可能状态进行判断，可能可以实现在VR使用期间减少晕动症。 四、具体算法1. 视线估计方法综述：​ 视线估计系统是典型的机器视觉系统，即让机器通过图像或者视频数据，计算出使用者的视线方向。视线估计方法根据对人体的侵害性可以分为侵入式视线估计方法和非侵入式视线估计方法。 ​ 侵入式视线估计方法包括机械记录法、电流记录法、电磁感应法和反射光记录法。这些方法大多具有较高的测量精度，但是由于在测试过程中与被测试者产生身体接触，而且设备复杂昂贵，作用距离短，因此降低了使用舒适性和应用范围。所以在实际应用领域中，这些方法逐渐被其更加舒适自然的非侵入视线估计方法所取代。 ​ 非侵入式视线估计技术由于能够兼顾精度和舒适性，并且适合嵌入到产品中，具有广泛的应用前景和实用价值，因此是目前研究的主要方向。但是这种基于图像信息的视线估计方法的精度容易受到诸如图像分辨率、光照环境、使用者个体差异和头部运动等因素的影响。非侵入式视线估计方法通常使用摄像机或照相机记载眼部运动，包括： ​ 1. 基于角膜反射光斑方法 ​ 2. 基于神经网络的映射函数方法 ​ 3. 基于投影变换方法 ​ 基于角膜反射光斑方法需要外加照明光源，由于角膜的凸型结构，当视线发生变化时，角膜对来自固定光源发出的光的反射光斑也是变化的。利用相机采集到的角膜上反射光斑的分布就能得到眼球运动信息，进而得到视线方向。这种方法精度较高，是目前比较常用视线测量方法之一。日本开发的眼控鼠标就是基于这种原理。这种方法的缺点是外加光源对测试者有一定的干扰性，视线估计精度也容易受到环境光线的影响。 ​ 上图给出了基于神经网络的映射函数进行视线估计的神经网络结构，将眼睛区域图像作为神经网络的输入，并利用高斯编码处理输出单元得到视线方向估计。这种方法并不借助眼睛的生理解剖模型，而是利用整幅图像的信息构造与注视点之间的单一映射。但是这类方法不仅需要大量的训练样本，而且样本维数较大，因此网络训练时间较长。同时训练好的网络缺少一定的适应能力，外界条件稍有改变都会显著影响映射的结果，因此不具备良好的推广性。 ​ 根据眼球结构和成像原理，人们提出了多种用于视线估计的3D模型。在Le Grand模型中，光轴定义为从瞳孔中心到角膜曲率中心的连线。在Wang的模型中，视线近似认为是眼球中心与虹膜中心连线。基于投影变换的视线估计方法只要根据二维图像信息求出视线在3D空间中的方向，再根据测试者和相机的相对位置，就可以得到视线在空间中的位置。但这类方法对头部和眼睛运动比较敏感，如果图像分辨率较低，则会极大的影响最终结果，同时这种方法涉及的模型较为复杂，计算量较大。 ​ 上述方法中，精度较高的基于角膜反射光斑方法需要外加光源照射眼睛区域，存在一定的侵入性和伤害性，对测试距离和测试环境也有严格的限制；映射方法适合处理注视与否问题，但是作为视线估计方法精度较低，而且缺少适应能力，外界条件稍有改变都会显著影响映射的结果；基于投影变换方法涉及的模型较为复杂，计算量较大，而且要求图像具有较高的分辨率。 ​ 我阅读的论文针对上述方法中的不足，提出了一种结合了投影变换和神经网络的视线方向估算方法。在无特殊光源和头部固定装置的条件下仅使用单相机作为采集设备。计算模拟结果表明该算法可以有效地提高人眼视线估计精度。 2. 视线估计流程：​ 视线估计系统工作流程图如下： ​ 本次技术点分析，我针对以上的流程重点学习了虹膜定位和视线估计的原理和算法。 4. 虹膜定位​ 由于我们在进行视线分析时需要获取瞳孔位置，因此我们在进行人眼定位之后，需要进行虹膜的定位（虹膜中心既是瞳孔）。东方人的虹膜颜色大都为黑色或深褐色，灰度值较低，和皮肤、巩膜的灰度值差异较大，因此利用恰当的阈值二值化分割出虹膜区域是最直观简单的方法。二值化计算代价小、速度快，非常具有实用价值。从输入图像 $f$ 到输出图像 $f’$ 的二值变换可以表示为（其中 $T$ 是阈值）： ​ ​ 选择恰当的阈值是图像分割和提取虹膜的关键，但是由于图像的噪声、环境光强的变化或其他一些因素，采用恒定的阈值对所有的图像进行去二值化处理是不合理的，对每幅图像找到一个全局自适应阈值分割虹膜区域比较合理。 ​ 自适应阈值可以通过图像灰度的直方图找到。灰度直方图是灰度级的函数，它表示图像中具有每种灰度级的像素的个数，反映图像中每种灰度出现的频率。在得到图像直方图后，图像阈值由以下公式计算：$$\\theta_e &#x3D; \\frac{H}{3} H &#x3D; \\frac{\\sum(gN_g)}{\\sum N_g}$$​ 其中 $g$ 为像素灰度， $N_g$ 为图像中灰度为 $g$ 的像素个数， $\\theta_e$ 为图像阈值。当某一个像素的灰度值低于 $\\theta_e$ 时，则令该像素灰度为0，反之为1。然后利用形态学算子（比如闭操作），将虹膜区域中可能存在的空隙填满。 ​ 二值化后的图像中虹膜区域的像素值都为0，将图像像素值沿纵向进行累加，以最小值对应的水平位置为中心，用边长为图像宽度的矩形窗口完成对虹膜的定位。 ​ 在对虹膜进行定位之后，通常我们还需要对虹膜进行椭圆拟合，拟合时可以使用Hough变换。 ​ Hough变换是1962年由Paul Hough提出的用来检测直线的一种方法，其本质上是一种聚类方法，通过建立图像空间与参数空间的对应关系，将图像空间像素点转化到参数空间，图像空间中的同在一条曲线上的点对应参数空间相交于一点的多条曲线，通过在参数空间统计交点分布来确定图像空间曲线参数。 ​ 在拟合参数过程中还使用到了RANSAC方法，RANSAC方法的核心思想是：先随机取出少量的点来构造一个解，然后验证这个解的可靠性，多次重复这个过程，选出最可靠的结果作为最终的拟合结果。这样做就可以从包含大量异常点的数据中得到较为可靠的模型参数。RANSAC的基本假设是：数据是由“内点’’、“外点’’和“噪声点’’组成，其中“内点”分布符合某种数学模型，而“外点”不符合这种数学模型，其余的可以视为“噪声点”。 ​ 我阅读的论文中，基于改进的RANSAC方法的虹膜轮廓拟合算法步骤如下： ​ （1）从虹膜的边缘图像中随机选择5个点，并验证是否每条边缘中至少有一个点被选中，如果不是，则重复步骤（1）。 ​ （2）用这5个点拟合出唯一的一个椭圆，如果不能拟合，则返回（1）。 ​ （3）计算所有数据点与（2）中拟合出的椭圆方程的距离，根据给定的阈值，距离大于阈值的划分为“外点”，反之为“内点”； ​ （4）重复（1）—（3）k次，记录下所有满足下面两个条件的椭圆： ​ （1）“内点”个数占所有数据个数的比重大于25％的椭圆对应的随机点组合 ​ （2）短半轴 $b$、长半轴 $a$ 和虹膜半径 $R$ 满足 $\\alpha R&gt;a&gt;b&gt;\\beta R$，$\\alpha$ 和 $\\beta$ 为自定义的合理阈值。 ​ （5）计算（4）中得到的所有椭圆方程对其内点的误差平方和，取误差平方和最小的椭圆所对应的内点作为数据点，用最小二乘法重新拟合椭圆作为最终结果。 5. 基于中心投影的视线估计​ 人眼模型： ​ 眼球是一个复杂的天然光学器件。眼球的形状近似球形，眼球壁外层的前 1&#x2F;6 为角膜，其余 5&#x2F;6 为白色的巩膜。角膜是透明的，其折射率约为1.367，它是光束进入眼睛的门户。角膜后面的空间称为前房，其中充满折射率与水相近的水状液。前房之后有一中心带圆孔的彩色盘状膜，称为虹膜。虹膜的中心圆孔即为瞳孔。虹膜后面是晶状体，它的外形如双凸透镜，并附着在睫状肌上。睫状肌的伸缩能调节晶状体的曲率，以达到调节焦距的目的。晶状体后面的空间称为后房，后房充满一种胶性透明体，叫玻璃体。玻璃体的折射率约为1.336，其透明外膜与视网膜紧贴着。 ​ 从几何光学的角度来看，眼睛是一个由多界面组成的复杂的共轴光学系统。瞳孔可以看作光圈，角膜、晶状体等可以看作透镜系统，眼底视网膜就是感光底片。进入眼睛的光线通过一系列界面的折射，最后成像于视网膜。与光学设备不同的是：光学设备通常是通过改变透镜之间距离来改变焦距，而眼睛是靠调节晶状体的弯曲程度来改变眼睛焦距。 ​ 下文是 Wang J G 等人提出的眼球模型。该模型将眼球视为一个半径为 R 的标准球体，并可以围绕着其中心转动。虹膜位于球体的前端，其轮廓是一个半径为 r 的圆盘状椭球，眼球中心到虹膜所在平面的距离为 d 。基于这个模型，Wang 等人提出了单眼视线估计方法和双眼视线估计方法，其精度在非侵入视线估计方法中仅次于基于角膜反射光斑的方法。这两种方法的思想都是将视线估计问题转化为求解空间中具有圆形特征物体的姿态问题，通过虹膜在图像上的椭圆轮廓求出其在三维空间中所在平面，并将虹膜平面的法向量作为对视线方向的估计。在双眼视线估计问题中，Wang充分利用双眼视线交汇一点的眼动模式作为约束条件求出注视点的空间位置。在单眼视线估计中，由于缺少了这个约束条件，所以还必须知道屏幕距离测试者的距离，才能得到注视点的位置。 ​ Wang的方法虽然在理论上非常完美，但是实验效果却不是很理想。总的来说Wang的方法存在以下两个问题： ​ 第一，在计算过程中涉及到空间中锥方程求解以及解的可能性的讨论等问题，计算较为复杂繁琐； ​ 第二，方法的精度受到图像分辨率限制，如果不能保证得到足够多的虹膜边缘像素，视线估计精度会大大降低。 ​ 因此我阅读的论文中针对上述问题提出了新的方法。 ​ 当人眼正视前方时，虹膜的轮廓接近圆形，而当视线方向发生偏移的时候，虹膜轮廓的在相机中所成像的形状会发生形变，成为一个椭圆。该方法利用这一点，依据虹膜轮廓的畸变程度得到视线方向的初步估计。 ​ 为了避免Wang方法中的复杂计算，我们将视线方向的立体角分解成两个角度：一个为人眼分别注视目标和注视相机时两个视线方向之间的夹角$\\theta$；另一个为视线在图像平面的投影与像平面水平坐标轴之间的夹角$\\gamma$。 ​ 考虑任意一个过眼球中心和相机的平面，假设视线在这个平面上发生偏转（如下图），虹膜 $\\overline {DJ}$ 在物平面的投影 $\\overline {BC}$ 可以表示为： ​ 可以看出 $ \\overline {BC}$ 同时也是物平面上虹膜轮廓拟合椭圆的短轴。虹膜中心在物平面上的偏移量可以表示为 ​ 其中 $R$ 为眼球半径，$r$ 为虹膜半径， $l$ 为物距，$R$、$r$ 和 $\\alpha$ 之间关系满足 $sin \\alpha &#x3D; r&#x2F;R$ ，通常把 $r&#x2F;R$ 的值看作一个固定的解剖结构常量，约为0.4。 ​ 第二个角度 $\\gamma$ ，可以从像平面上的虹膜轮廓拟合的椭圆方程得到。当视线方向发生偏转时，虹膜轮廓拟合椭圆的短轴就是视线在像平面上的投影，因此第二个角度 $\\gamma$ 就是椭圆短轴与图像坐标系中水平轴的夹角。 ​ 从上图可以发现，当第一个角度 $\\theta$ 确定，而第二个角度 $\\gamma$ 相差 $\\pi$ 时，虹膜的畸变程度是一样的，无法给出正确的注视方向，因此还需要借助其他信息处理这个歧义问题。Wang在2001的文章中提出一种基于眼角点位置的判断方法，其原理是：假设眼球中心不改变，并认为视线方向是由眼球中心指向虹膜中心，因此不管视线如何改变，从眼球中心到两个眼角的距离应该是近似相等的。这样就可以唯一确定眼球中心，从而确定视线方向。 ​ 在我阅读的论文中，作者通过对大量实验数据的统计，发现当视线发生偏转时，虹膜中心位移要大于瞳孔中心位移，但事实上，瞳孔就是虹膜中心的圆孔。产生这一现象的原因是由于眼球特殊的结构，在角膜与虹膜之间有一个充满无色液体的空腔结构叫做前房，虹膜就紧贴在前房的后面。前房的形状是中间厚，两边薄，可以将其看作是一个凸透镜。因此我们看到的虹膜实际上是虹膜的虚像，并且由于像场弯曲，使得瞳孔的虚像位于虹膜虚像的后方。因此当视线发生转动时，虹膜中心位移要大于瞳孔中心位移。​ 依据这个规律，作者提出一种从两个可能解中找出真实解的方法。由虹膜中心和瞳孔中心的坐标可以得到向量 $\\overline {O_{pupil} O_{iris} }$ ，将这个向量与两个可能的视线方向向量 $\\overline {v(\\gamma)}$做内积，y的真实解应满足条件 $&lt;\\overline{v(\\gamma)}，\\overline{O_{pupil} O_{iris}}&gt;0$。并且通过作者的实验结果分析，对于视线角(相对于注视相机)在5°​以上的情况，这种方法可以完全正确的找出正确解；对于视线角(相对于注视相机)在5°以下的情况，这种方法准确度在92％左右。 五、应用中的细节设计问题1. 碰撞检测的范围​ 基于目前眼球追踪技术，无法做到100%准确识别出注视物体，会存在一定的误差。因此视线与物体进行碰撞检测时，不应该将视线视为一个无限细的射线进行检测，一般需要设置一定的扩展范围，最好是将视线设置为一个圆锥形。 2. 碰撞检测并不等同于注视​ 人眼有两种常见的运动模式：眼跳和注视。检测到视线物体的碰撞和用户在注视这个物体并不是等同的。 ​ 眼跳的速度非常快，这时检测到视线和物体的碰撞，产生交互是没有必要的。视线落在某个物体上超过一定的时间才是注视，因此在交互设计中，一般需要通过一定的延迟判定才能认为是注视。 3. 避免米达斯接触​ 在眼球追踪技术应用中，还有一个问题：米达斯接触问题。 ​ 所谓米达斯接触（Midas Touch）问题（米达斯是希腊神话中的一位能点石成金的国王）指的是由于用户视线运动的随意性而造成计算机对用户意图识别的困难。用户有时只是单纯地观察一个物体，而不希望引发该物体对应的功能。 ​ 为了解决这个问题，一般不会采用注视后马上触发功能的方式，而是使用以下两种方式： ​ 1. 延迟触发：在被观察物体上，显示一个不影响正常浏览的时间进度条，当进度条完成设定时间的计时时，产生触发行为。 ​ 2. 二次眼控触发：在被观察物体旁边，显示“真正的”触发元素，用户余光可以看到，但不影响观察主体。当需要触发时，看那个“真正的”触发元素即可。 4. 与其他输入工具结合​ 在VR应用中，只用眼睛进行所有交互并不是最好的交互模式，结合其他输入工具，如手柄、语音、手势等进行多重交互，才是比较自然的。 ​ 比如在一个菜单界面上，眼睛的运动轨迹能够反应在菜单项中，使选项处于待激活状态，此状态下不触发场景切换或其他功能，然后配合语音交互或者特定手势交互，才触发功能，这种多重交互协作方式将会有效得避免误触。 References：［1］ 张雯.人眼注视方向识别的数字图像处理技术研究[D]. 博士, 南开大学, 2011. [学位论文] ［2］ Rachel Albert, Anjul Patney, David Luebke, and Joohwan Kim. 2017. Latency Requirements for Foveated Rendering in VirtualReality. ACM Trans. Appl. Percept. 14, 4, Article 25 (September 2017), 13 pages. ［3］ Linus Franke,1 Laura Fink,1 Jana Martschinke,1 Kai Selgrad2 and Marc Stamminger1[Lq1] .Time-Warped Foveated Rendering for Virtual Reality Headsets［J］.COMPUTER GRAPHICS forum, 2021,Volume 40 :110-123. [期刊]","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Virtual Reality","slug":"Computer-Graphics/Virtual-Reality","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Virtual-Reality/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"EyeTracking","slug":"EyeTracking","permalink":"https://yaelcassini.github.io/tags/EyeTracking/"},{"name":"Virtual Reality","slug":"Virtual-Reality","permalink":"https://yaelcassini.github.io/tags/Virtual-Reality/"}]},{"title":"研究生计算机图形学HW - 不同ZBuffer 算法的实现和效率比较","slug":"ZBuffer-Report","date":"2023-05-16T09:51:27.000Z","updated":"2024-01-04T06:51:32.693Z","comments":true,"path":"2023/05/16/ZBuffer-Report/","link":"","permalink":"https://yaelcassini.github.io/2023/05/16/ZBuffer-Report/","excerpt":"课程名称：计算机图形学（研究生）报告主题：不同ZBuffer 算法的实现和效率比较提交日期：2023 年 1 月 11 日","text":"课程名称：计算机图形学（研究生）报告主题：不同ZBuffer 算法的实现和效率比较提交日期：2023 年 1 月 11 日 codehttps://github.com/YaelCassini/Z-Buffer reporthttps://yaelcassini.github.io/2023/05/16/ZBuffer-Report/ 一、 实现功能及运行说明因为我个人想借这个项目的机会进行一些底层类的实现，为之后的希望能完成的图形引擎开发工作打一下基础，所以本项目没有依赖除了 C++标准库之外的其他库，一些基础的功能由自己个性化实现，比如说向量 Vector 的管理和计算（可以管理坐标、颜色、法向等信息），Obj 格式的 Mesh 读入，便于本项目展示的简单的坐标变换（有参考网络上项目的思路），四叉树以及八叉树的建立和管理等。 （一）主要算法实现了以下几种 ZBuffer： 普通的Zbufer 算法（Naive ZBuffer） 扫描线Zbuffer 算法（ScanLine ZBuffer） 简单版本的层次ZBuffer 算法（Naive ZBuffer + Hierarchical ZBuffer） 完整版本的层次 Zbuffer 算法（Naive ZBuffer + Hierarchical ZBuffer + Octree Scene） （二）为了支持效果自己完成的一些功能 读入OBJ 格式的 Mesh 文件，且同时支持三角形和四边形面片的读入，并且支持不同格式的 OBJ 文件，比如只包含坐标、包含坐标和纹理坐标和法向等。 为了方便展示不同尺度的模型，实现一个基于窗口大小进行的简单的坐标变换，保证任何 Mesh 都能完整展示在窗口中。 简单的模型着色功能，支持基于点光源的 Diffuse 和随机面片颜色两种着色方式。 实现了四叉树和八叉树的建立和管理，分别用于 Hierarchical 的 ZBuffer和场景面片的管理。 简单的向量管理类，支持不同的向量计算。 受渲染管线中Fragment Shader 的启发，建立了面向对象的场景面片管理， 包含面片的坐标、Z 值、颜色等信息。 在自己思考下加入了ZBuffer 遍历中的提前剪枝。 二、 开发与运行环境操作系统：Microsoft Windows 10 Pro 64bit CPU：Intel(R) i5-12400F 2.50 GHz内存：DDR4 8GIDE：Microsoft Visual Studio 2022配置平台：Release X64正常运行效果效果演示： 三、 项目架构及数据面向对象管理本实验使用 C++面向对象式地进行开发，为了更形象地展示，其中项目各个类之间的依赖关系和组织架构我画了一张图来展示：得益于面向对象的管理，main 函数的结构非常清晰：其中各个类实现的功能基本都可以从类名称清晰的看出，源代码的类定义中也有相关注释，在此就不再赘述，需要解释的一点是：我使用了一个 Fragment 类来管理光栅化之后的单个面片，这个面片与 Model 中的 Face 的区别是，Face 包含的是点坐标、法向等信息的索引值，而 Fragment 类中则直接记录的是面片的顶点坐标，并且是光栅化之后的像素坐标，该类同时还支持根据重心坐标对深度值进行插值，从而得到某一个具体像素处的深度值。 四、 实验步骤细节及问题解决具体的程序实现细节过于复杂，我不会在此一一赘述，但是在这个部分我会把其中几个我认为有价值的点拿出来简单展示一下。 1. 八叉树和层次 ZBuffer 的对应问题在实现完整版本的层次 ZBuffer 时，需要同时管理场景面片的八叉树，和ZBuffer 的四叉树两个数据结构，并且需要遍历八叉树，使用层次 ZBuffer 进行深度测试，在这里的实现细节时，需要将八叉树的遍历和层次 ZBuffer 的遍历同步进行，为了实现这种遍历，在构建八叉树的时候，我用的是下面这种顺序：从 Z 轴来看，前面四个子节点索引分别是 0，2，4，6，后面的子节点则是 1， 3，5，7。这样，在遍历的时候，如果需要进入到下一层子节点，就只需要从 0-7 遍历，而层次ZBuffer 对应的子节点下表只需要用八叉树下标&#x2F;2 做寻址即可。另外一个细节是，在简单模式下的 ZBuffer，如果只有左右两个像素需要剖分，就只会增加两个子节点，而不是严格意义上的四叉树，这样会减小遍历的压力，但在完整版本下，为了保证和八叉树的同步，我把层次ZBuffer 做成了严格的四叉树，没有子节点的地方使用空指针 NULL 占位。上图的情况是由于八叉树的子节点索引和层次 ZBuffer 的子节点索引没有在空间上对齐，导致遍历的时候出现整个子节点的面片都通不过深度测试（其实是因为xy 坐标不在范围内被深度测试强行拒绝）。 2. 层次 ZBuffer 绘制单个面片时的提前剪枝在寻找到层次 ZBuffer 无法拒绝，但是子节点又无法完全包裹面片时，就需要对面片进行绘制，如下图。但是我实现时发现这样非常非常耗时，具体的时间对比在下一部分。因此我加入了一种剪枝方式。层次ZBuffer 结构本身包含的剪枝是如果面片没有通过较大块的深度测试，就直接剪枝这块 Buffer，但是在绘制时，同样需要剪枝。如下图，由于这个面片跨越四个子节点，因此这四个节点都需要对该面片进行绘制，但是再向下一层，就有一些 Buffer 块不包含面片了，我在此时对这些Buffer 块进行剪枝，程序运行的速度大大加快。具体实现代码： 3. ScanLine 的边界控制问题因为 ScanLine 在切换下一条扫描线的时候需要使用提前计算好的 dx、dy、dzx、dzy 等递增量进行数据的递增，因此非常受到数据精度的影响，需要使用float 类型储存数据，但是由于光栅化为单个像素，又必须有 dy 等 int 类型的变量，在计算 dy 时，我一开始采用的是 round 函数进行绘制，但是这样可能会导致由于递增量的误差，在最后一条线绘制的时候，左边的 x 值已经超过了右边的x 值导致绘制错误，但是使用 ceil-floor 的方式又可能会在边界处绘制超过的像素部分，因此我最后对上界和下界都使用了floor 取整。在实践中由于数据精度问题还导致下面这种绘制错误的产生：这个问题的出现是由于在计算 dx 时，为了保证精度，我首先使用了下图中上面那种方式计算，这样会导致对于某些几乎平行于 x 轴，但是又没有被浮点判断消除掉的线，计算出的 dx 值会非常大，这就导致递增计算时出现很大的误差， 最终我改为了下图中下面那种计算方法。另外，ScanLine 算法中的边界控制这部分我认为说起来容易但是最容易出错，在实践中也耗费了我很多时间。比如，在判断活化边的结束条件部分我也出现了一些问题，一开始我担心如果用 dy&lt;0 来作为删除活化边的条件，会有一些情况整个三角形太小只占了一个元素，但是思考后认为应该用 dy&lt;0，因为只占一个元素的情况应该初始 dy&#x3D;0。而当活化边一边 dy&#x3D;0 的时候，就应该去对应的活化多边形中寻找下一条边替代并更新活化边的 dxl 和 dxr 了，这样才能保证活化边不被删除且下一次绘制时已经使用了新的递增量。 五、 实验结果与效率对比分析（一） 实验结果展示在不同着色模型下不同模型的绘制结果展示： （二） 算法效率对比分析在 800*600 的分辨率下，分别进行了不同面片数的 Mesh 绘制，并记录下不同算法的耗时（ms）：（为了方便比较这里把所有面片都预先转化成三角形模式，但是四边形也可以绘制） 而在 1600*1200 的分辨率下： 可以看出相比于ScanLine Zbuffer 算法，层次 ZBuffer 在面片较少时是没有太多优势的，但是在面片数逐渐增加时，其优势就逐渐体现出来了，并且，面片越多，完整的层次ZBuffer 相较于没有Octree 的简单版本优势越大。另外，没有额外剪枝的Hierarchical ZBuffer 算法速度非常慢，此处的ZBuffer 不是指的是在遍历过程中，由于面片被较大的ZBuffer 块深度测试拒绝而导致的剪枝，而是在上一部分提出的，遍历时根据 Zbuffer 覆盖范围和面片覆盖范围比较而进行的剪枝。 另外，在实验中，我发现层次ZBuffer 对于普通的Naïve ZBuffer 加速比效果不太理想，即使我同时绘制了五个模型也没有很好的加速效果，我推测可能是由于目前的场景还是不够复杂，没有很多那种被大范围遮挡的情况，而此时不需要遍历复杂的数据结构的Naïve ZBuffer 就稍占据了一些优势。 六、 总结与改进方向通过本次实验，我对几种基础的 ZBuffer 算法都有了更深入的理解，“纸上得来终觉浅，绝知此事要躬行”。亲自上手编程实现算法和仅仅通过眼睛学习效果是完全不同的，在这次实践中，我也发现自己对于一些编程上的技巧，数据结构的组织等仍有进步的空间，需要继续努力。我也深刻地意识到面向对象的编程的优势，将需要实现的功能拆分成不同模块，能大大提高编程和Debug 的效率。在具体实践的时候，ScanLine 耗费了我最多的时间和经历，主要因为这个算法个性化的程度比较高，相比于层次ZBuffer 本质上是利用到八叉树和四叉树， 结构比较清晰，ScanLine 算法则需要花费很多精力在控制边界调节、控制浮点数精度等细节上面。另外从我的实验结果来看，ScanLine 算法由于是用递增量去控制的，无论如何都会存在误差的累计，绘制的效果在某些情况下不太理想。但同时我也发现了很多程序中存在的问题，有一些已经解决了，在上文中也已经说明，但我认为还有一些可以改进的方向，只是由于事件原因没能实践。比如说，可以考虑使用 GPU 硬件加速八叉树和四叉树的结构，比如并行计算同一个八叉树的不同子节点，这样应该会大大加快程序访问八叉树的速度。另外，使用层次Zbuffer 绘制面片时，如果某个层次Zbuffer 不能拒绝面片， 但是单个子节点又都不能包含整个面片，那就只能从这个节点开始逐级向下绘制这个面片，但是这样可能会导致拒绝较大面片的效率不高，我认为后续可以进行改进的方法是对面片进行切割，因为这个阶段使用到的面片都是已经光栅化之后的屏幕空间的面片了，再进行平行于 xy 轴的面片切割应该不难实现，切割后就可以用切割的面片分别与子节点进行深度测试了。","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"ZBuffer","slug":"ZBuffer","permalink":"https://yaelcassini.github.io/tags/ZBuffer/"},{"name":"ScanLine ZBuffer","slug":"ScanLine-ZBuffer","permalink":"https://yaelcassini.github.io/tags/ScanLine-ZBuffer/"},{"name":"Octree","slug":"Octree","permalink":"https://yaelcassini.github.io/tags/Octree/"}]},{"title":"研究生计算机图形学HW - 图形处理器(GPU)的历史、现状和展望","slug":"GPU-Development-History","date":"2023-05-16T08:49:39.000Z","updated":"2023-09-18T08:06:59.758Z","comments":true,"path":"2023/05/16/GPU-Development-History/","link":"","permalink":"https://yaelcassini.github.io/2023/05/16/GPU-Development-History/","excerpt":"课程名称：计算机图形学（研究生）报告主题：图形处理器(GPU)的历史、现状和展望提交日期：2023 年 1 月 1 日","text":"课程名称：计算机图形学（研究生）报告主题：图形处理器(GPU)的历史、现状和展望提交日期：2023 年 1 月 1 日 零、前言首先，我的报告选择 GPU 发展历史该选题的原因是：在平时的学习研究中发现自己的硬件知识其实非常薄弱，几乎没有相关的硬件原理了解。虽然今后并不打算从事硬件相关的工作，但我认为“纸上得来终觉浅”——软件终究必须依靠当前的硬件工具进行运行，没有硬件知识终究会导致我的思路有很大的局限性，很多时候无法开发出效果更好、性能更高的系统、软件或者算法。因此我希望借此机会，通过查阅资料和自己的思考，使自己能对硬件知识、GPU 基础构架有一个广泛的了解。同时，GPU 的硬件设计制作发展和计算机图形学的发展也是相辅相成，无法分割的，因此本文也会带到一些图形学的发展历史，这样也算是在发展脉络上把两者结合了起来，我相信也能对自己有所帮助。 一、GPU 发展历史（1） GPU 简介GPU 全称是 Graphics Processing Unit，中文名称是图形处理器。又被称为显示核心、显卡、视觉处理器、显示芯片或绘图芯片，是一种微处理器，专门用于在 PC、工作站、游戏机和一些移动设备（如平板电脑、智能手机等）上运行绘图运算工作。其最初发明时仅仅是为了处理图形计算工作，减轻 CPU 的负担，后来著名的科技公司 Nvidia 最早看到其在通用计算中的巨大潜力，推出了 CUDA 平台，使得 GPU 在具备强大的图形计算能力的同时，成为当前的人工智能、深度学习等热点研究领域不可或缺的硬件支持。 我们目前市面上比较常见的 Geforce GTX20、30、40 系列显卡，本质上都是以 GPU 为核心的，其包括一块 GPU 核心芯片，一块 PCB 主板，以及其他集成在板上的显存、金手指、供电系统和散热等模块。如下图所示。 （2） 图形学的奠基1962 年麻省理工学院(MIT)的博士 Ivan E. Sutherland 发表的论文《SKETPAD: A MAN- MACHINE GRAPHICAL COMMUNICATION SYSTEM》以及他的画板程序演示为计算机图形学奠定了根基，这篇论文中首次使用了计算机图形学“Computer Graphics”这个术语，其也因此被称为计算机图形学之父。下图是该论文的一些绘制结果。 此后近 20 年的时间里，计算机图形学不断有新的发展，完成了基础研究的部分。60 年代早期 MIT 的教授 Steven A. Coons 提出了通过插值四条任意的边界曲线来构造曲面，法国雷诺汽车公司的工程师 Pierre Bézier 也在 60 年代发明了 Bézier 曲线、曲面的理论。上世纪 70 年代，区域填充、裁剪、消隐这些基础的图形学概念被先后提出，真实感图形学和实体造型技术也随之产生，不同的光照模型比如简单光照模型 Phong 模型也已经诞生。同时，图形学的标准制定也有标志性的进展， ACM 专门成立了图形标准化委员会，并先后于 1977、1979 年制定和修改了“核心图形系统”（Core Graphics System）。ISO 随后又发布了 CGI(Computer Graphis Interface，计算机图形接口)、CGM（Computer Graphics Metafile，计算机图形元文件标准）、GKS(Graphics Kernel system，计算机图形核心系统)、PHIGS（Programmer’s Hierarchical Interactive Graphics Standard，面向程序员的层次交互图形标准）等。而在上世纪 80 年代，Whitted 提出了光线追踪算法，美国 Cornell 大学和日本广岛大学的学者引入了热辐射工程中的辐射度方法，标志着真实感图形的显示算法已逐渐成熟。 但是在图形学研究过程的最初 20 年中，计算机却没有配备专门的图形处理芯片，图形处理任务都是 CPU 来完成的。硬件的性能不足，在一定程度上也限制了图形学技术的实际落地。在 80 年代，专门的图形处理硬件终于开始逐渐出现和发展。 （3） GPU 与显卡的发展（产品脉络）GPU 的发展史伴随着各种不同领域的科技公司的竞争和发展，比如半导体科技公司、硬件生产公司、软件开发公司、互联网公司等等，这些公司或许在发展的过程中都或多或少地参与过 GPU 的发展，因此下面将首先从各个不同的公司发布的产品来展示 GPU 的发展史。（但是由于篇幅限制，本篇读书报告中将会省略一些没有那么标志性的产品。） 早期显卡概念及发展1981 年，当时还没有显卡的概念，相应的名称叫做适配器或者寻址器。IBM 公司（国际商业机器股份有限公司）发布了首款黑白图形适配器（MDA），其物理外观如下图所示。其没有像素寻址的图形模式，而只具有单色的文本显示模式。只能显示 80 列 25 行的文本字符或者符号，用于绘制图表。同年，IBM 发布彩色图形适配器（CGA）具有 16kb 视频内存，能在 8025 或 4025 分辨率下支持 16 种颜色输出，或者在 320200 分辨率下支持 4 种颜色输出。同时 IBM 发布的这两种图形适配器可以被安装在同一台电脑上，当时的操作系统 DOS 中包含的命令是用户可以在 CGA 和 MDA 之间切换显示。1982 年，NEC(日本电气股份有限公司)发布了全球首款图形集成控制芯片 𝜇PD7220，该芯片可以绘制弧形、线条、圆形等图形基础元素，拥有高达 4Mbit 的图形内存，支持10241024 的分辨率和四种颜色输出，并且建立了易于使用的低级指令集，使得应用程序的开发者可以通过嵌入这些指令到程序里实现个性化的操作。 1985 年，著名的 ATI 公司成立，该公司也是当前市面上流行的 A 卡的初创者，同年该公司发布了第一款产品 ATI Graphics Solution Rev.1，如下图所示。1987 年 ATI 发布了ATI EGA Wonder 系列显卡，配备 256K 显存，采用 8 位 ISA 插槽。1990 年 ATI 推出升级款产品 ATI VGA Wonder+，采用全新的 28800-2&#x2F;4&#x2F;5 主芯片，该芯片当时采用的晶体管制造工艺为 800nm。1988 年，ATI 大力推广 ATI VGA Wonder 系列显卡，该系列显卡采用了后面一度被广泛使用的图形输出接口——VGA 接口，支持 1024*768 以上的分辨率，色彩支持达到 1600 多万色，就是我们常说的 24 位真彩色。 1990 年，Trident 9685 发布，能采用软件模拟来实现 DCI 和 DirectDraw 软 3D 加速，标志着显卡步入 3D 时代，随后发布的 Trident 9750&#x2F;9850 两款芯片则可以支持硬件 3D 加速。在 90 年代初期，功能比较均衡的 Trident 8900&#x2F;9000 系列（16-bit ISA）为当时绝对的主流卡。 在 90 年代初期，1991 年 ATI 发布 ATI Graphics Ultra 系列显卡，此时微软的 Windows 操作系统已经炙手可热，因此该系列显卡也是面向 Windows 系统推出的。该显卡配备 2D 显示处理核心和 Mach8 协处理器，主要作用是分担 CPU 对图形处理的工作。1994 年 相继推出了 Mach 32 、Mach 64 和 Mach 64-VT，支持 32 位色彩和 VESA 标准，Mach64 更是加入了视频加速、 YUV&#x2F;RGB 颜色转换和硬件缩放等功能，使得电脑 AVI 和 MPEG 视频不再需要 CPU 加速。但以上这些 GPU 主要还是面对 2D 图形处理的。 在 80 年代到 90 年代初期的这段时间里，GPU 的研发和设计基本处于一个群雄逐鹿的态势。除了上面提到的之外，还有很多公司参与过 GPU 的发展，比如 SGI（Silicon Graphics， 美国硅图公司）推出的高端图形工作站、苹果推出的具有图形化操作界面的个人电脑、TI（德州仪器，一家全球化半导体设计与制造企业）推出的 CPU 和 GPU 结合的完整 32 位处理器， Inter 的图形协处理器等。 VooDoo 开启的个人电脑时代的显卡发展但前期的很多显卡设备并没有在个人电脑上得到很好的推广，直到 1994 年 3Dfx 公司创立，并于 1995 年推出了他们的第一款显卡 3Dfx VooDoo（国内音译为巫毒），这是第一款真正意义上的消费级 3D 显卡，他将个人电脑真正意义上地带入了 3D 世界，也是一个极具标志性的时间节点。 1993 年，黄仁勋联合自己的技术伙伴一起成立了后来的显卡巨头 Nvidia。1995 年， Nvidia 推出了首款以 NV1 图形芯片为核心的多媒体解决方案。但是他们试图抛弃三角形绘制改用四边形绘制，并不兼容当时主流的图形绘制库 OpenGL 和 Direct3D（直到现在仍然是主流的图形绘制解决方案）。这使得他们的方案不被市场所接纳，几乎无人问津。但 Nvidia 很快做出了调整，1997 年，Nvidia RIVA 128 诞生，从此 Nvidia 放弃了自己的 API 接口，转而支持微软的 Direct3D 技术。RIVA 128 拥有 128 位内存总线，像素填充速率达到 100Mpixel&#x2F;s，并且性能已经强于 VooDoo。而在几乎同期的 1996 年，ATI 推出了他们第一款 3D 图形处理器 ATI 3D Rage 系列， 该卡性能一般且兼容性较差，但紧接着推出的 3D Rage Ⅱ 就解决了兼容性问题，并提供了两倍的 3D 性能。 之后，3Dfx 于 1998 年推出 VooDoo2，增加了一个纹理处理单元，允许一次处理两个纹理，并推出了著名的 SLI 技术（Scalable Link Interface），可以并联两块 VooDoo2 使用，但其本质上是 3D 子卡，需要配合 2D 卡使用。该技术在之后 3Dfx 被 Nvidia 收购后仍被迭代使用过。1999 年 3Dfx 推出了第一款真正全新设计的 2D+3D 显卡 VooDoo3，但由于其不支持当时流行的卡槽 AGP 2X 的绝大多数特性，仅仅拥有 16bit 显存带宽和 16MB 显存容量，加之 3Dfx 收购 STB System 后不再授权芯片给第三方厂家生产，很多厂商转而与 Nvidia 合作。 1999 年年底,Nvidia 显卡核心代号从 NV5 飞升到 NV10，正式推出 Geforce 256 显卡， 他是首款完全支持 DirectX 3.0 的显卡，也第一次支持使用 T&amp;L 光影转换引擎进行复杂的坐标处理和光源映像的运算。伴随着该显卡的推出，Nvidia 首次提出了 GPU 的概念。 同年，ATI 推出 Rage 128 和 Rage 128 Pro 显卡，并开启“曙光女神”计划推出 ATIRage Fury MAXX，将两颗 Rage 128 Pro 的核心集成在一张 PCB 上面，使用类似 SLI 的技术， 实现显卡性能翻倍，但其性能仍然没有超过 Nvidia。 2000 年，3Dfx 公司在多次跳票后先后推出采用单 VSA-100 芯片方案的中低端第四代显卡 VooDoo4 4500 和采用两块 VSA-100 芯片的 VooDoo5 5500，但旗下的 STB 工厂产能低下， 不能满足市场需要，最终 3Dfx 被 Nvidia 收购。自此，Nvidia 和 ATI 两分天下的局势基本形成。 Nvidia 和 AMD 两分天下的 GPU 发展（由于更新迭代速度较快，因此本部分尽量选取重要的节点，并不会囊括所有产品）2001 年，Nvidia 发布 Geforce 3 系列显卡，核心包含 5700 万个晶体管，支持 Direct8.0 和可编程的 Pixel Shaders；AVI 发布基于 RV200 核心的 Radeon 7500，RV200 本质上是 RV100的频率提高版本。 2002 年，Nvidia 发布 Geforce 4 系列，完整支持 Direct8.0，引入 NfiniteFX 引擎， 且配备了两个顶点着色引擎；ATI 推出基于 R300 核心的 Radeon 9000 系列，首次引入 VPU 视觉处理器技术，率先支持 Direct9.0，并且基于先进的 150nm 制程技术，晶体管数据多达1.1 亿个。 2004 年，Nvidia 于 4 月发布全新采用 NV40 系列核心的 Geforce 6800 系列显卡，其中Geforce 6800 Ultra 具有 16 条渲染管线，全面支持 Direct9.0c，且加入大量新技术，比如 Pure Video 和从收购的 3Dfx 公司演变而来的 SLI 多卡互联技术。 2006 年，Nvidia 8000 系列发布，使用 G80 核心，65nm 工艺制程，内部集成了大量流处理器，具有更大的显存带宽和更高的频率，是首批支持 DX10.0 的产品，且从 G80 核心开始 SLI 技术支持 3 显卡互联，如下图；ATI 推出核心代号 R500 的 Radeon X1000 系列，支持Direct9.0c、HDR、CrossFire 双卡互联，且完美兼容 SM3.0 技术，同年 ATI 被 AMD 收购， 但人们对 A 卡的称呼仍然没有变。 2008 年，Nvidia 发布了采用第二代统一渲染架构的显卡 GTX260 和 GTX280，其 GPU 核心代号为 Tesla，也正是在这时 Nvidia 意识到 GPU 不应该局限于图形计算，而应该走向通用计算，因此 Nvidia 同时推出了 Cuda 计算平台和 PhysX 物理引擎等技术。 2010 年，AMD 发布 Radeon 6000 系列显卡；Nvidia 发布 Geforce300 和 Gefore400 系列，核心研发代号为 Fermi，其中 GTX480 拥有 30 亿个晶体管，480 个 Cuda 核心，显存首次使用GDDR5，支持 DX11 且加入 PolyMorph 引擎技术，拥有强大的曲面细分能力。 2012，Nvidia 的 Geforce600 系列，核心研发代号为 Kepler，增加了 Cuda 核心数，并升级至第二代 PolyMorph 引擎以及纹理单元等；同年，AMD 彻底改良 GPU 核心架构，推出了著名的 GCN 架构，最早采用 28nm 制程技术。囊括了全新的 AMD Enduro（显卡切换技术），AMD ZeroCore 电源技术以及 DDM Audio 独立数字多点音频等技术。 2016 年，Nividia 推出使用全新 Pascal 架构的新显卡 Geforce Rtx 10 系列，同时使用台积电 16nm 和三星的 14nm 制程技术；而 AMD 推出基于第四代 GCN 架构 Polaris 北极星的显卡 Radeon RX400 系列 2018 年，Nvidia 推出 RTX 20 系显卡，首次使用 Turing GPU 的实时光线追踪技术。2020 年，AMD 推出基于第二代 RDNA 架构的 RX6000 系列，支持光线追踪。而 Nividia 发布基于全新 Ampre 安培架构的 RTX30 显卡。2022 年，AMD 发布了 RX7000 系列，Nvidia 则发布了 RTX40 系列。 （4） GPU 与显卡的发展（核心技术脉络）GPU 的发展，离不开核心技术的支持，可以说，等不到背后技术的发展，仅依靠一方的力量无法开创现在 GPU 的发展程度，我们必须关注核心技术的发展，才能在当前中国技术发展被卡脖子的时候，更好地找到突破的方向。 晶体管制作工艺发展GPU 芯片的核心元件是半导体。当今的半导体领域，不同的芯片中只有 GPU 芯片可以以三倍于摩尔定律的速度快速迭代发展。（摩尔定律是英特尔创始人之一戈登·摩尔根据自己的经验总结的半导体发展规律，其核心内容为：集成电路上可以容纳的晶体管数目在每经过大概 18-24 个月便会增加一倍。也就是说，芯片处理器的性能大约每两年能翻一倍。）集成电路从产生到成熟大致经历了这样几个过程：电子管——晶体管——集成电路—— 超大规模集成电路。由于集成电路的发展历史过于庞大，因此这里只对近年来的集成电路和晶体管制作技术作介绍。芯片是由晶体管作为最小单元组成的，一块有限大小的芯片上能集成多少晶体管，一定程度上就决定了芯片的性能。而想集成更多晶体管，就需要更先进的技术将晶体管做的更小，我们平时说的 22nm 制程也就是一个晶体管的大小。以下是近年来制程技术的历史发展情况： GPU 核心架构发展晶体管制作工艺限制了芯片计算强度的上线，但芯片的电路设计同样至关重要，决定着能否将芯片上的晶体管利用率最大化。在 GPU 几十年的发展史中，每一次核心架构的变迁都意味着一次较大的技术更迭和跨越。从 2008 年开始，Nvidia 的 GPU 架构几乎保持了每 2 年一次大更新，带来更多更新的运算单元和更好的 API 适配性，也使得 GPU 的性能不断攀升。AMD 也在近些年不止一次进行过核心架构的整体换血更新。在核心架构每次的大换代之间， 也会针对性地进行一些小升级，比如采用 Kepler 二代微架构的 GK110 核心相较于采用初代Kepler 微架构的 GK104 核心，升级了显卡智能动态超频技术，提升了 CUDA 运算能力，极致流式多处理器（SMX）的浮点运算单元提升 8 倍，加入了 Hyper-Q 技术，提高 GPU 的利用率， 更新了网格管理单元（Grid Management Unit），为动态并行技术提供了灵活性。下图展示了近年来 Nvidia 的 GPU 核心架构的变迁（图源网络）： 接口类型变迁接口类型是指显卡连接主板所采用的接口种类。接口的决定了 GPU 和 CPU 数据传输的最大带宽。PCI 是 Peripheral Component Interconnect（外设部件互连标准）的缩写，几乎所有的主板产品上都带有这种插槽，它是个人电脑中使用最为广泛的接口。PCI 插槽也是主板数量最多的插槽类型，在流行的台式机主板上，ATX 结构的主板一般带有 5～6 个 PCI 插槽，M-ATX 主板也都带有 2～3 个 PCI 插槽，可见其应用的广泛性。显卡发展过程中，出现过 ISA、PCI、AGP（发展过程包括 AGP1X、AGP2X、AGP4X、AGP Pro、AGP8X）等几种接口，所能提供的数据带宽依次增加。2004 年，PCI Express 接口标准被正式提出，目前的显卡大多使用 PCI-e 接口。 显存技术发展计算机运行中需要内存，而图形计算单元同样需要显存。目前比较常看到的 DDR、GDDR、HBM 都是动态随机存储器，即都是内存。DDR 和 GDDR 是我们日常计算机中使用的内存，相对加工工艺成熟，技术标准体系健全，其中 GDDR 是面向显卡和 GPU 的显存。DDR 是 Double Data Rate 的缩写，指的是在一个时钟周期内传输两次数据的双倍速率同步动态随机存储器。GDDR 是用在显卡上的内存，目前也已经发展到了第五代。相对于 GDDR3、GDDR4 而言，GDDR5 显存拥有诸多技术优势，拥有更高的带宽、更低的功耗、更高的性能。而 HBM 是同样是用在显卡中的内存（显存），和 GDDR 区别是采用垂直堆叠半导体工艺生 产的的存储芯片，通过被称为“硅透”(TSV)的线相互连接，实现低功耗、超宽带通信通道， 相比 GDDR5 减少了通信成本，单位带宽能耗更低，制作工艺更高，所以极大减少晶元空间。但加工成本更高。 DirectX 及 Shader Model 发展上文中曾经提到的 SM3.0 是 Shader Model 3.0 的缩写，该技术随 DirectX 更新。更好的 Shader Model 支持在很大程度上丰富了游戏研发时的编程模型。SM3.0 中 3.0 像素渲染引擎 3.0 和顶点渲染引擎 3.0 的最大指令数分别从上一代的 256个和 96 个提升到 65535 个。SM4.0 放弃之前版本中分离的像素渲染引擎以及顶点渲染引擎架构，而是通过统一渲染架构实现像素或者顶点渲染的功能，大幅度地提高 GPU 的资源利用率。加入了新的几何渲染引擎，首次允许 GPU 动态创建或者删除图等。SM5.0 在指令集方面进行了扩充和改进，DirectX 11 采用了针对 HDR 的 BC6H 压缩算法和针对 RGB 的 BC7 压缩算法。并且支持多线程处理技术，通过引入延迟执行这一指令，将一个渲染进程拆分成多个线程，实现了多线程处理一个渲染进程的效果。 二、GPU 发展现状Nvidia 在 2019 年举办的中国 GTC 大会上，设置了两大主题，具体主题如下图所示。可以预见，在未来的发展方向上，以 AI 深度学习等为代表的 GPU 通用计算将会大大增加其权重， GPU 的未来趋势无外乎 3 个：大规模扩展计算能力的高性能计算（GPGPU）、人工智能计算（AIGPU）、更加逼真的图形展现（光线追踪 Ray Tracing GPU)。 在高性能计算方面，NVIDIA 于 最 新 发 布 的 NVIDIA A100 显卡可针对 AI、数据分析和 HPC 应用场景，在不同规模下实现出色的加速，有效助力更高性能的弹性数据中心。A100 的芯片是使用 NVIDIA Ampere 架构的 Tensor 核心。Tensor 核心借助 Tensor 浮点运算 (TF32) 精度，能在不更改代码的前提下，提供比之前的 Volta 核心 高 20 倍之多的性能；若使用自动混合精度和 FP16，性能可进一步提升 2 倍。与 NVIDIA® NVLink®、NVIDIA NVSwitch™、PCIe 4.0、NVIDIA® InfiniBand® 和 NVIDIA Magnum IO™ SDK 结合使用时，它能扩展到数千个 A100 GPU。A100 提供 40GB 和 80GB 显存两种版本，其中的 80GB 版本由于 GPU 显存增加，且提供超快速的显存带宽（每秒超过 2 万亿字节 [TB&#x2F;s]），拥有处理超大型模型和数据集的能力。在光线追踪和图形显示方面，Nvidia 最新发布的RTX4090 作为一款性能出众的 GeForce GPU，在性能、效率和 AI 驱动的图形领域实现了质的飞跃。这款 GPU 采用 NVIDIA Ada Lovelace 架构，配备 24 GB 的 G6X 显存，可为游戏玩家和创作者带来出众的体验。RTX 30 使用的三星 8nm 工艺本质是 10nm，而 RTX 4090 则是采用的台积电定制 4nm 工 艺，至少进步了 2 代半。RTX 4090 拥有 763 亿晶体管，就说每 mm2 有 1.25 亿晶体管，相比0.45 亿的 RTX 3090 Ti 密度提升了 178%，核心频率也从 1860 上升到 2520MHz，提升幅度高达 35%。 （1） 芯片制程技术发展现状2022 年 6 月 30 日，三星电子宣布：3 纳米芯片量产！根据三星官网的数据，3nm 芯片相比之前的 5nm 芯片，性能提升 23%，功耗降低 45%，芯片面积缩小 16%。2022 年 7 月 1 日，长电科技宣布实现 4nm 手机芯片封装，以及 CPU，GPU 和射频芯片的集成封装。 中国芯片现状：全产业链国产化可实现 90nm（中国目前最顶级的、完全自主知识产权的量产化光刻机： 上微电（SMEE）的 SSA600&#x2F;20 型 90nm 光刻机）；全产业链去美化可实现 28nm（中芯国际稳定制程 28nm，使用 ASML 的 DUV 光刻机）； 全产业链最先进的制程是 14nm（中芯国际目前最先进的制程是 14nm，2019 年 14nm 制程工艺量产，代工华为的麒麟 710A 芯片)。 （2） 国内 GPU 产品线发展现状近些年国产 GPU 蓬勃发展，由于在芯片技术上被卡脖子，国内必须加紧 GPU 芯片的研发和设计发展。其中，发展比较快的有以下几个公司： 景嘉微成立于 2006 年 4 月的长沙景嘉微公司是目前唯一专注于国产GPU 芯片设计的上市公司。2014 年 4 月，景嘉微成功研发出国内首款具有完全自主知识产权的高可靠、低功耗 GPU 芯片-JM5400，打破了中国 GPU 市场长期被国外产品垄断的局面。景嘉微 GPU 已完成与龙芯、飞腾、麒麟软件、统信软件、道、天脉等国内主要 CPU 和操作系统厂商的适配工作；与中国长城、超越电子等十余家国内主要计算机整机厂商建立合作关系并进行严格的产品测试；与麒麟、长城、苍穹、宝德、超图、昆仑、中科方德、中科可控、宁美等多家软硬件厂商进行互相认证，共同构建国产化本土化的计算机应用生态。 芯动科技2020 年 10 月，位于武汉的芯动科技宣布与 Imagination 达成合作，将采用多晶粒（chiplet）和 GDDR6 高速显存等 SoC 创新技术，基于 Imagination 全新顶配 BXT 多核架构，开发“风华”系列 GPU。 在信创和算力安全方面，“风华”系列 GPU 内置物理不可克隆 iUnique Security PUF 信息安全加密技术，提升数据安全和算力抗攻击性，支持桌面电脑和数据中心 GPU 计算自主可控生态。这款 GPU 芯片自带浮点和智能 3D 图形处理功能，全定制多级流水计算内核，兼具高性能渲染和智能 AI 算力，还可级联组合多颗芯片合并处理能力，灵活性大大增加，适配国产桌面市场 1080P&#x2F;4K&#x2F;8K 高品质显示，支持 VR&#x2F;AR&#x2F;AI，多路服务器云桌面、云游戏、云办公等应用场景。 三、我的感想通过这几天的查找资料和学习，我对芯片制造、晶体管、GPU 核心架构等都有了一个普遍的了解。我觉得这次学习对我的提升是非常明显的，有很多之前完全不了解的硬件知识可以进行一个系统的认知。在学习的过程中，我也有很多感想。首先就是在查阅一些图形学和 GPU 发展的历史的时候，我惊奇地发现，其实 GPU 技术几乎从上世纪 80 年代才开始发展，最核心最快速的发展进程也就集中在上世纪末和本世纪的20 年内，这让我有一种很特别的感受，似乎就是在我作为一个个体成长起来的同时，图形学和 GPU 软件和硬件发展领域不断有新的技术涌现出来，行业飞速前进，而当我成长到决定之后从事图形学相关研究方向时，发现已经有很多研究成果，这些成果让现在的我们得以站在巨人的肩膀上，享受到更强大的计算机性能，极大地方便了研究的过程。第二，在查阅资料的过程中，我了解到，GPU 的研发是一个非常复杂的过程，涉及到很多方面的技术。当前芯片制造工艺被卡脖子，最严重，也最难突破的关键点是制作精密芯片的光刻机，我们国家没有成熟的光刻机技术，就没办法制作芯片。而目前光刻机只有荷兰的ASML 公司可以生产，一旦该公司不出口给我国光刻机，我们就完全无法自主制作芯片。因此我们国家要想突破这层桎梏，就必须去探索发展光刻机技术。第三，在学习历史的过程中，我也从各公司的发展中学习到一些失败的经验，比如Nvidia 在刚创始时就妄图改变行业规则，而导致了失败，GPU 终究是硬件工具，硬件的制作需要软件来驱动，实现更多功能，我们可以看到历代 GPU 的发展都伴随着能支持 DX 系统的迭代，因此如果不能和目前主流的 Windows、DirectX、OpenGL 相兼容，就不会受到市场的欢迎，自然也就无法在商业上推广。第四，GPU 的发展本质上也需要核心架构的发展，正如之前提到的，没有好的核心电路架构，就算晶体管制程工艺发展好了，也无法释放其计算能力，因此，大力发展我国的微电子电路设计能力是十分有必要的，好的核心架构和技术甚至能获得一定的专利保障。第五，GPU 发展离不开技术的支持，不同厂商的 GPU 都有其核心的竞争技术，比如 Nvidia的 DLSS，AMD 的 FSR 和 Inter 的 XESS。作为一款产品，不拿出新的技术支持，GPU 也终究只是一些复杂精细的元件，Nvidia 目前是一家独大的显卡公司，但与此同时，他也引领着图形学尤其是渲染领域很多核心技术的发展，在我之前写毕业论文的时候就曾经感受过这一点，Nvidia 强大的技术能力也体现在他们有很多工业界的方法去得到更好的图形效果，比如基于方差估计的 MipMap Roughness 优化等。第六，我国目前的 GPU 事业也已经有了一定发展，我们不能妄自菲薄，但是也不能好高骛远，必须承认的是，我们目前独立制造的 GPU 仍与世界先进技术存在着至少两三代的代差，比如国内一些显卡厂商的 GPU 算力只能对标 Nvidia 的 10 系显卡，我国 GPU 发展事业仍然道阻且长。 参考文献[1] Ivan E. Sutherland(Massachusetts Institute of Technology). SKETPAD: A MAN- MACHINE GRAPHICAL COMMUNICATION SYSTEM[J]. PROCEEDINGS—SPRING JOINT COMPUTER CONFERENCE, 1963.[2] NVIDIA. NVIDIA launches the World’s first graphics processing unit: GeForce 256[EB&#x2F;OL]. (2002-01-11) [2023-01-06].[3] BRIDGES R A, IMAM N, MINTZ T M, et al. Understanding GPU power: a survey of profiling, modeling, and simulation methods[J]. ACM Computing Surveys, 2016, 49(3): 41:1-41:27.[4] Jacob Gaboury, Alvy Ray Smith, Mary Whitton,etc. 2021. Making Computer Graphics History Public: SIGGRAPH 2021 Retrospective Panel. In Special Interest Group on Computer Graphics and Interactive Techniques Conference (SIGGRAPH ‘21 Panels). Association for Computing Machinery, New York, NY, USA, Article 8, 1- 3.[5] Prashanta Kumar Das, Ganesh Chandra Deka. History and Evolution of GPU Architecture[M].[6] NVIDIA. NVIDIA HISTORY-A Timeline of Innovation[EB&#x2F;OL]. [2023-01-06]. https://www.nvidia.com/en-us/about-nvidia/corporate-timeline/[7] MACRI J. AMD’s next generation GPU and high bandwidth memory architecture: FURY[C]&#x2F;&#x2F; Hot Chips Symposium. IEEE, 2015: 1-26.[8] BENAMOU J. Big ray tracing[J]. Journal of Computational Physics, 1996, 128(2): 463-474.[9] 熊 庭刚 .GPU 的发 展历 程、未 来趋 势及 研制实 践 [J]. 微纳 电子 与智能 制造,2020,2(02):36-40.[10] Graham Singer. The History of the Modern Graphics Processor-The Early Days of 3D Consumer Graphics[EB&#x2F;OL]. (2022-12-01) [2023-01-06]. https://www.techspot.com/article/650-history-of-the-gpu/[11] Olena. A brief history of GPU[EB&#x2F;OL]. (2018-02-22) [2023-01-06]. https://medium.com/altumea/a-brief-history-of-gpu-47d98d6a0f8a[12] JAKE FRANKENFIELD. What Is a Graphics Processing Unit (GPU)? Definition and Examples[EB&#x2F;OL]. (2021-09-07) [2023-01-06]. https://www.investopedia.com/terms/g/graphics-processing-unit-gpu.asp [13] 丽台科技. GPU 硬件的发展史是怎样的？[EB&#x2F;OL]. (2016-02-13) [2023-01-06]. https://www.zhihu.com/question/21980949[14] biaoJM. GPU-directX 的发展历史[EB&#x2F;OL]. (2018-04-28) [2023-01-06]. https://www.cnblogs.com/biaoJM/p/10186721.html[15] 顾正书. 国产 GPU 风生水起，英伟达和 AMD 感受到威胁了吗？[EB&#x2F;OL]. (2021-03-31) [2023-01-06].https://www.eet-china.com/news/202103310840.html[16] 一个显卡型号及具体参数整合网站.https://videocardz.net/","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"GPU","slug":"GPU","permalink":"https://yaelcassini.github.io/tags/GPU/"},{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/tags/Computer-Graphics/"},{"name":"Computer Graphics History","slug":"Computer-Graphics-History","permalink":"https://yaelcassini.github.io/tags/Computer-Graphics-History/"},{"name":"Nvidia","slug":"Nvidia","permalink":"https://yaelcassini.github.io/tags/Nvidia/"}]},{"title":"计算机动画HW1 - 路径曲线与运动物体控制","slug":"Cardinal-Spline","date":"2023-05-16T08:05:45.000Z","updated":"2024-01-04T06:50:45.806Z","comments":true,"path":"2023/05/16/Cardinal-Spline/","link":"","permalink":"https://yaelcassini.github.io/2023/05/16/Cardinal-Spline/","excerpt":"课程名称：计算机动画实验项目名称：路径曲线与运动物体控制实验日期：2020 年 9 月 27 日","text":"课程名称：计算机动画实验项目名称：路径曲线与运动物体控制实验日期：2020 年 9 月 27 日 codehttps://github.com/YaelCassini/CA_HW1 videohttps://www.bilibili.com/video/BV1T34y1B7WJ/ reporthttps://yaelcassini.github.io/2023/05/16/Cardinal-Spline/ 一、 实验目的和要求 设计并实现一个路径曲线，通过不同参数控制曲线状态，并实现对物体沿生成路线运动的控制。 通过上述实验内容，了解动画动态控制的基本原理何方法，提高动画编程能力。 二、 实验内容和原理 选用 Cardinal 曲线表示运动路径，掌握它的表示和算法，了解不同控制参数对曲线形状和状态的影响。 编写代码实现 Cardinal 曲线算法，对照 cardinal 样条曲线的数学表示和程序之间的对应关系。 给定若干关键控制点的位置（这些控制点可以大致描述某个运动路径的形状），用上述程序计算出控制点之间的插值点，显示出样条曲线。 改变曲线弯曲程度的参数$τ∈[0，1]$大小和控制插值点数目的参数 grain ，观察曲线形状的变化。 在路径曲线上放置一小汽车，使其在沿生成的 cardinal 曲线运动，汽车速度和加速度可以调节。 三、 实验平台Qt 5.14.2 @ Windows 四、 实验步骤1. 首先，对照Cardinal 样条曲线的数学表达和程序中计算代码的对应关系。Cardinal 样条曲线矩阵表示：$$$ P(u) &#x3D; U^T M B $$$其中，u 是幂次最高为 3 的插值变量，且u∈[0,1]， M 是 Hermite 多项式矩阵，B 是曲线中，用户指定的关键点数据。其矩阵展开表示。 其中，$P_i-1，P_i，P_i+1，P_i+2$，是用户指定的控制点控制点，参数τ 控制曲线的弯曲程度。为了实现 Cardinal 样条曲线计算，创建 spline 类。 1234567891011121314151617181920212223242526272829303132333435363738class spline&#123;private: double *ax,*bx,*cx,*dx;//P(u)系数 double *ay,*by,*cy,*dy;//P(u)系数 double *A,*B,*C,*D,*E;//计算弧长所用系数 double* matrix[4];//计算矩阵 double tension;//参数τ int num;//关键点个数 int grain;//每两个关键点之间插值点的个数（含关键点） bool create_flag=false;//是否已经为指针分配空间（判断是否需要delete） vector&lt;QPoint&gt; all_points;//所有点public: spline(); //生成CubicSpline曲线 void set_Spline(vector&lt;QPoint&gt;&amp; vec,int _grain,double _tension); //计算生成的三次样条曲线上所有插值点 void CubicSpline(vector&lt;QPoint&gt;&amp; vec); double calc_Total_length(); //计算曲线总长度 void init_Matrix(); //初始化矩阵 void init_spline_Coefficient(vector&lt;QPoint&gt;&amp; vec);//计算P(u)系数 QPoint calc_Interpolation(int i,double u);//计算内部插值点 point calc_double_Interpolation(int i,double u);//计算内部插值点（坐标为double类型） vector&lt;QPoint&gt;&amp; get_all_points(); //返回储存所有插值点的vector void init_length_Coefficient(int _num);//初始化长度计算参数 double f(int i,double u); //f函数 double simpson(int i,double a,double b);//求样条曲线长度 double calc_U(double s,int i,double u1,double u2);//根据长度计算参数u的值 void clear();//清除数据 ~spline()&#123;&#125;&#125;; 其中 set_Spline 函数根据关键点数组 vec、插值点数目 _grain、和控制曲线弯曲程度的参数 _tension 生成样条曲线所需要的计算数据（如矩阵数值，P(u)系数等）。具体算法见源码。 其中init_Matrix 函数计算矩阵中的数值，即为 P(u)公式中的矩阵M。init_spline_Coefficient 函数计算不同曲线段中的P(u)多项式系数，即为公式中的 M*B（分 x，y 两个方向计算）。具体算法见源码。 2. CubicSpline 函数.根据_grain 值生成不同的u 值，并计算曲线上所有插值点的坐标，储存在名为 all_points 的 vector 中。 123456789101112131415161718192021222324252627282930//计算曲线上所有插值点void spline::CubicSpline(vector&lt;QPoint&gt;&amp; vec)&#123; //当没清除就再次点击生成曲线时，不清除之前的插值点，插入间隔点 QPoint temp(0,0); all_points.push_back(temp); //根据设置的插值点个数参数，计算对应的u值 int num=vec.size(); double* u = new double[grain]; for (int i = 0; i&lt;grain; i++) &#123; u[i] = ((double)i) / grain; //u [0,1] &#125; //根据u值和曲线参数计算插值点坐标 for (int i = 0; i&lt;num-1; i++) &#123; QPoint p1=vec[i]; //加入关键点 all_points.push_back(p1); for (int j = 1; j&lt;grain; j++) &#123; QPoint temp=calc_Interpolation(i,u[j]); all_points.push_back(temp); &#125; &#125; //加入关键点 QPoint p1=vec[num-1]; all_points.push_back(p1); delete []u;&#125; 其中，calc_Interpolation 函数根据曲线段序号i，和参数 u 的不同值，计算具体一个插值点的坐标。 3. 编写 paintWindow 类作为画板，继承自 QWidget 类。在paintWindow 类中编写鼠标回调函数mousePressEvent，记录通过鼠标交互选定的关键点。以及绘制函数 paintEvent，在每次update（）时调用。paintWindow 类定义具体如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class paintWindow : public QWidget&#123; Q_OBJECTprivate: spline* sp; int grain; //每个曲线区间有多少个插值点（包括两端关键点） double tension; //参数，控制曲线弯曲程度 bool ifDrawInpoint=false; //是否显示插值点 int time;//时间 QTimer* timer; //计时器 QPixmap* car[5]; //储存小车位图信息 int car_index;//显示第几种小车 int pen_index=0;//使用第几种笔刷 double speed; //小车速度 double accelerate; //小车加速度 point now_point; //运动当前点 point next_point; //运动下一个点 double ratio; //旋转角度 vector&lt;QPoint&gt; points;//储存所有关键点 bool endflag=false; //小车是否运动到曲线末端public: paintWindow(); void paintEvent(QPaintEvent *); //绘制函数 void mousePressEvent(QMouseEvent *e); //鼠标回调函数 void create_Spline(int _grain, double _tension); //生成并显示cubicspline曲线 void start_Move(double _speed,double _accelarate); //小车开始运动 void stop_Move(); //小车暂停运动 void continue_Move(); //小车继续运动 int numbers(); //关键点个数 double total_length(); //曲线总长度 double now_length(); //小车当前走过的路线长度 int get_spline_index(double now_len); //获取小车当前在哪一段曲线 double get_Ratio(); //获取当前曲线斜率 void change_car(); //改变小车 void change_pen(QPainter&amp; paint); //改变笔刷 void change_DrawInPoint(); //改变是否绘制插值点的控制变量 QPixmap* now_car(); //当前小车位图指针 void clear();private slots: void changeState(); //连接计时器，改变小车坐标，旋转角度等信息&#125;; 4.鼠标回调函数mousePressEvent，记录通过鼠标交互选定的关键点。绘制函数 paintEvent，根据数据变化，绘制所有的关键点、曲线，已经选择是否绘制插值点。 5. 引入QTimer 类作为计时器.每隔一段时间调用 changestate 函数，改变小车坐标及旋转角度等。其中now_point 是当前小车位置，next_point 是下一个小车位置。get_Ratio 函数计算当下曲线的斜率，以及小车旋转角度。 6. MainWindow 设计及按钮槽函数MainWindow 窗口设计如下： MainWindow 类设计： 12345678910111213141516171819202122232425class MainWindow : public QMainWindow&#123; Q_OBJECTprivate: paintWindow* p_w;public: MainWindow(QWidget *parent = nullptr); ~MainWindow();private slots: void on_create_clicked();//绘制曲线并显示 void on_clear_clicked();//清屏 void on_start_clicked();//开始运动按钮槽函数 void on_show_clicked();//展示插值点按钮槽函数 void on_stop_move_clicked();//停止运动按钮槽函数 void on_continue_move_clicked();//继续运动按钮槽函数 void update_numbers();//更新关键点数目 void on_change_clicked();private: Ui::MainWindow *ui;&#125;; 五、 实验结果分析选取控制点： 绘制曲线：同时显示关键点个数和路线总长度。 不同参数对曲线值的影响： 1、不同的 grain：grain&#x3D;5（红色）和 grain&#x3D;60（蓝色） 2、不同的tension（τ）：分别为：0（绿色），0.25（灰色），0.5（红色），0.75（蓝色），1.0（黄色） 显示插值点（白色为内部插值点）： 小车开始运动： 更换小车：","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Computer Animation","slug":"Computer-Graphics/Computer-Animation","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Computer-Animation/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Computer Animation","slug":"Computer-Animation","permalink":"https://yaelcassini.github.io/tags/Computer-Animation/"},{"name":"Spline","slug":"Spline","permalink":"https://yaelcassini.github.io/tags/Spline/"}]},{"title":"计算机动画HW2 - 线性插值和矢量线性插值关键帧动画","slug":"Keyframe-Interpolation","date":"2023-05-16T05:54:42.000Z","updated":"2024-01-04T06:37:57.495Z","comments":true,"path":"2023/05/16/Keyframe-Interpolation/","link":"","permalink":"https://yaelcassini.github.io/2023/05/16/Keyframe-Interpolation/","excerpt":"课程名称：计算机动画实验项目名称：线性插值和矢量线性插值关键帧动画实验日期：2020 年 11 月 6 日","text":"课程名称：计算机动画实验项目名称：线性插值和矢量线性插值关键帧动画实验日期：2020 年 11 月 6 日 codehttps://github.com/YaelCassini/CA_HW2 videohttps://www.bilibili.com/video/BV1zL4y137rn/ reporthttps://yaelcassini.github.io/2023/05/16/Keyframe-Interpolation/ 一、 实验目的和要求 关键帧动画技术是计算机动画中的一类重要技术。本实验选取线性插值和矢量线性插值作为实验内容，旨在了解关键帧动画系统的结构，变形算法的思想以及不同算法对应的不同性能。 本实验要求实现线性插值和矢量线性插值两种关键帧插值算法的图形化界面展示，用户通过鼠标点击交互选定起点帧和终点帧的关键点，由程序自行生成起始帧的图形，并且通过计算得到中间的插值图像，连续播放形成关键帧动画。 二、 实验内容和原理系统包括三个部分： 输入数据：包括初始形状数据和终止形状数据, 一般为事先定义好的整型变量数据,如简单的几何物体形状(苹果，凳子，陶罐)以及简单的动物形状(大象，马)等。也可以设计交互界面，用户通过界面交互输入数据。 插值算法：包括线性插值和矢量线性插值。 线性插值：对于初始和终止形状上每个点的坐标 $P_i$ 进行线性插值得到物体变形的中间形状； 矢量线性插值：对初始形状和终止形状上每两个相邻点计算其对应的矢量的长度和角度，然后对其进行线性插值得到中间长度和角度， 对起点帧和终点帧的第一个关键点进行线性插值得到中间图像的第一个关键点。顺序连接插值后定义的各个矢量得到中间变化形状。插值变量变化范围是[0，1], 插值变量等于 0 时对应于初始形状，插值变量等于 0 时对应于终止形状；数据类型为 double。 插值结果输出。用户可以在图形化界面中自行指定插值帧的个数以及动画刷新频率，程序会根据其设定的参数生成不同效果的关键帧动画并播放动画。用户可以通过点击不同插值方式的按钮，反复播放不同算法生成的插值结果。 三、 实验平台Qt 5.14.2 @ Windows 四、 实验步骤1. 线性插值：指定两幅关键画面图形(最简单的是大小不同的两个矩形，分别由４个点构成。学生也可以自己构造更复杂的图形，如由若干点构成的手图形)， 然后计算两幅图对应点的线性距离来得到它们的中间画面图形。设图形上有 N 个点，$(x_i，y_i), i&#x3D;1,…N$; 初始图形的点记为$(x_{0i}， y_{0i})$，终止图形记为$(x_{1i}，y_{1i})$，生成的中间图形记为$(x_{ti}，y_{ti})$，设生成 M 个画面，则有： $$$ x_{ti} &#x3D; x_0t + x_1(1-t); t&#x3D;1,…M; y_{ti} &#x3D; y_0t + y_1(1-t); $$$ 线性插值代码实现： 12345678910111213141516171819if (mode == 0)&#123; inter_points.clear(); double t = 1.0 * time / grain; for (int i = 0; i &lt; start_points.size(); i++) &#123; QPoint temp; double x0 = start_points[i].x(); double y0 = start_points[i].y(); double x1 = end_points[i].x(); double y1 = end_points[i].y(); double x = (1 - t) * x0 + t * x1; double y = (1 - t) * y0 + t * y1; temp.setX(x); temp.setY(y); inter_points.push_back(temp); &#125; &#125; 2. 矢量线性插值：与线性差值框架类似，但插值变量不再是线性插值中的点坐标表(x, y), 而是把图形曲线上每两个邻近点看成一个矢量，这样就能把由N 个点构成的曲线分解成 N-1 个矢量。初始图形的矢量记为$(a_{0i}， p_{0i})$，终止图形记为$(a_{1i}，p_{1i})$，生成的中间图形记为$(a_{ti}，p_{ti})$, 设生成 M 个画面，则有： $$$ a_{ti} &#x3D; a_0t + a_1(1-t); t&#x3D;1,…M; p_{ti} &#x3D; p_0t + p_1(1-t); $$$ 矢量线性插值代码实现： 1234567891011121314151617181920212223242526272829303132333435//mode==1:普通矢量线性插值(不规定矢量插值方向)else if(mode==1)&#123; inter_points.clear(); double t=1.0*time/grain; QPoint temp; double x0=start_points[0].x(); double y0=start_points[0].y(); double x1=end_points[0].x(); double y1=end_points[0].y(); double x=(1-t)*x0+t*x1; double y=(1-t)*y0+t*y1; temp.setX(x); temp.setY(y); inter_points.push_back(temp); for(int i=0;i&lt;start_vectors.size();i++) &#123; double vec_a0=start_vectors[i].a; double vec_p0=start_vectors[i].p; double vec_a1=end_vectors[i].a; double vec_p1=end_vectors[i].p; if(vec_a0&lt;0)vec_a0+=2*PI; if(vec_a1&lt;0)vec_a1+=2*PI; if(vec_a1-vec_a0&gt;PI)vec_a0+=2*PI; if(vec_a1-vec_a0&lt;-PI)vec_a1+=2*PI; double vec_a=(1-t)*vec_a0+t*vec_a1; double vec_p=(1-t)*vec_p0+t*vec_p1; x+=vec_p*cos(vec_a); y+=vec_p*sin(vec_a); temp.setX(x); temp.setY(y); inter_points.push_back(temp); &#125;&#125; 本次试验中，我还对矢量线性插值进行了三种不同的改良：分别是规定矢量顺时针旋转、规定矢量逆时针旋转以及规定矢量旋转角度小于π。使用控制变量 mode：mode 为 1、2、3 时分别在矢量插值函数代码中插入不同语句。 3.编写paintWindow 类作为画板，继承自 QWidget 类。在 paintWindow 类中编写鼠标回调函数 mousePressEvent，记录通过鼠标交互选定的关键点。以及绘制函数paintEvent，在每次 update()时调用。paintWindow 类定义具体如下： 123456789101112131415161718192021222324252627282930313233343536373839class paintWindow : public QWidget&#123; Q_OBJECTprivate: int grain; //每个曲线区间有多少个插值点(包括两端关键点) int speed; //刷新速度(改为int) int mode=0; //插值模式 int pen_index=0;//使用第几种笔刷 int time;//时间 QTimer* timer; //计时器 vector&lt;QPoint&gt; start_points;//储存起点帧点坐标 vector&lt;Vector&gt; start_vectors;//储存起点帧向量 vector&lt;QPoint&gt; end_points;//储存终点帧点坐标 vector&lt;Vector&gt; end_vectors;//储存终点帧向量 vector&lt;QPoint&gt; inter_points;//储存当前插值帧关键点 bool start_draw=false; //是否绘制起始帧图像 bool end_draw=false; //是否绘制终止帧图像 bool startframe=true; //是否处于起始帧选定状态 bool endframe=true; //是否处于终止帧选定状态public: paintWindow(); void change_frame(); //从起始帧切换到终止帧 void finish_frame(); //结束终止帧交互 void calc_vectors(); //计算关键帧向量 void set_interpolation(int _grain,int _speed, int _mode); //设置动画参数 void paintEvent(QPaintEvent *); //绘制函数 void mousePressEvent(QMouseEvent *e); //鼠标回调函数 int numbers(); //关键点个数 void change_pen(); //改变笔刷 void clear(); //清屏private slots: void changeState(); //连接计时器，改变小车坐标，旋转角度等信息&#125;; 4.鼠标回调函数 mousePressEvent，记录通过鼠标交互选定的关键点，储存在名为start_points 和 end_points 的vector 中。 1234567//鼠标回调函数，鼠标点击，加入关键点void paintWindow::mousePressEvent(QMouseEvent * e)&#123; if (startframe)start_points.push_back(e-&gt;pos()); else if (endframe) end_points.push_back(e-&gt;pos()); update();&#125; 5.绘制函数 paintEvent，根据数据变化，绘制所有的关键点，起始帧图像，以及中间插值图像。(篇幅限制，此处省略部分代码) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//绘制函数void paintWindow::paintEvent(QPaintEvent*)&#123; QPainter paint(this); if (start_points.size() &lt;= 0)return; //没有关键点6. //设置笔刷样式，绘制关键点 paint.setPen(QPen(Qt::black, 5, Qt::DashDotLine, Qt::RoundCap)); for (int i = 0; i &lt; start_points.size(); i++) paint.drawEllipse(start_points[i], 1, 1); for (int i = 0; i &lt; end_points.size(); i++) paint.drawEllipse(end_points[i], 1, 1); //设置笔刷样式，绘制起点帧图像 //paint.setPen(QPen(Qt::blue,3,Qt::SolidLine,Qt::RoundCap)); if (start_points.size() &gt; 0) &#123; if (start_draw) &#123; for (unsigned int i = 0; i &lt; start_points.size() - 1; i++) &#123; QPoint p1 = start_points[i]; QPoint p2 = start_points[i + 1]; paint.drawLine(p1, p2); &#125; QPoint p1 = start_points[0]; QPoint p2 = start_points[start_points.size() - 1]; paint.drawLine(p1, p2); &#125; &#125; //设置笔刷样式，绘制终点帧图像(省略) //设置笔刷样式，绘制插值帧图像 //paint.setPen(QPen(Qt::red,3,Qt::DotLine,Qt::RoundCap)); if (time != 0) &#123; if (inter_points.size() &gt; 0) &#123; for (unsigned int i = 0; i &lt; inter_points.size() - 1; i++) &#123; QPoint p1 = inter_points[i]; QPoint p2 = inter_points[i + 1]; paint.drawLine(p1, p2); &#125; QPoint p1 = inter_points[0]; QPoint p2 = inter_points[inter_points.size() - 1]; paint.drawLine(p1, p2); &#125; &#125;&#125; 6.引入QTimer 类作为计时器，每隔一段时间调用 changestate 函数， 在该函数中，改变当前插值图像信息。通过线性插值或者矢量线性插值计算，将当前插值图像的所有关键点坐标储存在名为inter_points 的vector 中。 7. MainWindow 设计及按钮槽函数MainWindow 窗口设计如下： 五、 实验结果分析分析不同起始帧和终止帧对应不同插值方法的效果和局限性： 1) 普通四边形(几乎不旋转)普通线性插值和第一种矢量线性插值(变换角不大于π)效果都很好，但是规定变换方向为顺时针或者逆时针的则出现了变形问题，通过分析，我找到了原因，这是因为有两条相邻的边，向量旋转方向相反，比如： 上图中绿色标注的边终点帧比起点帧的向量角度更小，而蓝色标注的边，则是终点帧比起点帧的向量角度更大，因此在选择向量顺时针插值时，绿色标注的边可以直接选择角度小于π的旋转方式，而蓝色标注的边则会选择大于π的旋转方式(几乎接近旋转一周)，因此导致图像插值过程中变形。 2) 边交叉的四边形(有一定的旋转角度(0 ~π&#x2F;2)) 可以看出上图中四种插值方式的效果都非常好，顺时针向量插值时，图像呈现顺时针转动效果，逆时针插值时效果相反。 3) 小车大小变化(有一定的旋转角度(π&#x2F;2 ~π)) 可以看出上图中直接线性插值方式会产生明显的变形，不能保持形状平滑变化，而其他三种矢量线性插值方式效果都表现得非常好。 4) 箭头图形(旋转角度接近π) 可以看出上图中直接线性插值方式会产生明显的变形，不能保持形状平滑变化，第一种矢量线性插值方式也会产生非常严重的变形， 而规定了顺时针或者逆时针差值的矢量线性插值方式效果表现得非常好。通过分析，我找到了原因，这是因为对第一种矢量线性差之方式， 有两条相邻的边，向量旋转方向在都接近π的情况下，一个比π略小一些，一个比π略大一些，比如： 上图中绿色标注的边终点帧比起点帧的向量大一个接近π的值， 于是算法在判断后，认为该边应该逆时针旋转插值，而蓝色标注的边， 则是终点帧比起点帧的向量大一个稍大于π的值(也可以看成是小一个接近π的值)，因此算法在判断后，认为该边应该顺时针旋转。这就导致了相邻的两个向量向着不同的方向旋转，因此导致图像插值过程中变形。 5) 复杂图像的关键帧插值动画 如上图，可以看出，除了线性插值有明显的变形之外，其他三种矢量差值方式都表现得效果非常好。 6) 分析总结没有一种关键帧动画算法可以适用于所有的场景，通过对不同起始帧终止帧图像的情形的实践和分析，我总结出： 对于方向基本没有变化的初始帧和终止帧，普通线性插值效果非常不错，第一种矢量线性插值算法(规定矢量旋转角度小于π)也表现非常好，第二三种矢量线性插值算法(规定矢量旋转方向为顺时针或者逆时针)则可能会产生较大的变形，原因是相邻两个矢量旋转角度一个大于零一个小于零。 对于方向有一定变化(0~π)的初始帧和终止帧，普通线性插值算法会使得插值图像有较大的变形(一般情况下，旋转角度大的， 变形程度也会更大)，而三种矢量线性插值算法都表现得效果非常好。 对于方向变化接近π的初始帧和终止帧，普通线性插值算法也会使得插值图像有较大的变形(一般情况下，旋转角度大的，变形程度也会更大)，第二三种矢量线性插值算法(规定矢量旋转方向为顺时针或者逆时针)也表现非常好，第一种矢量线性插值算法(规定矢量旋转角度小于π)则可能会产生较大的变形，原因是相邻两个矢量旋转角度一个大于π一个小于零π。 对于方向变化较大(π~2π)的初始帧和终止帧，效果可以参考第二条。 以上所有总结建立在本实验程序的演示基础上，本实验中产生这些现象的主要原因是，不能保证初始帧和终止帧有完全相同的角度，如果在更多元化的图形化交互界面中，可以将初始帧直接复制放大缩小平移旋转得到终止帧，则每一种矢量线性插值算法都不会产生上述的严重变形现象。 但是在真正的动画制作中，也不可能保证初始帧和终止帧有完全相同的角度，因此本次实验的分析还是非常具有实际意义的。","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Computer Animation","slug":"Computer-Graphics/Computer-Animation","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Computer-Animation/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Computer Animation","slug":"Computer-Animation","permalink":"https://yaelcassini.github.io/tags/Computer-Animation/"},{"name":"KeyFrame","slug":"KeyFrame","permalink":"https://yaelcassini.github.io/tags/KeyFrame/"}]},{"title":"Relightable Neural Renderer 配置环境记录","slug":"Relightable-Neural-Renderer-Environment-Configuration","date":"2023-05-15T07:03:48.000Z","updated":"2023-09-18T08:39:34.727Z","comments":true,"path":"2023/05/15/Relightable-Neural-Renderer-Environment-Configuration/","link":"","permalink":"https://yaelcassini.github.io/2023/05/15/Relightable-Neural-Renderer-Environment-Configuration/","excerpt":"因为项目需要学习了Relightable Neural Rendering， 并尝试把源码下载到本地配置环境运行，被pytorch环境折磨的不轻，把最后成功的过程在这里放一下。原仓库中记录的环境是Ubuntu 16.04 + CUDA 9.0 + gcc 4.9.2 + Anaconda 3，但因为手边没有合适的Linux服务器，所以使用windows环境配置，版本太老的cuda目前已经找不到合适的pytorch支持，最后使用的环境是window 10 + python3.9.16 + pytorch 1.13.0 + cuda 11.7 + anaconda 3，在两台windows系统电脑上都成功跑通了：一台是双3090，一台是1650。","text":"因为项目需要学习了Relightable Neural Rendering， 并尝试把源码下载到本地配置环境运行，被pytorch环境折磨的不轻，把最后成功的过程在这里放一下。原仓库中记录的环境是Ubuntu 16.04 + CUDA 9.0 + gcc 4.9.2 + Anaconda 3，但因为手边没有合适的Linux服务器，所以使用windows环境配置，版本太老的cuda目前已经找不到合适的pytorch支持，最后使用的环境是window 10 + python3.9.16 + pytorch 1.13.0 + cuda 11.7 + anaconda 3，在两台windows系统电脑上都成功跑通了：一台是双3090，一台是1650。 原Github仓库地址：https://github.com/LansburyCH/relightable-nr 环境配置过程原仓库提供的environment环境文件太过杂乱，有很多不必要一一匹配的包，并且其中有很多版本都太老了已经无从下载，因此安装的时候就没有管这个environment了。首先在官网安装cuda11.7版本，anaconda新建一个python3.9的环境，安装pytorch1.13.0，安装命令为： 1conda install pytorch==1.13.0 torchvision==0.14.0 torchaudio==0.13.0 pytorch-cuda=11.7 -c pytorch -c nvidia 安装旧版本的pytorch指令集：https://pytorch.org/get-started/previous-versions/ 安装后需要进行的步骤为： 安装opencv：conda install opencv 安装trimesh：conda install -c conda-forge trimesh 安装torch-geometric。这里参考了：https://blog.csdn.net/xiangfengl/article/details/120254867#%E5%AE%89%E8%A3%85torch-%20geometric12345pip install torch-scatter -f https://pytorch-geometric.com/whl/torch-1.13.0%2Bcu117.htmlpip install torch-sparse -f https://pytorch-geometric.com/whl/torch-1.13.0%2Bcu117.htmlpip install torch-cluster -f https://pytorch-geometric.com/whl/torch-1.13.0%2Bcu117.htmlpip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.13.0%2Bcu117.htmlpip install torch-geometric pip install pyshtools pip install openexr conda install tensorboardX pip install pytorch_msssim 与此同时，源码需要做的修改： nerural-renderer模块中，rasterize_cuda_kernel.cu中，将#if __CUDA_ARCH__ &lt; 600 and defined(__CUDA_ARCH__)修改为#if __CUDA_ARCH__ &lt; 600 &amp;&amp; defined(__CUDA_ARCH__)。 将源码cuda文件夹下所有的代码中的AT_CHECK替换为TORCH_CHECK。 在precompute.py, stitch_lp.py, train_rnr.py三个文件开头添加：12import osos.environ[&#x27;OPENCV_IO_ENABLE_OPENEXR&#x27;] = &#x27;TRUE&#x27; 将np.int修改为np.int_ 由于在windows系统下，将num_workers = 8修改为num_workers = 0。 把train_rnr.py 中的 if opt.exp_name is not &#39;&#39;: 修改为 if opt.exp_name != &#39;&#39;: 使用windows系统，需要把sh文件修改为bat文件，在线转换工具：https://daniel-sc.github.io/bash-shell-to-bat-converter/","categories":[{"name":"Relighting Project","slug":"Relighting-Project","permalink":"https://yaelcassini.github.io/categories/Relighting-Project/"}],"tags":[{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Neural Rendering","slug":"Neural-Rendering","permalink":"https://yaelcassini.github.io/tags/Neural-Rendering/"},{"name":"Relighting","slug":"Relighting","permalink":"https://yaelcassini.github.io/tags/Relighting/"},{"name":"Anaconda","slug":"Anaconda","permalink":"https://yaelcassini.github.io/tags/Anaconda/"},{"name":"Pytorch","slug":"Pytorch","permalink":"https://yaelcassini.github.io/tags/Pytorch/"}]},{"title":"Pytorch学习笔记","slug":"Pytorch-Notes","date":"2023-05-08T06:47:49.000Z","updated":"2023-09-21T07:15:31.567Z","comments":true,"path":"2023/05/08/Pytorch-Notes/","link":"","permalink":"https://yaelcassini.github.io/2023/05/08/Pytorch-Notes/","excerpt":"Pytorch小白学习。","text":"Pytorch小白学习。 U-net网络结构： https://zhuanlan.zhihu.com/p/313283141 nn.ReplicationPad3d 使用输入边界的复制对输入张量进行填充。 Parameters padding(int,tuple)–填充的大小。如果是int，则在所有边界中使用相同的填充。如果是6 tuple，则使用(padding_left,padding_right, padding_top, padding_bottom, padding_front, padding_back ) torch.nn.Conv3D 3D卷积, 输入的shape是(N, C_{in}, D, H, W) (N, C_{in}, D, H, W)(N, C_{in}, D, H, W)，输出shape(N, C_{out}, D_{out}, H_{out}, W_{out}) 其中，就是batch_size；C_{in}对应着输入图像的通道数，比如RGB图像通道数为3；D为深度，H、W则是tensor的长宽。 torch.nn.BatchNorm3d torch.nn.LeakyReLU pytorch中的relu,sigmiod,tanh等激励函数(激活函数）： https://blog.csdn.net/weixin_44912159/article/details/104994863 train()和eval()模式的区别","categories":[{"name":"Relighting Project","slug":"Relighting-Project","permalink":"https://yaelcassini.github.io/categories/Relighting-Project/"}],"tags":[{"name":"GPU","slug":"GPU","permalink":"https://yaelcassini.github.io/tags/GPU/"},{"name":"Pytroch","slug":"Pytroch","permalink":"https://yaelcassini.github.io/tags/Pytroch/"},{"name":"Machine Learing","slug":"Machine-Learing","permalink":"https://yaelcassini.github.io/tags/Machine-Learing/"},{"name":"Nerual Rendering","slug":"Nerual-Rendering","permalink":"https://yaelcassini.github.io/tags/Nerual-Rendering/"}]},{"title":"计算机中的颜色管理知识","slug":"Color-Management","date":"2023-04-24T08:26:01.000Z","updated":"2024-01-05T09:08:35.407Z","comments":true,"path":"2023/04/24/Color-Management/","link":"","permalink":"https://yaelcassini.github.io/2023/04/24/Color-Management/","excerpt":"颜色管理是图形学中一个非常重要的课题，图形学与图像和颜色的可视化息息相关，但是我们有时候追求的是储存元数据的信息，有时候又追求的是图像看上去合理，符合美术工作人员的期待。不同的显示器、不同的颜色空间管理以及不同的人眼都会产生颜色的感知偏差。","text":"颜色管理是图形学中一个非常重要的课题，图形学与图像和颜色的可视化息息相关，但是我们有时候追求的是储存元数据的信息，有时候又追求的是图像看上去合理，符合美术工作人员的期待。不同的显示器、不同的颜色空间管理以及不同的人眼都会产生颜色的感知偏差。 参考： Games101-Lecture 20-Color and Perception 朵格Dolag：https://zhuanlan.zhihu.com/p/611850037 如云般飘过：https://zhuanlan.zhihu.com/p/36968533 赵庆宗：https://zhuanlan.zhihu.com/p/31374619 故园社南：https://blog.csdn.net/qq_45207442/article/details/105031491 https://ciechanow.ski/color-spaces/ 学习过程中，如有错误，欢迎指正。 一、Gamma 矫正Gamma矫正最初是为了适应CRT显示器的非线性输出问题，由于sRGB色彩空间提出的时代，流行的CRT显示器显示图片时，实际发出的亮度和电信号(也就是颜色数据)表示的亮度不是线性的，CRT显示器的非线性输出具体来说是，如果输入一个0.5的值到显示器，显示器会呈现出0.218的值。因此需要提前对图像数据进行一个1 &#x2F; 2.2 &#x3D; 0.4545的一个幂次变换，此过程称为伽马校正，校正过后的图像数据处在伽马空间中。但是其实sRGB并不只是一个单纯的伽马校正，是个接近1 &#x2F; 2.2的分段函数。而目前Gamma矫正的存在则是主要为了适应人眼的非线性感知问题。人眼对暗部细节的感知更加丰富，因此使用gamma矫正在储存图像时，相当于对源数据的暗部进行了展开，亮部进行了压缩，这样能储存更丰富的暗部细节信息。但gamma矫正本质上是一种编码格式，并不应该影响实际的数据，比如源数据在储存为RGB格式时做了gamma矫正，那么在从RGB文件中读取时要做反gamma矫正重新映射回源数据。另外，由于历史遗留原因，我们使用的大部分显示器，仍然沿袭CRT显示器的这种非线性输出，也就是我们再把数据传递给显示器时需要做一个类似gamma矫正的变换，而显示器则会做一个类似CRT显示器的反gamma变换。 二、色彩模型 Color Model色彩模型规定了颜色能够被哪些分量(也就是原色)进行表示。举例来说RGB色彩模型下的颜色就可以用RGB三原色的数值来进行表示，比如存在一个颜色可以表示为[Red &#x3D; 0.2, Green &#x3D; 0.75, Blue &#x3D; 0.13]。常见的色彩模型有RGB、CMYK、HSV、HSL等。其中，电子设备流媒体等一般都使用RGB色彩模型，这也是最常用的色彩模型，而印刷一般使用CMYK色彩模型。HSV色彩模型更多用于设计中调整颜色。 RGB计色法及三基色概念色彩空间的基础就是颜色，要弄清楚色彩空间首先就要弄清楚颜色是怎么被记录和显示的。各种不同波长的光线通过直射、折射或者反射的方式进入我们的眼睛，刺激视网膜上的锥状细胞来产生颜色的感觉。锥状细胞分为三种：L（Long-长波）型、M（Medium-中波）型和S（Short-短波）型。其识别颜色的波长的峰值分别为：L型-564580nm；M型-534545nm；S型-420~440nm。由于 L型 细胞的敏感区更接近红色，所以称为感红细胞；M型 为感绿细胞；S型 为感蓝细胞。如下图： 由于人类对不同颜色光线混合的反应是线性的（格拉斯曼定律），对于不同光谱所组成的色光，只要对这三种锥状细胞产生的刺激相同，就可以形成一样的色彩感觉，所以几乎所有的颜色都可以由三种基本颜色混合而成。 在1931年，CIE（国际照明委员会）规定的三基色为：700nm-红光；546nm-绿光；435nm-蓝光，并且用配色实验（增加或减少 RGB 颜色，使待配色与 RGB 混合色视觉效果相同）配出了色光的 RGB 分布系数。 值得一提的是，RGB 计色会出现负数，出现负数的原因在于 RGB 亮度是累加的，如果出现比较暗的光线，则必须在待配色中增加 RGB 分量。如下图 R 为负意味着，只靠三基色的混合无法达到和该波长的光视觉效果相同，只能在该波长的光里面加红基色，才能达到两边视觉效果相同，因此就出现了R的负值。 XYZ计色法上文说到了 RGB 混合中出现了负值，容易产生错误；且 RGB 不能直观体现亮度的信息。为了解决 RGB 计色所存在的问题，CIE 通过对 RGB 计色法的线性变换，创造出了 XYZ 计色法。XYZ 计色法中的 Y 分量单独表示亮度，X 与 Z 不包含亮度信息，且 XYZ 永远为正。XYZ 并没有实际的物理意义，为虚基色，CIEXYZ 所能表述的颜色要比 CIERGB 多，它的色度由 XYZ 的比例来决定。值得注意的是，从RGB到XYZ的变换本质上是一个二维的线性变换，是在$r+g+b&#x3D;1$这个前提确定的平面上进行的从rg空间到xy空间的变换，变换基于这样一个实验前提：国际照明委员会（CIE）在颜色匹配实验中发现，当红R、绿G、蓝B这三原色光的相对亮度比例为1.0000： 4.5907 ： 0.0601时就能匹配等能白光，所以CIE选取这一比例作为红、绿、蓝三原色的单位量，即（R）、（G）、（B）&#x3D; 1：1：1。尽管这时三原色光的亮度值并不相等，但CIE却把每一原色的亮度值作为一单位看待，所以色光加色法中红、绿、蓝三原色光等比例混合（r&#x3D;g&#x3D;b&#x3D;0.333）结果为白光。具体来说，在rg空间确定xz直线的方法就是：联立$L &#x3D; 1.0000r + 4.5907g + 0.0601b &#x3D; 0$和$r+g+b&#x3D;1$，如下图下图为 XYZ 混色曲线。 三. 不同的Color Space以及其换算由于我们是进行设计、创作、游戏等，最终都会使用显示器、屏幕等进行显示，而这些设备一般都是使用RGB色彩模型，因此此文章只讨论RGB色彩模型相关的问题。 白点(White Point)和原色(Primaries)白点是一个色彩空间里设定为白色的点，用开尔文或者色度来表示。原色就是一个色彩空间的基本颜色，其他颜色都可以通过这些基本颜色进行表示，也用色度表示。每个色彩空间有不同的原色、白点。 以DCI-P3 D65色彩空间为例(D65表示其白点为6500开尔文色温的颜色)，其白点为(0.3127, 0.3290)，原色为R &#x3D; (0.68, 0.32)，G &#x3D; (0.265, 0.650)，B &#x3D; (0.15, 0.06)。 CIE XYZ颜色空间CIE XYZ颜色空间中的XYZ是对之前CIE RGB颜色空间的一个修改，因为之前CIE RGB颜色空间不能表达出人眼可见的所有颜色。CIE XYZ颜色空间可以表达所有的可见颜色，是绝对颜色空间，因此常常用这个CIE xy色度图来度量其他颜色空间的色域(Gamut)，这种表示方法也叫三色刺激值(Tristimulus Value)表示，也称为色度(Chromaticity)表示。 RGB色彩空间RGB色彩模型下有很多色彩空间，常见的有sRGB、Adobe RGB、ProPhoto RGB、DCI-P3、Rec.2020、Rec.709、ACES2065-1、ACEScc&#x2F;ACEScct、ACEScg。 sRGBsRGB(Standard RGB)是目前最常用的色彩空间，它是一个带有伽马的色彩空间。 Rec.709色彩空间也是一个伽马空间，通常认为它的伽马值为2.4，但实际上也是个分段函数。Rec.709和sRGB其实色域差不多。 DCI-P3DCI-P3蛮怪的，它的色温是6300开尔文，但不是在CIE Standard Illuminant下的，所以不能称为63D，而且白点稍微有点发绿，好怪。然后它是一个系数为2.6的伽马空间，这是为了能适当兼容sRGB。但是DCI-P3色域比sRGB大了有30%，因此许多HDR设备都用这个色彩空间，比如你的手机。 Display-P3Display-P3是苹果创造的色彩空间，要正常一点。它使用65D的白点，系数为2.2的伽马空间，非常兼容sRGB，感觉还不错。 Rec.2020Rec.2020又比上面两个P3的色域大上一圈，色域相当不错，但是显然造价更高，在激光影院可能会使用。 Adobe RGBAdobe RGB和DCI-P3的色域面积是差不多的，然而是两个差别不小的色彩空间，所以说在选购显示器的时候不要只关注色域的面积，主要看它的色度图以及和你想要的色彩空间的覆盖率。 四. 色域 Color Gamut由于 CIE XYZ 三基色所合成的色光是由他们的比值所决定的，因此我们可以对xyz分量做归一化，取 $x+y+z &#x3D; 1$。相当于原来的色域在三维空间中是一个三维的范围，但是我们现在只取$x+y+z &#x3D; 1$这个平面上的部分考虑，如下图：在这个平面上，已知其中两项就可以得到 XYZ 计色法的色度，所以 XYZ 计色法的色度就可以由 xy 二维坐标来表示，我们取该平面在二维空间下的投影，就得到了我们在很多地方都可以看到的马蹄图，他的学名叫CIE XYZ色度图。 马蹄形的左右两边的轮廓线代表了波长由 380nm-700nm 连续变化的单色光；马蹄形的底边代表了紫红色光。值得一提的是，紫红色光并不是单色光，而是由红色（700nm）和紫色（380nm）混合而成。在马蹄形内部，越靠近马蹄形边缘的颜色饱和度越高。 相信大家都接触过不少的色域，比如有些相机里会自带一些色域：sRGB、Adobe RGB。还有部分厂家会有自己特有的色彩空间，如索尼的 S-Gamut3、松下的 V-Gamut、富士的 F-Log-Gamut；以及各种国际标准色彩空间：ProPhoto RGB、P3、Rec.709、Rec.2020 等等。这些色域都可以在色彩空间色度图中表现出来，严格来讲这些色域都是颜色空间 CIEXYZ 的子集。可以通过线性变化来得到。 上图为各个色域在 CIEXYZ 色度图上的映射，三角形三个顶点分别是对应 RGB 的颜色。Rec.709 与 sRGB 的范围相同。 确定 RGB 三点以及白点的值，就可以表达一个色域。色域中的 RGB 值可以通过线性变化得到 XYZ 的值：$$ \\begin{bmatrix} x\\y\\z \\end{bmatrix} &#x3D; \\begin{bmatrix} M \\end{bmatrix} \\begin{bmatrix} r\\g\\b \\end{bmatrix}$$各个色彩空间的 [M] 值 可以通过标准制定者给出的数值得到，可以参考网站：http://www.brucelindbloom.com 或是各个白皮书中找到。 目前被大多数显示设备所接受并使用的 Rec.709 标准使用的色域与 sRGB 相同，并且网络上显示图片的标准也是 sRGB，这就意味着 sRGB 目前统治着大部分的市场。部分相机虽然支持更大的色域范围，如：ProPhoto RGB、Adobe RGB、S-Gamut3、F-Gamut 等，但是要上传到网络空间则须转换到 sRGB 的色域。 若色域未经转换就直接丢给 Rec.709 标准的显示器或者上传到网络空间的话，会产生颜色偏差。这是因为 Rec.709 标准的显示器把更宽广色域的 RGB 三值直接对应到 sRGB 的值中所产生的偏差，通常会出现饱和度下降的情况；若两个色域的白点也不一致的话，色温也会出现偏差。 下图为 ProPhoto RGB 和 sRGB（Rec.709）的色域对比，同样的重心坐标在两个不同的颜色空间代表的是不同的颜色： 五. 颜色变换管线微软有在文档里写普通的颜色变换管线和Windows实现任意两个色彩空间转换的过程。 颜色变换管线首先0是原本的色彩空间，首先如果这个色彩空间不是线性空间，则需要先进行反伽马变换1，变换完后就到了线性空间，线性空间的颜色就可以通过颜色矩阵2这种线性变换来变换到其他颜色空间，如果目标颜色空间也是一个伽马空间，则要施加一个对应的伽马校正3，然后就得到了转换后的颜色空间。 Windows的颜色变换管线Windows使用单独的管线。其实这个例子都不太像是颜色变换管线而是图像显示管线了。介绍一下各个步骤： 第0步，那就是Framebuffer里面渲染得到的颜色数据，它们都是RGB伽马空间的，可以是sRGB, sYCC, HDR10, 或者scRGB颜色空间。 第1步，反伽马，转换到线性空间。 2a、2b、2c是颜色空间转换的三个变换，它们乘在一起就是颜色空间的转换矩阵。 2a：从线性空间转换到CIE XYZ的绝对颜色空间。 2b：做一些例如校准的调整，可编程。 2c：从CIE XYZ转换到目标的线性的RGB色彩空间上。 2a和Framebuffer相关，2c和显示器相关，普通应用可以控制2b这个矩阵。 显示颜色也分两步。 3a：使用EOTF来伽马校正，由显示器驱动完成。 3b：做一些例如校准的调整，又是可编程的那种。 3a的转换由wire format color space(实在搜不到)来指定，但应该就是显示器的颜色空间，例如SDR显示器就需要做一次伽马校正，HDR10显示器就需要做一次逆PQ(或称ST.2084)电光传输函数的变换。 完成上述步骤后，Framebuffer(没错，还是在Framebuffer里)里的数据就会扫描到你GPU连接显示器的那条线里，然后显示。 六. 色调映射(Tone Mapping)简单地从色域较大的空间转换到色域较小的空间，一定会产生SDR中无法表现的颜色，如果直接将超出范围的颜色进行截断，就会出现如大片相同颜色，因此需要在转换之前先进行色调映射。此外HDR图像是浮点表示的，可能会产生值超过1的部分，但SDR是归一化的色彩空间，所以数据上来说，其归一化后的数值只能从0到1，要将HDR图像转换到SDR，就需要色调映射。 色调映射的基本原理就是把颜色变化从更大的色域范围压缩到更小的色域范围，但是仍保持颜色的差别和对比。 色调映射的算法蛮多，比较常用的有CE Tone Mapping、Filmic Tone Mapping，但现在基本都被ACES色调映射统一了。这篇文章说ACES色调映射是ACES提出的，但是我找不到任何证据(比如ACES官网上查不到任何色调映射相关的文字)说明这是ACES提出，而应该是Epic Games的图程Krzysztof Narkowicz基于ACES的ODT提出的，他在他的博客中有提到，在研究出来之后称为了UE的默认色调映射函数，UE的文档可以看到。 七. ACES(Academy Color Encoding System)流程这玩意太难了先搁置。","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"}],"tags":[{"name":"Color Space","slug":"Color-Space","permalink":"https://yaelcassini.github.io/tags/Color-Space/"},{"name":"Gamma Correction","slug":"Gamma-Correction","permalink":"https://yaelcassini.github.io/tags/Gamma-Correction/"},{"name":"Tone Mapping","slug":"Tone-Mapping","permalink":"https://yaelcassini.github.io/tags/Tone-Mapping/"},{"name":"Color Gamut","slug":"Color-Gamut","permalink":"https://yaelcassini.github.io/tags/Color-Gamut/"}]},{"title":"Shadow Rendering 阴影绘制方法的发展过程","slug":"Shadow-Rendering","date":"2023-03-29T12:16:36.000Z","updated":"2023-09-19T09:59:06.790Z","comments":true,"path":"2023/03/29/Shadow-Rendering/","link":"","permalink":"https://yaelcassini.github.io/2023/03/29/Shadow-Rendering/","excerpt":"课程名称：计算机图形学（研究生）报告主题：图形处理器(GPU)的历史、现状和展望提交日期：2023 年 1 月 1 日","text":"课程名称：计算机图形学（研究生）报告主题：图形处理器(GPU)的历史、现状和展望提交日期：2023 年 1 月 1 日 渲染技术研究报告——阴影绘制技术的发展历程及方法比较一、前言阴影绘制是真实感渲染中非常重要的一个模块，对提高场景的真实度有着至关重要的作用，不管是使用光栅化的流程还是光线追踪的流程进行场景绘制，阴影绘制的技术都经过了多次的更新和迭代。我也在一些课程中学习过一些简单的阴影绘制方法，因此想借此机会对所有的阴影绘制方法做一个系统性的梳理和总结。阴影绘制的方法按照时间发展顺序主要有Shadow Volume算法、Shadow Map算法、PCF算法、PCSS算法、VSM算法等等。首先，阴影的定义是Shadow is the region of space for which at least on point of the light source is occluded，也就是绘制中那些至少对一盏光源，其没有被直接照亮而是被其他物体遮挡住的区域。图源Real-Time Rendering 4th如上图所示，要实现阴影的绘制，需要考虑的有光源、遮挡物（Occluder）、接受物（Receiver）、本影区（umbra）半影区（penumbra）等。其中，对于接收物体是平面的情况，我们可以直接通过光源位置、物体几何等信息进行光线求交几何计算，解析地得到平面上阴影的形状和范围（如下图），但是这显然无法处理复杂的场景阴影绘制，也不是我们需要的通用的方法，也因此本文仍然选择聚焦于在任何曲面或者几何体上产生阴影的通用方法。图源Real-Time Rendering 4th 二、Shadow Volume算法诞生及其改进图源Real-Time Rendering 4thShadow Volume是Franklin在1977年提出的阴影绘制算法，虽然在今天这个算法由于其较大的开销已经不太被使用，但我们仍然可以从中学到一些基础的思维方式，并且由于该算法不是在图像空间进行的，因此不会像Shadow Map一样收到采样的影响。Shadow Volume算法的基本思想是对于投影物体（以一个三角形为例），以光源为出发点建立一个类似金字塔的无限延伸的体积结构，并切除在光源点和投影物体之间的部分。所有包含在剩余体积范围内的区域都处在阴影中。对于场景中的所有物体，都可以使用该方法建立其投影金字塔。在正常绘制场景时，对于每一哥Fragment，都需要遍历所有的投影金字塔，计算其是否被包含在其中并记录被包含的次数。被包含的越多，则该处阴影强度越大（阴影颜色更暗）。以此类推，绘制完成所有的Fragment。可想而知，对于较为复杂的场景，Shadow Volume方法需要的时间和空间开销都是巨大的，不仅需要管理每一个投影物体的投影金字塔，还需要对任何一个片元进行所有金字塔的遍历测试。如果场景中包含N个物体，且都可以投射阴影，则该算法的时间复杂度将达到O(n²)。 三、Shadow Map算法的诞生及其改进早在 1968年，Arthur Appel就在研究隐藏面消除时提出了光线投射算法（Ray Casting），并首次给出了光线跟踪算法的描述。其具体思路是从每一个像素射出一条射线，然后找到最接近的物体挡住射线的路径，而视平面上每个像素的颜色取决于从可见光表面产生的亮度。 1974年，Catmull为了解决消隐问题提出了Z-Buffer算法，该算法的主要思路是使用一个屏幕空间的缓存，记录每一个像素点所对应的最小深度，在绘制每一个多边形时，与对应像素位置的当前最小深度做对比，如果小于该值则证明该多边形可见，绘制并更新Z-Buffer。Z-Buffer算法思路简单且通用性较好，为之后图形学的许多技术提供了理论基础。 因此在1978年，William以Z-Buffer算法为基础，提出了Shadow Map算法，主要思想就是维护一个从光源看出的Z-Buffer（也就是Shadow Map）。能从光源出发直接看到的区域就不属于阴影，否则属于阴影。图源【3】Shadow Map是一个2-pass的算法。算法主要步骤为： 第一个pass：以光源为视点出发绘制场景，只需要绘制深度信息，像Z-Buffer算法一样记录屏幕空间上每一个像素点的最小深度，得到 Shadow Map。 第二个Pass：正常绘制场景。 在每个像素绘制时通过坐标转换，计算出其在光源坐标系下对应的屏幕坐标。 如果其在光源坐标系下的深度在浮点数精度下小于等于Shadow Map上对应位置的当前值，则证明该点被光源直接照亮，否则证明该点在阴影中。其中，需要做的坐标转换为：首先根据片元当前的屏幕坐标，乘以当前相机投影矩阵的逆矩阵得到其世界坐标，再根据光源坐标系下的投影矩阵计算出在Shadow Map的屏幕坐标。其中，对于太阳光这样的平行光我们需要使用平行投影方式绘制Shadow Map，而对于点光源则应该使用透视投影绘制Shadow Map。图源Real-Time Rendering 4th 不难想到，如何选择Shadow Map绘制的视口是一个至关重要的问题，如果光源坐标系下的视口刚好可以包含正常绘制时所有能看到的物体，如上图中所示，则算法可行，否则可能会出现正常绘制时的某些Fragment对应的光源坐标系下的坐标超过视口范围，在Shadow Map上没有对应点，无法判断是否属于阴影的情况。另外，对于在场景中间的点光源（在不同方向上都可能投射阴影），则一般选择使用一个six-view cude，分别绘制不同方向上的Shadow Map。但这样的解决方法同样也带来了不同view交界处的走样问题。 Shadow Map算法的效果很大程度上受限于 Shadow Map的分辨率，因此在绘制Shadow Map时进行场景物体的剔除和剪枝也是十分有必要的，对于那些在相机中不可见的物体，在Shadow Map中也不需要绘制，这样可以有效缩小Shadow Map绘制的范围，从而对同样分辨率的Shadow Map达到更高的利用率和绘制精度。图源Real-Time Rendering 4th 但是普通的Shadow Map算法不可避免地存在着问题，主要的两个问题有自遮挡问题（“surface acne”）和锯齿状走样问题。图源网络 其中，自遮挡问题产生的原因是如下图，在从灯光出发进行Shadow Map绘制时，视线方向与接收投影的平面方向存在夹角，但是绘制时仅采样了像素中心的深度值作为整体的深度值。在第二个pass比较深度是就会出现本来同一平面但是有部分像素通不过Shadow Map的深度测试这种情况，从而导致如下图所示的阴影错误。对该问题可以使用设置比较的bias来尝试解决，但是bias过小时不能完全避免这种错误的产生，过大时又会产生如下图中右边所示的阴影和物体不贴合的错误（被称为Light Leaks 或者 Peter Panning），出现物体悬浮的绘制效果。图源Real-Time Rendering 4th 另外一个解决Self-shadowing自遮挡问题的思路是修改绘制Shadow Map的过程，比如说绘制时进行面剔除（Face Culling），仅绘制模型的背面。这种方法在物体都是流形时（拥有背面和反面）效果较好，能很好地避免surface acne问题。但是无法处理某些模型只有单个面的情况。一种沿着这个思路的改进方法是Second-depth Shadow Map，是在绘制Shadow Map时选择front face和back face的中间值作为Shadow Map的采样值。图源Real-Time Rendering 4th 而另一个问题锯齿状走样本质上还是由于Shadow Map的分辨率限制导致的，由于Shadow Map的绘制视口与相机绘制视口不同，可能会导致在相机坐标系下占很大部分的空间在Shadow Map中仅仅对应几个像素，因而导致其不能完全表达出该部分的相互遮挡信息，正常绘制时的较大区域可能整体无法通过Shadow Map的深度测试，产生锯齿状走样。 为了解决分辨率不够导致的锯齿状走样问题，Nvdia提出了CSM算法（Cascaded Shadow Maps），也就是使用级联的阴影贴图。其主要思想就是通过物体的距离，动态地进行不同分辨率的Shadow Map的绘制，比如说对远处的物体采用分辨率较小的Shadow Map，而对于较近处的物体则采用分辨率较大Shadow Map。LearnOpenGL中提供了一种基本的思路：首先使用相机的视图和投影矩阵，反向计算出它所定义的视锥体在世界坐标系下的位置，然后将其划分为 n 个子视锥体，其中第i个截锥体的远平面是第i+1个截锥体的近平面。然后对于每一个截锥体中的物体依次渲染一张Shadow Map，在正常绘制时，则同样根据Fragment的Z值计算其应该属于哪一个截锥体，从而选取不同的Shadow Map。需要注意的一点是，如果某个物体不在相机视锥体内，但在光源和某个截锥体之间，则绘制Shadow Map时也需要对其进行考虑，否则也会造成阴影绘制的错误。 四、PCF算法&amp;PCSS算法普通的Shadow Map只能得到非零即一的阴影测试值，只能绘制硬阴影，这显然不能满足我们真实感渲染的需求，因此在1987年，William T. Reeves引入了本来用于做抗锯齿的PCF算法（Percentage Closer Filter）到阴影绘制领域，在此基础上改良得到Shadow Map算法得到了PCSS算法。该算法的基本思想是对深度测试的结果进行Filter（而不是直接对Shadow Map进行filter）。具体操作方法是：在第二个Pass进行正常绘制时，对于每一个Fragment的深度测试，不仅比较直接对应的Shadow Map像素，还要与其邻域内（比如说3*3）像素进行深度测试，小于等于（表示不在阴影中）则记为0，大于则记为1，得到一个01的矩阵，对其求平均得到一个0-1之间的浮点数值，则代表该像素的阴影值，这样就能实现软阴影的效果。图源【7】在以上这种思想的指导下我们不难发现，filter的邻域大小一定程度决定了得到的阴影边缘的平滑程度，也就是邻域越大越容易得到“软”阴影。而在生活中，当投影物体靠近接收物体时，我们得到的阴影边缘更硬，反之则较软。以此为指导，Fernando在2005年提出的PCSS算法是在PCF进行阴影绘制基础上的进一步改进。其主要思想是使用如下图所示的几何关系来估计半影区（Penumbra）的宽度（也就是阴影的软硬程度）。其中$d_blocker$指的是投影物体的深度也就是Shadow Map中储存的深度，$d_receiver$指的是接收物体的深度也就是当前片元的深度。而用此方法计算出的半影区的宽度可以指导我们进行PCF中filter邻域大小的选择。图源【8】 PCSS算法的主要流程为： Blocker Search 在一个小的邻域内采样得到投影物体的平均深度。 Penumbra Estimation 根据投影物体的平均深度和当前片元的深度计算半影区的宽度。 Percentage Closer Filtering 根据计算出的半影区的宽度选定filter的邻域大小并进行PCF计算。其中，在第一步进行投影物体深度的采样时，采样区域的大小可以用下图所示的这种方式选定，也就是根据投影物体的深度和光源的大小计算选定。图源【8】 五、VSM算法和VSSM算法VSM算法全称为Variance Shadow Mapping，VSSM算法全称为Variance Soft Shadow Mapping，这两种算法相互承袭，是一种使用统计学知识对PCSS算法的改进方案，其主要的思路是通过对Shadow Map中Block内的深度分布进行统计学估计，避免大量采样计算PCF的过程，从而加快阴影绘制速度。PCF算法的基本思想就是在某一个邻域内测试有百分之多少的像素能使得当前片元通过深度测试。也就是测试当前片元的深度在该邻域内分布在百分之多少。VSSM算法引入了统计学的知识，假设当前邻域内的深度分布符合高斯分布，如果要测试当前片元的深度在该邻域内分布在百分之多少，只需要知道当前分布的均值和方差。对于深度图邻域内均值的计算，我们可以自然地联想到对Shadow Map进行Mipmap查询。而对于方差的计算，VSM引入了以下的公式，因此我们只需要在绘制Shadow Map的同时绘制一个储存深度的平方的map。$var(x)&#x3D;E(x^2),-E^2(x)$这样在Shadow Map绘制完成后，对于其上的每一个点我们都能通过均值和方差得到该位置的一个深度的近似分布情况，从而可以根据当前片元的值，计算出其CDF。另外，VSM算法还引入了切比雪夫不等式（如下），只需要知道分布的期望和方差，就可以计算出x大于某个固定值的概率。$P(x&gt;t)≤σ^2&#x2F;(σ^2+(t-μ)^2)$切比雪夫不等式成立的条件是$t＞μ$，也就是当前的$d＞z_avg$。也就说如果Block内的平均深度小于当前Fragment的深度，就不能使用这种估计方法。 上面这种从统计学出发的估计解决了PCSS算法中的第三个步骤也就是PCF计算，但是PCSS算法中的第一个步骤Blocker Search仍然会耗费较长的时间，因此VSSM算法针对性地提出了估计方案。对于一个Block，第一个步骤Block Search的目标是估计其中遮挡物的平均深度，我们可以设Block中的像素总数为N，平均深度为$Z_avg$，深度小于当前值（遮挡物）的像素数为N1，平均深度为$Z_occ$，深度大于当前值（接收物体）的像素数为N2，平均深度为$Z_unocc$。则可以得到等式：$N_1&#x2F;N Z_unocc+N_2&#x2F;N Z_occ&#x3D;Z_avg$不难看出，N_1&#x2F;N就是非遮挡物所占比例，也就可以转化为P（X≥t）。则上式可以转化为：$P(x≥t) z_unocc+(1.0-P(x≥t)) z_occ&#x3D;z_avg$要计算遮挡物的平均深度，可以使用：$Z_occ&#x3D;(z_avg-P(x≥t) z_unocc)&#x2F;(1.0-P(x≥t))$而其中的$Z_avg$可以通过Mipmap得到，因此VSSM假设非遮挡物的深度都是t，从而可以计算出遮挡物的平均深度，这种假设的理论依据是一般的接收物体都是一个平面。而对于那些不是一个平面的阴影接收物体，以及切比雪夫不成立的情况，VSSM这篇论文则提出了分治的解决方案。对不满足$d&gt;z_avg$的Block，将其分割为更小的sub-Block，再进行阴影的绘制计算。具体的分治思路是，对于那些$z_avg＜d$的sub-Block，我们之前使用切比雪夫不等式的估计仍然是有效的，但是对于那些$z_avg≥d$的sub-Block，论文中选择了直接使用普通的PCSS算法进行阴影的绘制。其原因是论文认为分治之后的sub-Block较小，可以使用传统的PCF采样进行计算。论文使用类似四叉树的结构进行分治之后Block的管理和遍历。 六、MSM算法MSM算法全称为Moment Shadow Mapping。是Christoph Peters在2015年提出的一种阴影绘制方式。MSM实际上是在VSSM算法的基础上，对使用统计学思想逼近Depth Map的分布进行阴影绘制这种想法的延续。VSSM算法中，仅仅使用到了Depth的平均值和方差（也就是一阶矩和二阶矩）去估计深度的分布情况，这显然是可能产生偏差的，比如说对于下图中右边这种深度的分布，集中分布在几个固定的值附近，这样的情况使用切比雪夫不等式去估计就会出现比较大的误差。图源Games202而为了让VSM中对分布的描述更加精确，Christoph Peters提出了使用高阶矩来描述分布的方法。如下图，蓝色表示真正的深度分布CDF，如果使用VSSM算法则只能对CDF逼近到红色线条的程度，而如果使用前四阶矩则能逼近到绿色线段的程度，这样能使得我们对深度分布的估计更精确，对PCF进行近似计算也就更精确。图源【13】Christoph的测试表明，相对于VSM和ESM算法，MSM算法能提供更小的Shadow绘制误差（如下图）。图源【13】 七、总结在当前的渲染领域，由于时序上降噪技术的引入，实时的光线追踪技术成为了可能，因此目前传统的阴影绘制方法或许没有像之前那样应用这么广泛，但是在顺着这条发展路径学习的过程中，我对渲染的一些理解仍然能加深，并且获得新的启发。传统渲染方式虽然在一定程度上是某个时代算力限制的产物，但是其中蕴含的思考方式和优化方法，相信仍然能在未来的学习中给我带来灵感和启发。 参考资料： Tomas Akenine-Möller, Eric Haines, Naty Hoffman, Angelo Pesce, Michał Iwanicki, and Sébastien Hillaire,T. Real-Time Rendering 4rd Edition[M]. Natick, MA, USA: A. K. Peters, Ltd., 2020. Catmull, E., “A Subdivision Algorithm for Computer Display of Curved Surfaces,” PhD. thesis, Dept. of Computer Science, University of Utah, 1974. Lance Williams. 1978. Casting curved shadows on curved surfaces. SIGGRAPH Comput. Graph. 12, 3 (August 1978), 270–274. https://doi.org/10.1145/965139.807402 Y. Wang and S. Molnar. Second-depth shadow mapping. Technical Report TR94-019, Department of Computer Science, University of North Carolina - Chapel Hill, Dec. 1994. Fernando, S. Fernandez, K. Bala, and D. P. Greenberg. Adaptive shadow maps. In SIGGRAPH 2001 Conference Proceedings, pages 387–390, 2001. M. Stamminger and G. Drettakis. Perspective shadow maps. ACM Transactions on Graphics, 21(3):557–562, July 2002. William T. Reeves, David H. Salesin, and Robert L. Cook. 1987. Rendering antialiased shadows with depth maps. SIGGRAPH Comput. Graph. 21, 4 (July 1987), 283–291. https://doi.org/10.1145/37402.37435 https://developer.download.nvidia.com/shaderlibrary/docs/shadow_PCSS.pdf William Donnelly and Andrew Lauritzen. 2006. Variance shadow maps. In Proceedings of the 2006 symposium on Interactive 3D graphics and games (I3D ‘06). Association for Computing Machinery, New York, NY, USA, 161–165. https://doi.org/10.1145/1111411.1111440 https://developer.download.nvidia.com/SDK/10.5/opengl/src/cascaded_shadow_maps/doc/cascaded_shadow_maps.pdf Salvi, Marco, “Rendering Filtered Shadows with Exponential Shadow Maps,” in Wolfgang Engel, ed., ShaderX6, Charles River Media, pp. 257–274, 2008. Yang, B., Dong, Z., Feng, J., Seidel, H.-P. and Kautz, J. (2010), Variance Soft Shadow Mapping. Computer Graphics Forum, 29: 2127-2134. https://doi.org/10.1111/j.1467-8659.2010.01800.x Christoph Peters and Reinhard Klein. 2015. Moment shadow mapping. In Proceedings of the 19th Symposium on Interactive 3D Graphics and Games (i3D ‘15). Association for Computing Machinery, New York, NY, USA, 7–14. https://doi.org/10.1145/2699276.2699277 Lingqi Yan. Games202 Lecture3&amp;Lecture4. https://zhuanlan.zhihu.com/p/384446688 https://zhuanlan.zhihu.com/p/478472753","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Shadow","slug":"Shadow","permalink":"https://yaelcassini.github.io/tags/Shadow/"},{"name":"Shadow Map","slug":"Shadow-Map","permalink":"https://yaelcassini.github.io/tags/Shadow-Map/"},{"name":"PCF","slug":"PCF","permalink":"https://yaelcassini.github.io/tags/PCF/"},{"name":"PCSS","slug":"PCSS","permalink":"https://yaelcassini.github.io/tags/PCSS/"},{"name":"VSM","slug":"VSM","permalink":"https://yaelcassini.github.io/tags/VSM/"},{"name":"MSM","slug":"MSM","permalink":"https://yaelcassini.github.io/tags/MSM/"}]},{"title":"Rendering框架及发展历史总结(待补充)","slug":"Rendering-History","date":"2023-03-28T12:37:39.000Z","updated":"2023-09-18T07:51:21.596Z","comments":true,"path":"2023/03/28/Rendering-History/","link":"","permalink":"https://yaelcassini.github.io/2023/03/28/Rendering-History/","excerpt":"","text":"真实感渲染光照模型 Illumination Model 灯光 阴影 基于物理的材质 Material 明暗 纹理 透明 一种标准的基本属性主要是Metallic-Roughness，另一种标准是Specular-Glossiness，前者对设计师更友好，后者侧重物理属性，保留了反射率F0。 光栅化 Rasterization光线追踪消隐技术全局光照（Global Illumination）后处理DLSS光照模型局部光照模型 Lambert漫反射模型 Gourand光照模型 Phong光照模型 Blinn-Phong光照模型 Cook-Torrance模型 全局光照模型 光线追踪 路径追踪 递归光线追踪 whitted-type 分布式光线追踪 distrubution 双向路径追踪 Bidirectional Path https://graphics.stanford.edu/courses/cs348b-03/papers/veach-chapter10.pdf Metropolis 光子映射 Photon Mapping 基于点的全局光照 辐射度算法 光子映射 Other TopicRay MarchingPercentage Closer Soft Shadows (PCSS)大事记&amp;原文引用1760 Johann Heinrich Lambert在其著作Photometria中提出Lambert模型。 Half-Lambert是Valve公司提出来的算法，为了解决Lambert公式在灰面太暗的问题。”Half Lambert” lighting is a technique first developed in the original Half-Life. 1967 Siggraph（Special Interest Group for Computer GRAPHICS，计算机图形图像特别兴趣小组）成立 光照模型：Wylie等人第一次在显示物体时加入了光照效果。该论文提出，物体表面上一点接收到的光强，与该点到光源距离的平方成反比，且与光照方向和表面发现的夹角有关。 Chris Wylie, Gordon Romney, David Evans, and Alan Erdahl. 1967. Half-tone perspective drawings by computer. In Proceedings of the November 14-16, 1967, fall joint computer conference (AFIPS ‘67 (Fall)). Association for Computing Machinery, New York, NY, USA, 49–58. https://doi.org/10.1145/1465611.1465619 1968 Arthur Appel 在研究隐藏面消除时提出了光线投射算法（Ray Casting），并首次给出了光线跟踪算法的描述。其具体思路是从每一个像素射出一条射线，然后找到最接近的物体挡住射线的路径，而视平面上每个像素的颜色取决于从可见光表面产生的亮度。 Arthur Appel. 1968. Some techniques for shading machine renderings of solids. In Proceedings of the April 30–May 2, 1968, spring joint computer conference (AFIPS ‘68 (Spring)). Association for Computing Machinery, New York, NY, USA, 37–45. https://doi.org/10.1145/1468075.1468082 1970 光照模型：Bouknight提出第一个光反射模型，指出物体表面朝向是确定物体表面上一点光强的主要因素，用Lambert漫反射定律计算物体表面上各多边形的光强，对光照射不到的地方，用环境光代替。 W. Jack Bouknight. 1970. A procedure for generation of three-dimensional half-toned computer graphics presentations. Commun. ACM 13, 9 (Sept. 1970), 527–536. https://doi.org/10.1145/362736.362739 1971 光照模型：Gourand提出的基于“漫反射模型与插值”思想的Gourand模型。对多面体模型，用漫反射模型计算多边形顶点的光亮度，再用增量法插值计算。 Gouraud, H. (1971). Continuous Shading of Curved Surfaces. IEEE Transactions on Computers, C-20, 623-629. https://ieeexplore.ieee.org/document/1671906 1974 Siggraph开始每年举办计算机图形学顶级年度会议。 Z-buffer算法 Catmull, E., “A Subdivision Algorithm for Com\u0002puter Display of Curved Surfaces,” PhD. thesis, Dept. of Computer Science, University of Utah, 1974. 1975 光照模型：Phong提出图形学中第一个有影响的简单光照明模型。模型虽然只是一个经验模型，但是其真实度已达到可以接受的程度。在Phong光照模型的基础之上，相继出现了Goud明暗处理和Phong明暗处理两个增量式光照模型。 Bui Tuong Phong. 1975. Illumination for computer generated pictures. Commun. ACM 18, 6 (June 1975), 311–317. https://doi.org/10.1145/360825.360839 1976 UV mapping James F. Blinn and Martin E. Newell. 1976. Texture and reflection in computer generated images. Commun. ACM 19, 10 (Oct. 1976), 542–547. https://doi.org/10.1145/360349.360353 用于消隐的数据结构 James H. Clark. 1976. Hierarchical geometric models for visible surface algorithms. Commun. ACM 19, 10 (Oct. 1976), 547–554. https://doi.org/10.1145/360349.360354 1977 光照模型：Blinn-Phong James F. Blinn. 1977. Models of light reflection for computer synthesized pictures. SIGGRAPH Comput. Graph. 11, 2 (Summer 1977), 192–198. https://doi.org/10.1145/965141.563893 Shadow Volume Crow, Franklin C., “Shadow Algorithms for Computer Graphics,” Computer Graphics (SIG\u0002GRAPH ’77 Proceedings), vol. 11, no. 2, pp. 242–248, July 1977. 1978 Shadow Map算法 Lance Williams. 1978. Casting curved shadows on curved surfaces. SIGGRAPH Comput. Graph. 12, 3 (August 1978), 270–274. https://doi.org/10.1145/965139.807402 Development： C. Hourcade and A. Nicolas. Algorithms for an\u0002tialiased cast shadows. Computers and Graphics, 9(3):259–265, 1985. Midpoint Shadow Map. Andrew Woo, VII.1 - THE SHADOW DEPTH MAP REVISITED, Editor(s): DAVID KIRK, Graphics Gems III (IBM Version), Morgan Kaufmann, 1992,Pages 338-342, https://doi.org/10.1016/B978-0-08-050755-2.50073-7. Mark Segal, Carl Korobkin, Rolf van Widenfelt, Jim Foran, and Paul Haeberli. 1992. Fast shadows and lighting effects using texture mapping. SIGGRAPH Comput. Graph. 26, 2 (July 1992), 249–252. https://doi.org/10.1145/142920.134071 Shenchang Eric Chen and Lance Williams. 1993. View interpolation for image synthesis. In Proceedings of the 20th annual conference on Computer graphics and interactive techniques (SIGGRAPH ‘93). Association for Computing Machinery, New York, NY, USA, 279–288. https://doi.org/10.1145/166117.166153 Y. Wang and S. Molnar. Second-depth shadow map\u0002ping. Technical Report TR94-019, Department of Com\u0002puter Science, University of North Carolina - Chapel Hill, Dec. 1994. . Fernando, S. Fernandez, K. Bala, and D. P. Green\u0002berg. Adaptive shadow maps. In SIGGRAPH 2001 Conference Proceedings, pages 387–390, 2001. M. Stamminger and G. Drettakis. Perspective shadow maps. ACM Transactions on Graphics, 21(3):557–562, July 2002. 感觉是消隐 Edwin Catmull. 1978. A hidden-surface algorithm with anti-aliasing. SIGGRAPH Comput. Graph. 12, 3 (August 1978), 6–11. https://doi.org/10.1145/965139.807360 太有名了先放在这里 Turner Whitted. 1978. A scan line algorithm for computer display of curved surfaces. SIGGRAPH Comput. Graph. 12, SI (August 1978), 8–13. https://doi.org/10.1145/988437.988440 1980 光照模型&amp;光线追踪：Whitted提出了Whitted模型，并第一次给出一般性光线跟踪算法的范例。该模型综合考虑了光的反射、折射透射、阴影等。此时的光线追踪才真正的变成一个强大的工具，其将光线投射算法扩展为递归算法（Recursive Ray Tracing）。 Turner Whitted. 1980. An improved illumination model for shaded display. Commun. ACM 23, 6 (June 1980), 343–349. https://doi.org/10.1145/358876.358882 八叉树？ Steven M. Rubin and Turner Whitted. 1980. A 3-dimensional representation for fast rendering of complex scenes. SIGGRAPH Comput. Graph. 14, 3 (July 1980), 110–116. https://doi.org/10.1145/965105.807479 1982 光照模型：Cook和Torrance为了克服Phong模型的缺点，提出了一个基于物理光学的表面反射模型—大名鼎鼎的Cook-Torrance微表面模型，使得模型中反射光的位置和分布与实际情况非常接近，因而用它绘制的图形具有很好的质感。 R. L. Cook and K. E. Torrance. 1982. A Reflectance Model for Computer Graphics. ACM Trans. Graph. 1, 1 (Jan. 1982), 7–24. https://doi.org/10.1145/357290.357293 体积散射 blinn 1983 光照模型：Hall和Greenbert在whitted基础上此进一步给出Hall光透射模型,考虑了漫透射和规则透射光。改进了whitted中投射高光效果，并再环境光中加入距离衰减因子，使之能够更好的模拟物体表面的透射特性。 1984 Cook于1984年引入蒙特卡洛方法（Monte Carlo method）到光线跟踪领域，将经典的光线跟踪方法扩展为分布式光线跟踪算法（Distributed Ray Tracing），又称为随机光线追踪（stochasticray tracing），可以模拟更多的效果，如金属光泽、软阴影、景深（ Depthof Field）、运动模糊等等。 Robert L. Cook, Thomas Porter, and Loren Carpenter. 1984. Distributed ray tracing. SIGGRAPH Comput. Graph. 18, 3 (July 1984), 137–145. https://doi.org/10.1145/964965.808590 Goral 1984年 辐射度算法 1986 光照模型&amp;光线追踪：Kajiya统一了以前所有的光照模型。Kajiya首先提出使类似于随机采样的蒙特卡罗（Monte Carlo）方法求解绘制方程的光线追踪算法（Raytracing）——通过对到达图像平面上的光线路径进行采样，然后估计它们对最终图像的贡献来生成图像。 James T. Kajiya. 1986. The rendering equation. SIGGRAPH Comput. Graph. 20, 4 (Aug. 1986), 143–150. https://doi.org/10.1145/15886.15902 Non-diffuse Radiosity David S. Immel, Michael F. Cohen, and Donald P. Greenberg. 1986. A radiosity method for non-diffuse environments. SIGGRAPH Comput. Graph. 20, 4 (Aug. 1986), 133–142. https://doi.org/10.1145/15886.15901 1987 PCF算法 William T. Reeves, David H. Salesin, and Robert L. Cook. 1987. Rendering antialiased shadows with depth maps. SIGGRAPH Comput. Graph. 21, 4 (July 1987), 283–291. https://doi.org/10.1145/37402.37435 1991 非漫射辐射度（Non-diffuse Radiosity） Françis X. Sillion, James R. Arvo, Stephen H. Westin, and Donald P. Greenberg. 1991. A global illumination solution for general reflectance distributions. SIGGRAPH Comput. Graph. 25, 4 (July 1991), 187–196. https://doi.org/10.1145/127719.122739 Hanrahan 1991年 分级辐射度算法（Hierarchical radiosity） 先放在这 Xiao D. He, Kenneth E. Torrance, François X. Sillion, and Donald P. Greenberg. 1991. A comprehensive physical model for light reflection. SIGGRAPH Comput. Graph. 25, 4 (July 1991), 175–186. https://doi.org/10.1145/127719.122738 1992 RenderMan规范，简称RISpec，是一个开放的API，由皮克斯开发，用于描述三维模型并把它转换成逼真的数字图像。RenderMan规范作为建模程序和渲染程序之间的通信协议（或称为接口），用于生成逼真的数字图像。 1993 不连续网格辐射度（Discontinuity meshing） Dani Lischinski, Filippo Tampieri, and Donald P. Greenberg. 1993. Combining hierarchical radiosity and discontinuity meshing. In Proceedings of the 20th annual conference on Computer graphics and interactive techniques (SIGGRAPH ‘93). Association for Computing Machinery, New York, NY, USA, 199–208. https://doi.org/10.1145/166117.166143 Lafortune and Willems 1993 年• Veach and Guibas 1994年 双向路径跟踪 1994 微表面&amp;Roughness相关 Michael Oren and Shree K. Nayar. 1994. Generalization of Lambert’s reflectance model. In Proceedings of the 21st annual conference on Computer graphics and interactive techniques (SIGGRAPH ‘94). Association for Computing Machinery, New York, NY, USA, 239–246. https://doi.org/10.1145/192161.192213 1995 Diffusion for light transport 1996 光子映射 Photon Mapping Jensen, Henrik Wann. “Global Illumination using Photon Maps.” Rendering Techniques (1996). 1997 Veach and Guibas 1997 马尔可夫链蒙特卡洛 Robust Monte Carlo Methods for Light Transport Simulation 光子映射 Photon Mapping Bruce Walter, Philip M. Hubbard, Peter Shirley, and Donald P. Greenberg. 1997. Global illumination using local linear density estimation. ACM Trans. Graph. 16, 3 (July 1997), 217–259. https://doi.org/10.1145/256157.256158 Light Transport Veach, Eric &amp; Guibas, Leonidas. (1970). Metropolis Light Transport. Computer Graphics (SIGGRAPH ‘97 Proceedings). 31. 10.1145&#x2F;258734.258775. Keller 1997年Virtual point lights (Instant Radiosity) 1998 Jensen and Christensen 1998年Volumetric photon mapping Bi-Directional Path Tracing Lafortune, Eric &amp; Willems, Yves. (1998). Bi-Directional Path Tracing. Proceedings of Third International Conference on Computational Graphics and Visualization Techniques (Compugraphics’. 93. 2000 Pauly 2000年 Metropolis in volumes 2001 次表面散射 Jensen H W, Marschner S R, Levoy M, et al. A practical model for subsurface light transport[C]&#x2F;&#x2F;Proceedings of the 28th annual conference on Computer graphics and interactive techniques. ACM, 2001: 511-518. 2002 Kelemen et al. 2002Primary sample space MCMC 2005 Walter 2005年 LightCuts Cline 2005年“Energy Redistribution” 和 非遍历 MCMC Fernando发表了Percentage-Closer Soft Shadows，称为“百分比渐近柔和阴影（PCSS）。 https://developer.download.nvidia.com/shaderlibrary/docs/shadow_PCSS.pdf RSM算法（Reflective Shadow Map） Carsten Dachsbacher and Marc Stamminger. 2005. Reflective shadow maps. In Proceedings of the 2005 symposium on Interactive 3D graphics and games (I3D ‘05). Association for Computing Machinery, New York, NY, USA, 203–231. https://doi.org/10.1145/1053427.1053460 2006 VSM算法（Variance shadow maps） William Donnelly and Andrew Lauritzen. 2006. Variance shadow maps. In Proceedings of the 2006 symposium on Interactive 3D graphics and games (I3D ‘06). Association for Computing Machinery, New York, NY, USA, 161–165. https://doi.org/10.1145/1111411.1111440 2007 Walter 2007 年 Microfacet transmission model CSM算法 https://developer.download.nvidia.com/SDK/10.5/opengl/src/cascaded_shadow_maps/doc/cascaded_shadow_maps.pdf 2008 Jarosz 2008年 光束辐射估计（Beam Radiance Estimate） 2010 Jakob 2010年Anisotropic volume media 2011 d’Eon and Irving 2011年Advanced diffusion models 2012 Jakob &amp;amp;amp; Marschner 2012年Manifold Exploration Disney Principled BRDF - MERL 100 BRDF 材质库 2014 Křivánek 2014年Unifying Points, Beams, and Paths 2015 Kettunen 2015 梯度域路径跟踪 Stochastic Screen-Space Reflections https://view.officeapps.live.com/op/view.aspx?src=https%3A%2F%2Fadvances.realtimerendering.com%2Fs2015%2FStochastic%2520Screen-Space%2520Reflections.pptx Moment Shadow Map Christoph Peters and Reinhard Klein. 2015. Moment shadow mapping. In Proceedings of the 19th Symposium on Interactive 3D Graphics and Games (i3D ‘15). Association for Computing Machinery, New York, NY, USA, 7–14. https://doi.org/10.1145/2699276.2699277 2018 微软提出了DirectX Ray Tracing（DXR）的API，提供了Ray Tracing Pipeline的雏形。 NVIDIA宣布了可加速硬件中光线追踪速度的新架构Turing，以及搭载实时光线追踪技术的RTX系列显卡。Nvidia推出了新一代的RTX显卡，提供了Ray Tracing硬件加速的能力。 第一款搭载RTX实时混合光线追踪技术的游戏《战地5（Battlefield V）》正式面世，基于EA的Frostbite引擎，带来了出色的混合光线追踪反射（Hybrid Ray-Traced Reflections）渲染表现。 Eric Heitz于2018年提出了一种结合了解析直接光照（analytic direct illumination）和随机阴影（stochastic shadows）的新方法[13]）。在paper中，他们提出了一种比率估计器（ratio estimator），该比率估计器可以将解析光照技术（analytic illumination techniques）与随机光线追踪阴影（stochastic raytraced shadows）正确组合。 Eric Heitz, Stephen Hill, and Morgan McGuire. 2018. Combining analytic direct illumination and stochastic shadows. In Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D ‘18). Association for Computing Machinery, New York, NY, USA, Article 2, 1–11. https://doi.org/10.1145/3190834.3190852 2019 SIGGRAPH2019的Ray Tracing专题报告展望了实时光线追踪的未来。其中，SEED团队分享了自己的混合渲染管线（上图），管线由一个接一个的阶段串联，而每个阶段采用最合适的技术来实现。 SIGGRAPH 2019, State-of-the-Art and Challenges in Game Ray Tracing 2020 Vulkan也推出了Ray Tracing规范，同DXR非常相似。 2021 2021年，UE5的视频又掀起了一波热潮，新一代的渲染引擎Lumen则是一套完整的光线追踪管线，分为Software和Hardware两种形式。 Nvidia推出 RayTracing Gens Ⅱ。 2022 AMD推出自己的Ray Tracing库——HIP。 Referencehttps://zhuanlan.zhihu.com/p/50165536https://zhuanlan.zhihu.com/p/49474631https://zhuanlan.zhihu.com/p/29418992","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Monte Carlo","slug":"Monte-Carlo","permalink":"https://yaelcassini.github.io/tags/Monte-Carlo/"},{"name":"RayTracing","slug":"RayTracing","permalink":"https://yaelcassini.github.io/tags/RayTracing/"},{"name":"PathTracing","slug":"PathTracing","permalink":"https://yaelcassini.github.io/tags/PathTracing/"}]},{"title":"PathTracing(待补充)","slug":"PathTracing","date":"2023-03-24T06:32:57.000Z","updated":"2024-01-05T09:17:25.146Z","comments":true,"path":"2023/03/24/PathTracing/","link":"","permalink":"https://yaelcassini.github.io/2023/03/24/PathTracing/","excerpt":"光线追踪及路径追踪算法学习与实践。","text":"光线追踪及路径追踪算法学习与实践。 Key Words: 重要性采样 Importance Sampling 基于图像的光照 Image based lighting 蒙特卡洛积分 Monte-Carlo Integration 蒙特卡洛积分 https://zhuanlan.zhihu.com/p/146144853 https://www.cnblogs.com/time-flow1024/p/10094293.html#mjx-eqn-eq%3AFN https://zhuanlan.zhihu.com/p/365624460 Path-Tracing Project：作为课程作业实现的光线追踪渲染器： codehttps://github.com/YaelCassini/PlusProtoEngine Reference: https://raytracing.github.io/books/RayTracingInOneWeekend.html https://raytracing.github.io/books/RayTracingTheNextWeek.html https://agraphicsguynotes.com/posts/sample_microfacet_brdf/ http://www.cim.mcgill.ca/~derek/ecse689_a3.html https://raytracing.github.io/books/RayTracingInOneWeekend.html#dielectrics https://en.wikipedia.org/wiki/M%C3%B6ller%E2%80%93Trumbore_intersection_algorithm https://math.stackexchange.com/questions/538458/how-to-sample-points-on-a-triangle-surface-in-3d https://computergraphics.stackexchange.com/questions/5152/progressive-path-tracing-with-explicit-light-sampling","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Monte Carlo","slug":"Monte-Carlo","permalink":"https://yaelcassini.github.io/tags/Monte-Carlo/"},{"name":"RayTracing","slug":"RayTracing","permalink":"https://yaelcassini.github.io/tags/RayTracing/"},{"name":"PathTracing","slug":"PathTracing","permalink":"https://yaelcassini.github.io/tags/PathTracing/"}]},{"title":"Visibility 物体可见性预计算（待补充代码）","slug":"Visibility","date":"2023-02-17T06:10:50.000Z","updated":"2024-01-04T03:45:03.539Z","comments":true,"path":"2023/02/17/Visibility/","link":"","permalink":"https://yaelcassini.github.io/2023/02/17/Visibility/","excerpt":"任务目标：参与一个可微分渲染的项目，主要负责其中的渲染部分相关工作，在前期需要使用已有的Mesh和Texture数据生成网络所需要的输入数据。其中就包括Visibility，刚开始做的时候什么都不太懂，学习相关知识耽误了很多时间，故整理于此。","text":"任务目标：参与一个可微分渲染的项目，主要负责其中的渲染部分相关工作，在前期需要使用已有的Mesh和Texture数据生成网络所需要的输入数据。其中就包括Visibility，刚开始做的时候什么都不太懂，学习相关知识耽误了很多时间，故整理于此。 任务理解：经与导师沟通后，本项目要求的Visibility并不是从相机角度看过去的可视性，而是更像环境光照那种，设想有一个无限大的球面，在球面上通过遍历不同的经纬得到不同的光线方向，对于模型上面的每一个顶点，计算在球面上各个方向其是否可视（光线不被其他物体或者面片遮挡）。为了方便数据输入网络，导师还要求将这个可视数据通过球谐函数Spherical Harmonics计算得到在球谐函数空间的前9维系数，从而将每一个顶点在各个方向上是否可见的信息，转化为一个9维的向量，作为Mesh中顶点的附加属性。整个过程需要： 遍历Mesh上面的每一个顶点。 计算该点向球面上各个方向的可见性（场景中无相交），可见为1，不可见为0。 将可见性信息投影到Equirectangualr Map（这一步主要用于中间结果观察，不影响SH计算） 将可见性信息投影到SH球谐函数上，使用前4阶系数（10个系数）。 将该系数向量作为顶点的固有属性储存下来。 （选）将该系数向量作为顶点的信息使用OpenGL绘制成texture space的贴图，得到9个通道的贴图，储存的是每一个像素对应uv的可见性信息在SH空间下的系数。 具体实现：因为在计算Visibility中需要对整个球面进行光线方向的采样，并计算其在整个场景中是否与其他物体或者面片相交，因此其实可以转化为使用一个光线追踪的框架来帮助完成这个工作，在前期探索中，曾经试图使用Games202 Assignment2的Nori框架来完成这件事，但是后面与导师沟通后，导师建议我使用Mitsuba来完成该工作，原因主要有下：Mitsuba的使用场合较为广泛，相关的资料和实验室能够提供的帮助也较多；另外学习Mitsuba也对我之后在渲染方向的继续探索有帮助。 具体我使用的是Python+Mitsuba的方式，用python脚本去调用Mitsuba的接口及其中的光追框架。用mitsuba里面的enoki库实现了并行化计算visibility，这部分目前不计算球谐投影过程的话，20k面片的场景，两秒内完成计算Visibility信息。 而对于投影到SH这一步，目前我在Giuhub上找到一个开源的项目： https://github.com/chalmersgit/SphericalHarmonics 初步决定在其基础上进行修改完成第二部分计算工作。这个项目初衷是针对Image Based Lighting的SH投影计算，其使用的IBL投影方式是Equirectangular Projection(ERP)。相关资料： https://blog.csdn.net/lin453701006/article/details/71173090 因此首先要把球面采样的代码修改到与该投影方式对应，得到一张这样的图像，再使用该项目计算SH。 具体实现中遇到的问题 从maya导出的mesh 在Maya中没有Transform 但是导入Blender有x轴上90度的旋转，而进入到Mitsuba时其在空间坐标系中的状态是Blender中去掉90旋转之后的状态，原因是Maya、Blender和Mitsuba三者的坐标系有些不同，虽然都是右手坐标系，但是Blender中默认是Z轴向上的，而另外两个是Y轴向上。 在进行球面采样的时候，需要为了防止边界出现问题，需要将每个像素点的坐标变换到像素点中心，即遍历xy时对其进行x+0.5 y+0.5的计算。 相关知识点Image Based Lighting分为三种不同的投影方式： Cube Map Dual Paraboloid Map Equirectangualr Map 相关资料 Spherical Harmonics：https://www.jianshu.com/p/a379b4c6d346","categories":[{"name":"Relighting Project","slug":"Relighting-Project","permalink":"https://yaelcassini.github.io/categories/Relighting-Project/"}],"tags":[{"name":"Deep Learing","slug":"Deep-Learing","permalink":"https://yaelcassini.github.io/tags/Deep-Learing/"},{"name":"Artificial Intelligent","slug":"Artificial-Intelligent","permalink":"https://yaelcassini.github.io/tags/Artificial-Intelligent/"},{"name":"Spherical Harmonics","slug":"Spherical-Harmonics","permalink":"https://yaelcassini.github.io/tags/Spherical-Harmonics/"}]},{"title":"一些资源链接&小知识","slug":"Dessert-Knowledge","date":"2022-11-10T03:45:40.000Z","updated":"2024-01-18T13:37:19.621Z","comments":true,"path":"2022/11/10/Dessert-Knowledge/","link":"","permalink":"https://yaelcassini.github.io/2022/11/10/Dessert-Knowledge/","excerpt":"一些零碎的知识","text":"一些零碎的知识 Siggraph索引：https://kesen.realtimerendering.com/ 常用Mesh：http://casual-effects.com/data/index.html HDRI贴图：https://polyhaven.com/zh/hdris/indoor 在线shell转bat： https://daniel-sc.github.io/bash-shell-to-bat-converter/ Spherical Harmonics： https://www.jianshu.com/p/a379b4c6d346 https://github.com/blurgyy/cg-2020 Chrono是c++11的一个时间库，可以用它来做程序运行时间的记录。 https://www.cnblogs.com/jwk000/p/3560086.html Warp是一个可以迁移拓扑并投影贴图的软件 TinyXML2是一个可以解析XML格式文件的库 https://github.com/leethomason/tinyxml2 三维制作软件中，基本都是右手坐标系，但需要注意默认朝上的轴，比如： Maya里面的坐标系是Y轴朝上 Blender里面的坐标系是z轴朝上 所以模型导入blender会自动沿着x轴旋转90度 py3nvml使用： https://blog.csdn.net/zywvvd/article/details/109538759 git waring：LF will be replaced by CRLF in 2022&#x2F;06&#x2F;08&#x2F;hello-world&#x2F;index.html. https://xiaozhuanlan.com/topic/4053786912 cuDNN&amp;cuBlas cuda深度神经网络库 CUDA Deep Neural Network (cuDNN) cuBLAS简介：CUDA基本线性代数子程序库（CUDA Basic Linear Algebra Subroutine library） Nsight System和Nsight Compute 将 CUDA API, GPU activity 的 tracing 与 kernel的profiling 分开，以便专门优化减小overhead，前者是 Nsight System，后者是 Nsight Compute。 拆开易扩展，Nsight System 可以监控 多进程、多核的 CPU backtrace； Nsight Compute 可以交互地debug 和 kernel profiling，它可以设置baseline，比较不同的kernel 执行。 欧几里德结构数据(Euclidean Structure Data) 以及非欧几里德结构数据(Non-Euclidean Structure Data) https://blog.csdn.net/imsuhxz/article/details/91361977 如何制作雨中布料渲染效果 https://www.youtube.com/watch?v=w3lwfMKkEwI https://youngjoongkwon.wordpress.com/2017/11/30/real-time-animation-of-rain-wet-cloth-material-2016/ https://cdn.jsdelivr.net/gh/YaelCassini/Papers/TA/Wet%20cloth%20animation%20with%20vertex%20based%20adhesion%20force%20model.pdf https://cdn.jsdelivr.net/gh/YaelCassini/Papers/TA/Real-time%20Animation%20of%20Rain-wet%20Cloth%20Material.pdf Normal Mapping相关 Triplanar Mapping https://blog.selfshadow.com/publications/blending-in-detail/#mjx-eqn-eqquat Parallax Occlusion Mapping POM 视差映射","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"}],"tags":[{"name":"Papers","slug":"Papers","permalink":"https://yaelcassini.github.io/tags/Papers/"},{"name":"ToolBag","slug":"ToolBag","permalink":"https://yaelcassini.github.io/tags/ToolBag/"}]},{"title":"Deep Face 初期调研及实践","slug":"Deep-Fake-Survey","date":"2022-07-04T02:27:13.000Z","updated":"2024-01-04T03:01:46.165Z","comments":true,"path":"2022/07/04/Deep-Fake-Survey/","link":"","permalink":"https://yaelcassini.github.io/2022/07/04/Deep-Fake-Survey/","excerpt":"Deep Face(后改为Relighting)项目 初期调研及实践","text":"Deep Face(后改为Relighting)项目 初期调研及实践 Keywords: 全连接神经网络、CNN、RNN、LTSM、GAN 深度学习入门：https://zhuanlan.zhihu.com/p/372029815 GAN论文总结：https://mp.weixin.qq.com/s?__biz=MzU5MTgzNzE0MA==&amp;mid=100002834&amp;idx=1&amp;sn=7d1c740509ba6b65f630f6db6bd51d7b CNN：https://zhuanlan.zhihu.com/p/38160157 3DMM：https://zhuanlan.zhihu.com/p/161828142 数据集：https://github.com/ondyari/FaceForensics/ http://kaldir.vc.in.tum.de/faceforensics_benchmark/ 下载：http://kaldir.vc.in.tum.de/faceforensics_download_v1.py","categories":[{"name":"Relighting Project","slug":"Relighting-Project","permalink":"https://yaelcassini.github.io/categories/Relighting-Project/"}],"tags":[{"name":"Deep Learing","slug":"Deep-Learing","permalink":"https://yaelcassini.github.io/tags/Deep-Learing/"},{"name":"GAN","slug":"GAN","permalink":"https://yaelcassini.github.io/tags/GAN/"},{"name":"Deep Fake","slug":"Deep-Fake","permalink":"https://yaelcassini.github.io/tags/Deep-Fake/"},{"name":"Artificial Intelligent","slug":"Artificial-Intelligent","permalink":"https://yaelcassini.github.io/tags/Artificial-Intelligent/"}]},{"title":"Subsurface Scattering 次表面散射学习笔记(待补充)","slug":"Subsurface-Scattering","date":"2022-06-15T07:47:18.000Z","updated":"2024-01-04T02:46:11.561Z","comments":true,"path":"2022/06/15/Subsurface-Scattering/","link":"","permalink":"https://yaelcassini.github.io/2022/06/15/Subsurface-Scattering/","excerpt":"次表面散射指的是漫反射中，光线入射表面后在内部弹射后从表面另一个点出射造成的视觉现象，常出现在半透明或者多表面材质中。次表面散射现象较明显的材质有：皮肤、玉器等。","text":"次表面散射指的是漫反射中，光线入射表面后在内部弹射后从表面另一个点出射造成的视觉现象，常出现在半透明或者多表面材质中。次表面散射现象较明显的材质有：皮肤、玉器等。 BSDF &#x3D; BRDF + BTDF当光线从一种介质射向另外一种介质时，根据其行进路线，可以被分为两个部分：一部分光线在介质交界处发生了反射， 并未进入另外一种介质，另外一部分光线则进入了另一种介质。反射部分的光照的辐射亮度（radiance）和入射光照的辐射照度（irradiance）的比例是一个和入射角度、出射角度相关的函数，这个函数就被称之为双向反射分布函数（BRDF）。相应的，穿越介质的那部分光照的辐射亮度和辐射照度的比例就被称之为双向透射分布函数（BTDF）。这两部分出射光的辐射亮度总和和入射光的辐射照度的比例就被叫做双向散射分布函数（BSDF），即BSDF &#x3D; BRDF + BTDF。（引自：https://zhuanlan.zhihu.com/p/27014447） 参考资料： 毛星云总结Gems 3：https://zhuanlan.zhihu.com/p/42433792 https://zhuanlan.zhihu.com/p/21247702?refer=graphics 引入偶极子：2001. A Practical Model for Subsurface Light Transport 引入多极子：2005. Light Diffusion in Multi-Layered Translucent Materials 基于纹理空间：Advanced Skin Rendering——Nvidia：https://developer.download.nvidia.com/presentations/2007/gdc/Advanced_Skin.pdf 可分离的次表面散射：Separable Subsurface Scattering Arnold 提供的次表面散射说明：https://docs.arnoldrenderer.com/display/A5AFMUG/Subsurface Random Walk算法：https://blog.csdn.net/Da___Vinci/article/details/82958297 一维随机游走：https://blog.csdn.net/qq_43186282/article/details/114585885 http://www.iryoku.com/separable-sss/","categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"}],"tags":[{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"Monte Carlo","slug":"Monte-Carlo","permalink":"https://yaelcassini.github.io/tags/Monte-Carlo/"},{"name":"Subsurface Scattering","slug":"Subsurface-Scattering","permalink":"https://yaelcassini.github.io/tags/Subsurface-Scattering/"}]},{"title":"Volantis主题配置(转载)","slug":"Volantis-Configuration","date":"2022-06-15T06:28:46.000Z","updated":"2024-01-03T09:38:45.207Z","comments":true,"path":"2022/06/15/Volantis-Configuration/","link":"","permalink":"https://yaelcassini.github.io/2022/06/15/Volantis-Configuration/","excerpt":"Volantis主题配制教程转自：https://volantis.js.org/v5/theme-settings/","text":"Volantis主题配制教程转自：https://volantis.js.org/v5/theme-settings/ 创建主题配置文件主题目录下的 _config.yml 文件通常负责主题相关配置，我们强烈建议您使用代替的主题配置文件以防止自己的配置丢失。那么如何使用代替主题配置文件呢？ 第 1&#x2F;2 步：创建配置文件 在博客根目录的 _config.yml 文件旁边新建一个文件： _config.volantis.yml ，这个文件中的配置信息优先级高于主题文件夹中的配置文件。 第 2&#x2F;2 步：覆盖自定义配置 当您需要修改某项内容时，例如导航栏菜单，那么您需要在主题配置文件中找到相关内容，复制进自己创建的配置文件中：blog/_config.volantis.yml12345678910navbar: visiable: auto # always, auto logo: # choose [img] or [icon + title] img: volantis-static/media/org.volantis/blog/Logo-NavBar@3x.png # https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png icon: title: menu: - name: 博客 icon: fa-solid fa-rss url: /小提示使用「npm i hexo-theme-volantis」方式安装的主题，主题配置文件在「blog/node_modules/hexo-theme-volantis/_config.yml」使用传统方式安装的主题，主题配置文件在「blog/themes/volantis/_config.yml」 自定义主题外观最大布局宽度blog/_config.volantis.yml123custom_css: ... max_width: 1080px # Sum of body width and sidebar width 网页所呈现的内容的最大宽度，即 body 和 sidebar 的宽度之和。 抗锯齿blog/_config.volantis.yml123custom_css: ... font_smoothing: true # font-smoothing for webkit 自定义光标样式blog/_config.volantis.yml1234567891011custom_css: ... cursor: enable: true text: volantis-static/media/cursor/text.png # https://cdn.jsdelivr.net/gh/inkss/common@1/cursor/text.png pointer: volantis-static/media/cursor/pointer.png # https://cdn.jsdelivr.net/gh/inkss/common@1/cursor/pointer.png default: volantis-static/media/cursor/left_ptr.png # https://cdn.jsdelivr.net/gh/inkss/common@1/cursor/left_ptr.png not-allowed: volantis-static/media/cursor/circle.png # https://cdn.jsdelivr.net/gh/inkss/common@1/cursor/circle.png zoom-out: volantis-static/media/cursor/zoom-out.png # https://cdn.jsdelivr.net/gh/inkss/common@1/cursor/zoom-out.png zoom-in: volantis-static/media/cursor/zoom-in.png # https://cdn.jsdelivr.net/gh/inkss/common@1/cursor/zoom-in.png grab: volantis-static/media/cursor/openhand.png # https://cdn.jsdelivr.net/gh/inkss/common@1/cursor/openhand.png 导航栏样式您可以设置导航栏的高度以及视觉特效，视觉特效目前可选的有： shadow：卡片阴影。 floatable：当鼠标移动到容器内时，呈现出浮起来的效果。 blur：背景模糊效果（毛玻璃），当浏览器不支持时显示为不透明。 blog/_config.volantis.yml123456custom_css: ... navbar: height: 64px width: auto # auto, max effect: [shadow, blur] # [shadow, floatable, blur] 滚动条样式blog/_config.volantis.yml1234567custom_css: ... scrollbar: size: 4px border: 2px color: &#x27;#2196f3&#x27; hover: &#x27;#ff5722&#x27; 侧边栏样式视觉特效参数同上，值得注意的是：卡片的 floatable 效果和 blur 效果相冲突。 blog/_config.volantis.yml1234custom_css: ... sidebar: effect: [shadow] # [shadow, floatable, blur] 正文区域样式视觉特效参数同上，值得注意的是：卡片的 floatable 效果和 blur 效果相冲突。您可以在 language: true 这里设置代码块显示语言名称。text_align 可以设置 h1&#x2F;h2&#x2F;h3&#x2F;h4&#x2F;p 的文字对齐方向。 blog/_config.volantis.yml12345678910111213custom_css: ... body: effect: [shadow] # [shadow, floatable, blur] highlight: language: true # show language of codeblock copy_btn: true text_align: # left, right, justify, center h1: left h2: left h3: left h4: left p: justify 布局间距您可以设置几种标题的布局间距 h2&#x2F;h3&#x2F;h4、段落间距 line、区块内部的段落间距 inline。 blog/_config.volantis.yml12345678custom_css: ... gap: h2: 48px # Spacing above H2 (only px unit) h3: 24px # Spacing above H3 (only px unit) h4: 16px # Spacing above H4 (only px unit) p: 1em # Paragraph spacing between paragraphs line_height: 1.6 # normal, 1.5, 1.75, 2 ... 自定义字体您可以自定义正文和代码字体。 blog/_config.volantis.yml123456789101112131415161718192021custom_css: ... fontfamily: logofont: fontfamily: &#x27;&quot;Varela Round&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, Helvetica, Arial&#x27; name: &#x27;Varela Round&#x27; url: volantis-static/media/fonts/VarelaRound/VarelaRound-Regular.ttf # https://cdn.jsdelivr.net/gh/volantis-x/cdn-fonts/VarelaRound/VarelaRound-Regular.ttf weight: normal style: normal bodyfont: fontfamily: &#x27;UbuntuMono, &quot;Varela Round&quot;, &quot;PingFang SC&quot;, &quot;Microsoft YaHei&quot;, Helvetica, Arial&#x27; name: &#x27;UbuntuMono&#x27; url: volantis-static/media/fonts/UbuntuMono/UbuntuMono-Regular.ttf # https://cdn.jsdelivr.net/gh/volantis-x/cdn-fonts/UbuntuMono/UbuntuMono-Regular.ttf weight: normal style: normal codefont: fontfamily: &#x27;Menlo, UbuntuMono, Monaco&#x27; # name: &#x27;Monaco&#x27; # url: volantis-static/media/fonts/Monaco/Monaco.ttf # https://cdn.jsdelivr.net/gh/volantis-x/cdn-fonts/Monaco/Monaco.ttf # weight: normal # style: normal 自定义颜色多彩配色方案 blog/_config.volantis.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091color_scheme: # ------------ # 通用颜色 common: # 主题色 theme: &#x27;#44D7B6&#x27; # 链接色 link: &#x27;#2196f3&#x27; # 按钮色 button: &#x27;#44D7B6&#x27; # 鼠标放到交互元素上时的色 hover: &#x27;#ff5722&#x27; # 主题色块内部的文字颜色 inner: &#x27;#fff&#x27; # 选中区域文字的背景颜色 selection: &#x27;alpha(#2196f3, 0.2)&#x27; # ------------ # 亮色主题（默认） light: # 网站背景色 site_bg: &#x27;#f4f4f4&#x27; # 网站背景上的文字 site_inner: &#x27;#fff&#x27; # 网站页脚文字 site_footer: &#x27;#666&#x27; # 卡片背景色 card: &#x27;#fff&#x27; # 卡片上的普通文字 text: &#x27;#444&#x27; # 区块和代码块背景色 block: &#x27;#f6f6f6&#x27; # 代码块高亮时的背景色 codeblock: &#x27;#FFF7EA&#x27; # 行内代码颜色 inlinecode: &#x27;#D56D28&#x27; # 文章部分 h1: &#x27;#444&#x27; h2: &#x27;#444&#x27; h3: &#x27;#444&#x27; h4: &#x27;#444&#x27; h5: &#x27;#444&#x27; h6: &#x27;#444&#x27; p: &#x27;#444&#x27; # 列表文字 list: &#x27;#666&#x27; # 列表 hover 时的文字 list_hl: &#x27;mix($color-theme, #000, 80)&#x27; # 辅助性文字 meta: &#x27;#888&#x27; # ------------ # 暗色主题 dark: # 网站背景色 site_bg: &#x27;#222&#x27; # 网站背景上的文字 site_inner: &#x27;#eee&#x27; # 网站页脚文字 site_footer: &#x27;#aaa&#x27; # 卡片背景色 card: &#x27;#444&#x27; # 卡片上的普通文字 text: &#x27;#eee&#x27; # 区块和代码块背景色 block: &#x27;#3a3a3a&#x27; # 代码块高亮时的背景色 codeblock: &#x27;#343a3c&#x27; # 行内代码颜色 inlinecode: &#x27;#D56D28&#x27; # 文章部分 h1: &#x27;#eee&#x27; h2: &#x27;#eee&#x27; h3: &#x27;#ddd&#x27; h4: &#x27;#ddd&#x27; h5: &#x27;#ddd&#x27; h6: &#x27;#ddd&#x27; p: &#x27;#bbb&#x27; # 列表文字 list: &#x27;#aaa&#x27; # 列表 hover 时的文字 list_hl: &#x27;mix($color-theme, #fff, 80)&#x27; # 辅助性文字 meta: &#x27;#888&#x27; # 夜间图片亮度 brightness: 70% 自定义右键菜单自定义右键菜单自 5.0.0-rc.8 版本进行了全新重构，与历史版本相比，重构版右键菜单拥有更灵活的配置。 由于新版右键菜单配置较为复杂，原版菜单暂时性保留，在配置文件上新版右键以 rightmenus 命名。 为了方面称呼，以新版右键代指重构版右键菜单，老版右键代指历史版本右键菜单。 差异对比新旧两版右键菜单的差异如下： 对比项 老版右键 新版右键 自定义菜单项 只支持新增链接型菜单 同时支持事件型和链接型菜单 菜单项显示与顺序调整 部分支持 完全支持 内置菜单自定义调整 部分支持 完全支持修改文字描述、图标显示、功能实现等内容 自定义响应事件处理 不支持 支持自行添加 复制图片至剪切板 仅支持 PNG 格式图片 任意格式的图片 全局音乐控制 支持 支持 新版右键菜单新版右键在菜单项上根据配置文件自行生成前端代码，所以统一了一个共用的菜单对象： 1&#123;id: &#x27;&#x27;, name: &#x27;&#x27;, icon: &#x27;&#x27;, link: &#x27;&#x27;, event: &#x27;&#x27;, group: &#x27;&#x27;&#125; 同时为了响应不同状态下的右键行为，提出了内置组 （defaultGroup）的概念，相应的对于右键默认提供的功能实现则定义为内置实现（defaultEvent）。 1234&#123; defaultEvent: [&#x27;copyText&#x27;, &#x27;copyLink&#x27;, &#x27;copyPaste&#x27;, &#x27;copyAll&#x27;, &#x27;copyCut&#x27;, &#x27;copyImg&#x27;, &#x27;printMode&#x27;, &#x27;readMode&#x27;], defaultGroup: [&#x27;navigation&#x27;, &#x27;inputBox&#x27;, &#x27;seletctText&#x27;, &#x27;elementCheck&#x27;, &#x27;elementImage&#x27;, &#x27;articlePage&#x27;]&#125; 具体来说，内置组对应右键行为，例如 inputBox 代表在输入框下右键行为；内置实现对应自定义右键默认提供的功能实现，例如 readMode 代表了阅读模式。 参数解释plugins/menus 类的组内数据支持对象（单个菜单）或数组（一系列菜单）12345678910rightmenus: order: menus.groupName plugins: defaultGroupItem menus: groupName: - &#123;menu&#125; - &#123;menu&#125; groupName1: &#123;menu&#125; 右键菜单加载菜单的具体加载由 order 控制，可供使用的内容为：plugins.[组名], menus.[组名], hr, music 这四大类。 右键菜单排序菜单的排序由 order 字段的先后顺序和组内菜单项的先后顺序决定。 右键菜单类菜单项共分为两大类：plugins 和 menus，前者放置内置组及内置菜单，允许添加&#x2F;修改组内菜单；后者为用户自建菜单类，允许添加&#x2F;修改组及组内菜单。一般意义上 plugins 类的组为动态组，根据实际的右键状态进行显示；menus 类中内容由用户添加，菜单项默认显示。 右键菜单项菜单项共六个字段：id, name, icon, link, event, group，具体作用如下： id: 唯一值 name: 用于菜单名称显示 icon: 用于菜单图标显示 link: 跳转链接 event: 事件，当输入内容不为内置事件时，作 JavaScript 代码执行 group: 菜单项所处分组名称 note link&#x2F;event 二选一，同时出现时仅处理 link。 内置功能内置组 组名 描述 备注 navigation 导航组件，横向排列，共用一行，仅显示图标 原则上支持的数量不限 inputBox 文本输入框相关组件 生效于 input&#x2F;textarea seletctText 文本选中类组件 生效于右键选中文本，text 为选中的文本 elementCheck 链接判断组件 生效于链接处的右键行为，link 为链接地址 elementImage 图片判断类组件 生效于图片类的右键行为，link 为链接地址 articlePage 文章页面组件 生效于 post.article 页面 note 除 navigation 外的内置组，在显示时会隐藏含 link 属性的菜单项。 内置实现 事件名 描述 备注 copyText 复制文本 复制选中文本 copyLink 复制链接地址 复制 a 或 image 下的链接至剪切板 copyPaste 粘贴文本 需要用户批准相应权限，仅支持粘贴文本至输入框（暂不支持粘贴图片） copyAll 全选文本 选中输入框内的文本内容 copyCut 剪切文本 剪切输入框中选中的文本内容 copyImg 复制图片 支持 Chrome 浏览器，复制图片资源至剪切板 printMode 打印页面 一个调制过样式的打印功能 readMode 阅读模式 一个简单的阅读模式功能 默认设置iconPrefixFontawesome 图标前缀，音乐类组件使用，参考内容：fa-solid, fa-regular, fa-light, fa-thin, fa-duotone, fa-brands。 articleShowLink在 articlePage 组显示时（文章页）时依旧显示含 link 属性的菜单项。 musicAlwaysShow当设定全局音乐播放器时，是否一直显示音乐控制菜单。false：仅当音乐播放时启用。 corsAnywhere适用于复制图片文件的场景，当图片源未设置 Access-Control-Allow-Origin 时，图片复制由于 CORS 问题失败。 你可以自行部署相应项目解决该问题，详见：Rob–W&#x2F;cors-anywhere 或者 Zibri&#x2F;cloudflare-cors-anywhere。 回调方法volantis.rightmenu.handle 在右键菜单打开时执行。 volantis.rightmenu.handle(callBack[,”callBackName”, “setRequestAnimationFrame &#x3D; true”])。 此外，你还可以在 volantis.mouseEvent 处获得 MouseEvent 信息。 配置文件 blog/_config.volantis.yml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394### 自定义右键 新rightmenus: enable: true # 右键菜单项及加载顺序 # 内容示例：plugins.[组名], menus.[组名], hr(分割线，推荐去线留白), music(音乐控制器) order: - plugins.navigation - hr - plugins.inputBox - plugins.seletctText - plugins.elementCheck - plugins.elementImage - menus.link - hr - menus.darkMode - plugins.articlePage - music ############################ # - &#123;id: &#x27;&#x27;, name: &#x27;&#x27;, icon: &#x27;&#x27;, link: &#x27;&#x27;, event: &#x27;&#x27;, group: &#x27;&#x27;&#125; # id: 唯一值 # name: 用于菜单名称显示 # icon: 用于菜单图标显示 # link: 跳转链接 # event: 事件，当输入内容不为内置事件时，作 JavaScript 代码执行 # group: 菜单项所处分组名称 # 注： # 1. link/event 二选一，同时出现时仅处理 link # 2. 内置事件列表： copyText, copyLink, copyPaste, copyAll, copyCut, copyImg, printMode, readMode # 3. 内置组列表：navigation, inputBox, seletctText, elementCheck, elementImage, articlePage # 4. plugins 列允许自定义组内项目 # 5. menus 列允许自定义组及其内容 # 6. 除 navigation 外的内置组，在显示时会隐藏含 link 属性的菜单项 ########################### # 基础项设置 options: # 图标前缀 fa-solid, fa-regular, fa-light, fa-thin, fa-duotone, fa-brands iconPrefix: fa-solid # 例外，在 articlePage 组显示时（文章页）时依旧显示含 link 属性的菜单项 articleShowLink: false # 当设定全局音乐播放器时，是否一直显示音乐控制菜单。false：仅当音乐播放时启用 musicAlwaysShow: false # 适用于复制图片文件的场景，当图片源未设置 Access-Control-Allow-Origin 时，图片复制由于 CORS 问题失败 # 你可以自行部署相应项目解决该问题，详见：https://github.com/Rob--W/cors-anywhere 或者 https://github.com/Zibri/cloudflare-cors-anywhere corsAnywhere: # 右键内置组，预置实现 plugins: # 导航组件 # 横向排列，共用一行，仅显示图标 (原则上支持的数量不限) navigation: - &#123;id: &#x27;left&#x27;, name: &#x27;转到上一页&#x27;, icon: &#x27;fa-solid fa-arrow-left&#x27;, event: &#x27;history.back()&#x27;, group: &#x27;navigation&#x27;&#125; - &#123;id: &#x27;right&#x27;, name: &#x27;转到下一页&#x27;, icon: &#x27;fa-solid fa-arrow-right&#x27;, event: &#x27;history.forward()&#x27;, group: &#x27;navigation&#x27;&#125; - &#123;id: &#x27;redo&#x27;, name: &#x27;刷新当前页面&#x27;, icon: &#x27;fa-solid fa-redo&#x27;, event: &#x27;window.location.reload()&#x27;, group: &#x27;navigation&#x27;&#125; - &#123;id: &#x27;up&#x27;, name: &#x27;回到顶部&#x27;, icon: &#x27;fa-solid fa-arrow-up&#x27;, event: &#x27;VolantisApp.scrolltoElement(volantis.dom.bodyAnchor)&#x27;, group: &#x27;navigation&#x27;&#125; #- &#123;id: &#x27;home&#x27;, name: &#x27;回到首页&#x27;, icon: &#x27;fa-solid fa-home&#x27;, link: &#x27;/&#x27;, group: &#x27;navigation&#x27;&#125; # 文本输入框相关组件 # 生效于 input/textarea，粘贴、剪切、全选 inputBox: - &#123;id: &#x27;copyPaste&#x27;, name: &#x27;粘贴文本&#x27;, icon: &#x27;fa-solid fa-paste&#x27;, event: &#x27;copyPaste&#x27;, group: &#x27;inputBox&#x27;&#125; - &#123;id: &#x27;copyAll&#x27;, name: &#x27;全选文本&#x27;, icon: &#x27;fa-solid fa-object-ungroup&#x27;, event: &#x27;copyAll&#x27;, group: &#x27;inputBox&#x27;&#125; - &#123;id: &#x27;copyCut&#x27;, name: &#x27;剪切文本&#x27;, icon: &#x27;fa-solid fa-cut&#x27;, event: &#x27;copyCut&#x27;, group: &#x27;inputBox&#x27;&#125; # 文本选中类组件 # 生效于右键选中文本，__text__ 为选中的文本。 seletctText: - &#123;id: &#x27;copyText&#x27;, name: &#x27;复制文本&#x27;, icon: &#x27;fa-solid fa-copy&#x27;, event: &#x27;copyText&#x27;, group: &#x27;seletctText&#x27;&#125; - &#123;id: &#x27;searchWord&#x27;, name: &#x27;站内搜索&#x27;, icon: &#x27;fa-solid fa-search&#x27;, event: &#x27;OpenSearch(__text__)&#x27;, group: &#x27;seletctText&#x27;&#125; - &#123;id: &#x27;bingSearch&#x27;, name: &#x27;必应搜索&#x27;, icon: &#x27;fa-solid fa-search&#x27;, event: &#x27;window.open(`https://cn.bing.com/search?q=$&#123;__text__&#125;`)&#x27;, group: &#x27;seletctText&#x27;&#125; #- &#123;id: &#x27;googleSearch&#x27;, name: &#x27;谷歌搜索&#x27;, icon: &#x27;fa-solid fa-search&#x27;, event: &#x27;window.open(`https://www.google.com/search?q=$&#123;__text__&#125;`)&#x27;, group: &#x27;seletctText&#x27;&#125; # 链接判断组件 # 生效于链接处的右键行为，__link__ 为链接地址 elementCheck: - &#123;id: &#x27;openTab&#x27;, name: &#x27;新标签页打开&#x27;, icon: &#x27;fa-solid fa-external-link-square-alt&#x27;, event: &#x27;window.open(__link__)&#x27;, group: &#x27;elementCheck&#x27;&#125; - &#123;id: &#x27;copyLink&#x27;, name: &#x27;复制链接地址&#x27;, icon: &#x27;fa-solid fa-link&#x27;, event: &#x27;copyLink&#x27;, group: &#x27;elementCheck&#x27;&#125; # 图片判断类组件 # 生效于图片类的右键行为，__link__ 为链接地址 elementImage: - &#123;id: &#x27;copyImg&#x27;, name: &#x27;复制图片&#x27;, icon: &#x27;fa-solid fa-image&#x27;, event: &#x27;copyImg&#x27;, group: &#x27;elementImage&#x27;&#125; - &#123;id: &#x27;googleImg&#x27;, name: &#x27;谷歌识图&#x27;, icon: &#x27;fa-solid fa-images&#x27;, event: &#x27;window.open(`https://www.google.com.hk/searchbyimage?image_url=$&#123;__link__&#125;`)&#x27;, group: &#x27;elementImage&#x27;&#125; # 文章页面组件 # 生效于 post.article 页面 articlePage: - &#123;id: &#x27;printMode&#x27;, name: &#x27;打印页面&#x27;, icon: &#x27;fa-solid fa-print&#x27;, event: &#x27;printMode&#x27;, group: &#x27;articlePage&#x27;&#125; - &#123;id: &#x27;readMode&#x27;, name: &#x27;阅读模式&#x27;, icon: &#x27;fa-solid fa-book-open&#x27;, event: &#x27;readMode&#x27;, group: &#x27;articlePage&#x27;&#125; # 右键自定义菜单区域 menus: link: - &#123;id: &#x27;help&#x27;, name: &#x27;常见问题&#x27;, icon: &#x27;fa-solid fa-question&#x27;, link: &#x27;https://volantis.js.org/faqs/&#x27;, group: &#x27;link&#x27;&#125; - &#123;id: &#x27;examples&#x27;, name: &#x27;示例博客&#x27;, icon: &#x27;fa-solid fa-rss&#x27;, link: &#x27;https://volantis.js.org/examples/&#x27;, group: &#x27;link&#x27;&#125; - &#123;id: &#x27;contributors&#x27;, name: &#x27;加入社区&#x27;, icon: &#x27;fa-solid fa-fan&#x27;, link: &#x27;https://volantis.js.org/contributors/&#x27;, group: &#x27;link&#x27;&#125; - hr - &#123;id: &#x27;source_docs&#x27;, name: &#x27;本站源码&#x27;, icon: &#x27;fa-solid fa-code-branch&#x27;, link: &#x27;https://github.com/volantis-x/volantis-docs/&#x27;, group: &#x27;link&#x27;&#125; - &#123;id: &#x27;source_theme&#x27;, name: &#x27;主题源码&#x27;, icon: &#x27;fa-solid fa-code-branch&#x27;, link: &#x27;https://github.com/volantis-x/hexo-theme-volantis/&#x27;, group: &#x27;link&#x27;&#125; darkMode: - &#123;id: &#x27;darkMode&#x27;, name: &#x27;暗黑模式&#x27;, icon: &#x27;fa-solid fa-moon&#x27;, event: &#x27;volantis.dark.toggle()&#x27;, group: &#x27;darkMode&#x27;&#125;### 高级玩法可以利用 Custom Files 自定义文件 功能，实现自定义右键菜单脚本及菜单项控制。 一个在右键菜单中添加 查看上一篇、查看下一篇 菜单项的范例： blog/_config.volantis.ymlblog/source/_volantis/bodyEnd.ejs省略了部分不相关内容1234567rightmenus: order: - menus.prevNext menus: prevNext: - &#123;id: &#x27;prev&#x27;, name: &#x27;查看上一篇&#x27;, icon: &#x27;fa-solid fa-angles-left&#x27;, event: &quot;volantis.rightmenu.jump(&#x27;prev&#x27;)&quot;, group: &#x27;prevNext&#x27;&#125; - &#123;id: &#x27;next&#x27;, name: &#x27;查看下一篇&#x27;, icon: &#x27;fa-solid fa-angles-right&#x27;, event: &quot;volantis.rightmenu.jump(&#x27;next&#x27;)&quot;, group: &#x27;prevNext&#x27;&#125;为了方便管理，将函数挂在 volantis.rightmenu 对象下12345678910111213141516171819202122232425&lt;script&gt; volantis.rightmenu.jump = (type) =&gt; &#123; const selector = type === &#x27;prev&#x27; ? &#x27;article .prev-next a.prev&#x27; : &#x27;article .prev-next a.next&#x27;; const item = document.querySelector(selector); if(!!item) &#123; if(typeof pjax !== &#x27;undefined&#x27;) &#123; pjax.loadUrl(item.href) &#125; else &#123; window.location.href = item.href; &#125; &#125; &#125; volantis.rightmenu.handle(() =&gt; &#123; const prev = document.querySelector(&#x27;#prev&#x27;).parentElement, next = document.querySelector(&#x27;#next&#x27;).parentElement, articlePrev = document.querySelector(&#x27;article .prev-next a.prev p.title&#x27;), articleNext = document.querySelector(&#x27;article .prev-next a.next p.title&#x27;); prev.style.display = articlePrev ? &#x27;block&#x27; : &#x27;none&#x27;; prev.title = articlePrev ? articlePrev.innerText : null; next.style.display = articleNext ? &#x27;block&#x27; : &#x27;none&#x27;; next.title = articleNext ? articleNext.innerText : null; &#125;, &#x27;prevNext&#x27;, false) &lt;/script&gt; 老版右键菜单目前老版右键与新版右键共存，但同时只能开启一个自定义右键菜单。 配置文件 blog/_config.volantis.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344# 自定义右键菜单rightmenu: enable: false faicon: fa # 公共图标类型 fa fal fa-solid fa-duotone # hr: 分割线, music: 音乐控制器 layout: [home, hr, help, examples, contributors, hr, source_docs, source_theme, hr, print, darkmode, reading, music] ### 可选功能项 ### print: # 只有文章页才允许自定义打印 name: 打印页面 icon: fa fa-print darkmode: # 需开启 plugins.darkmodejs name: 暗黑模式 icon: fa fa-moon reading: name: 阅读模式 icon: fa fa-book-open customPicUrl: # 右键的图片复制：只有 Chrome 支持，且只支持 PNG 格式的图片。 enable: false # 如果使用了对象存储且开启了自适应 Webp，那么可以提供额外的链接用以替换图片的访问地址 old: #https://static.inkss.cn/img/article/ new: #https://cdn.jsdelivr.net/gh/inkss/inkss-cdn@master/img/article/ music: # 当设定全局音乐播放器时，是否一直显示音乐控制菜单。false：仅当音乐播放时启用 alwaysShow: true ### 自定义菜单 ### help: name: 常见问题 icon: fa fa-question url: https://volantis.js.org/faqs/ examples: name: 示例博客 icon: fa fa-rss url: https://volantis.js.org/examples/ contributors: name: 加入社区 icon: fa fa-fan fa-spin url: https://volantis.js.org/contributors/ source_docs: name: 本站源码 icon: fa fa-code-branch url: https://github.com/volantis-x/volantis-docs/ source_theme: name: 主题源码 icon: fa fa-code-branch url: https://github.com/volantis-x/hexo-theme-volantis/#### 设置网站导航栏导航栏配置导航栏分为 logo、menu、search 三个区域设置，其中 logo 区域如果设置了图片，则不能显示图标和标题， menu 区域的设置可以写在一个单独的文件中。 blog/_config.volantis.yml123456789101112131415161718192021222324252627# 注意事项：建议规范全站路径 URL 最后带一个 &quot;/&quot; 例如 &quot;about/&quot;navbar: visiable: auto # always, auto logo: # choose [img] or [icon + title] img: volantis-static/media/org.volantis/blog/Logo-NavBar@3x.png # https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png icon: title: menu: - name: 博客 icon: fa-solid fa-rss url: / - name: 分类 icon: fa-solid fa-folder-open url: categories/ - name: 标签 icon: fa-solid fa-tags url: tags/ - name: 归档 icon: fa-solid fa-archive url: archives/ - name: 友链 icon: fa-solid fa-link url: friends/ - name: 关于 icon: fa-solid fa-info-circle url: about/ search: Search... # Search bar placeholder 菜单嵌套导航栏菜单支持嵌套，嵌套的属性名为 rows ，写法示例： 123456789101112131415161718192021222324...- name: 更多 icon: fa-solid fa-ellipsis-v rows: - name: 主题源码 url: https://github.com/volantis-x/hexo-theme-volantis/ - name: 更新日志 url: https://github.com/volantis-x/hexo-theme-volantis/releases/ - name: hr - name: 有疑问？ rows: - name: 看 FAQ url: faqs/ - name: 看 本站源码 url: https://github.com/volantis-x/volantis-docs/ - name: 提 Issue url: https://github.com/volantis-x/hexo-theme-volantis/issues/ - name: hr - name: 公告和测试博文 url: archives/ - name: 示例博客 url: examples/ - name: 特别感谢 url: contributors/ 分割线在子菜单中，新增一个只有 name: hr 的“菜单”就会被渲染成一个分割线。 1- name: hr 小标题在子菜单中，新增一个只有 name: 小标题内容（也可以有 icon: 小标题的图标）的“菜单”就会被渲染成一个小标题。 12345678910111213...- name: 近期 icon: fa-solid fa-clock url: / rows: - name: 热门文章 icon: fa-solid fa-fire - name: ProHUD 开源库的设计思路 url: blog/2019-08-27-prohud/ - name: ValueX：实用的安全对象类型转换库 url: blog/2019-08-29-valuex/ - name: 心率管家 App 的设计与开发 url: blog/2019-07-23-heartmate/ 播放器在子菜单中，新增一个 icon: fa-solid fa-compact-disc 的“菜单”就会被渲染成一个 APlayer 播放器。 12- name: 背景音乐 icon: fa-solid fa-compact-disc 设置网站页脚您通过 layout 可以自由布局网站页脚内容 aplayer, social, license, info, copyright。 blog/_config.volantis.yml123456789101112131415site_footer: # layout of footer: [aplayer, social, license, info, copyright] layout: [aplayer, social, license, info, copyright] social: - icon: fas fa-rss url: atom.xml - icon: fas fa-envelope url: mailto:me@xaoxuu.com - icon: fab fa-github url: https://github.com/xaoxuu - icon: fas fa-headphones-alt url: https://music.163.com/#/user/home?id=63035382 copyright: &#x27;[Copyright © 2017-2021 XXX](/)&#x27; # You can add your own property here. (Support markdown, for example: br: &#x27;&lt;br&gt;&#x27;) br: &#x27;&lt;br&gt;&#x27; 其中，aplayer 需要在插件部分设置中启用。您可以新增文字属性，用于展示其它文字信息，例如： blog/_config.volantis.yml123456site_footer: layout: [..., br, hello, ...] ... # You can add your own property here. (Support markdown, for example: br: &#x27;&lt;br&gt;&#x27;) br: &#x27;&lt;br&gt;&#x27; hello: &#x27;[Hello World](/)&#x27; 网站与文章封面封面高度blog/_config.volantis.yml123cover: height_scheme: full # full, half ... 目前主题提供两种首页封面高度方案，其它页面均为半屏幕高度。 封面布局方案blog/_config.volantis.yml1234cover: ... scheme: dock # search (搜索), dock (坞), featured (精选), focus (焦点) ... 布局方案 适合场景 search 注重搜索 dock 入口选项比较多 featured 选项在4个左右 focus 选项在4个左右 默认显示设置blog/_config.volantis.yml123456cover: ... display: home: true archive: false others: false # can be written in front-matter &#x27;cover: true&#x27; 由于主页、归档是 hexo 自动生成的，您需要在主题配置文件中设置是否显示封面，而其它页面则可以在 front-matter 中通过设置 cover: true/false 来决定显示封面或者不显示封面。 文章布局配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105# 文章布局article: # 文章列表页面的文章卡片布局方案 preview: scheme: landscape # landscape # pin icon for post pin_icon: https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0/assets/svg/1f4cc.svg # auto generate title if not exist auto_title: true # false, true # auto generate excerpt if not exist auto_excerpt: true # false, true # show split line or not line_style: solid # hidden, solid, dashed, dotted # show readmore button readmore: auto # auto, always # 文章详情页面的文章卡片本体布局方案 body: # 文章顶部信息 # 从 meta_library 中取 top_meta: [author, category, date, counter] # ---------------- # 文章页脚组件 footer_widget: # ---------------- # 参考资料、相关资料等 (for layout: post/docs) references: title: 参考资料 icon: fas fa-quote-left # 在 front-matter 中: # references: # - title: 某篇文章 # url: https:// # 即可显示此组件。 # ---------------- # 相关文章，需要安装插件 (for layout: post) # npm i hexo-related-popular-posts related_posts: enable: false title: 相关文章 icon: fas fa-bookmark max_count: 5 # 设为空则不使用文章头图 placeholder_img: https://cdn.jsdelivr.net/gh/volantis-x/cdn-wallpaper-minimalist/2020/046.jpg # ---------------- # 版权声明组件 (for layout: post/docs) copyright: enable: true permalink: &#x27;本文永久链接是：&#x27; content: - &#x27;博客内容遵循 署名-非商业性使用-相同方式共享 4.0 国际 (CC BY-NC-SA 4.0) 协议&#x27; - permalink # ---------------- # 打赏组件 (for layout: post/docs) donate: enable: false images: - https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png - https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png # 文章底部信息 # 从 meta_library 中取 bottom_meta: [updated, tags, share] # meta library meta_library: # 默认文章作者（可在 front-matter 中覆盖） author: avatar: name: 请设置文章作者 url: / # 文章创建日期 date: icon: fas fa-calendar-alt title: &#x27;发布于：&#x27; format: &#x27;ll&#x27; # 日期格式 http://momentjs.com/docs/ # 文章更新日期 updated: icon: fas fa-edit title: &#x27;更新于：&#x27; format: &#x27;ll&#x27; # 日期格式 http://momentjs.com/docs/ # 文章分类 category: icon: fas fa-folder-open # 文章浏览计数 counter: icon: fas fa-eye unit: &#x27;次浏览&#x27; # 文章字数和阅读时长 wordcount: icon_wordcount: fas fa-keyboard icon_duration: fas fa-hourglass-half # 文章标签 tags: icon: fas fa-hashtag # 分享 share: - id: qq img: https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qq.png - id: qzone img: https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/qzone.png - id: weibo img: https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/weibo.png - id: # qrcode # 当id为qrcode时需要安装插件 npm i hexo-helper-qrcode img: # https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/wechat.png - id: # telegram img: # https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/logo/128/telegram.png 其中 top_meta 和 bottom_meta 部分的取值自 meta_library 库。 侧边栏配置侧边栏小组件与 meta 库不同的是：除了现有的 widget ，您可以很轻易地创建自己的 widget ，然后放在需要的地方。此外，您还可以将 widget 写在单独的文件中。 查看所有相关配置 blog/_config.volantis.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899sidebar: # 主页、分类、归档等独立页面 for_page: [blogger, category, tagcloud, qrcode] # layout: docs/post 这类文章页面 for_post: [toc] # 侧边栏组件库 widget_library: # --------------------------------------- # blogger info widget blogger: class: blogger display: [desktop, mobile] # [desktop, mobile] avatar: https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/Logo-NavBar@3x.png shape: rectangle # circle, rectangle url: /about/ title: subtitle: jinrishici: true # Poetry Today. You can set a string, and it will be displayed when loading fails. social: true # --------------------------------------- # toc widget (valid only in articles) toc: class: toc display: [desktop, mobile] # [desktop, mobile] header: icon: fas fa-list title: 本文目录 list_number: false min_depth: 2 max_depth: 5 # --------------------------------------- # category widget category: class: category display: [desktop] # [desktop, mobile] header: icon: fas fa-folder-open title: 文章分类 url: /blog/categories/ # --------------------------------------- # tagcloud widget tagcloud: class: tagcloud display: [desktop, mobile] # [desktop, mobile] header: icon: fas fa-tags title: 热门标签 url: /blog/tags/ min_font: 14 max_font: 24 color: true start_color: &#x27;#999&#x27; end_color: &#x27;#555&#x27; # --------------------------------------- # qrcode widget donate: class: qrcode display: [desktop, mobile] # [desktop, mobile] height: 64px # Automatic height if not set images: - https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png - https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png # --------------------------------------- # webinfo widget webinfo: class: webinfo display: [desktop] header: icon: fa-solid fa-award title: 站点信息 type: article: enable: true text: &#x27;文章数目：&#x27; unit: &#x27;篇&#x27; runtime: enable: true data: &#x27;2020/01/01&#x27; # 填写建站日期 text: &#x27;已运行时间：&#x27; unit: &#x27;天&#x27; wordcount: enable: true text: &#x27;本站总字数：&#x27; # 需要启用 wordcount unit: &#x27;字&#x27; visitcounter: siteuv: enable: true text: &#x27;本站访客数：&#x27; unit: &#x27;人&#x27; sitepv: enable: true text: &#x27;本站总访问量：&#x27; unit: &#x27;次&#x27; lastupd: enable: true friendlyShow: true # 更友好的时间显示 text: &#x27;最后活动时间：&#x27; unit: &#x27;日&#x27; 每一个小部件都有 class 和 display，前者代表这个小部件是什么，后者代表这个小部件在什么桌面和移动平台中是否显示，如果在移动平台显示，由于屏幕宽度有限，侧边栏的小部件则会被移动到正文区域下方，因此部分侧边栏小部件便失去意义，建议设置为仅桌面端显示。 1234小部件名: class: 小部件类别 display: [小部件在桌面端是否显示, 小部件在移动设备是否显示] pjaxReload: true # 是否 pjax 重载 默认 true; 设置为 false 时 确保所有页面都含有该小部件 博主信息部件blog/_config.volantis.yml12345678blogger: class: blogger display: [desktop] # [desktop, mobile] avatar: https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/avatar/avatar.png title: subtitle: jinrishici: true # Poetry Today. You can set a string, and it will be displayed when loading fails. social: true 其中，今日诗词 jinrishici 如果设置为一个字符串，这个字符串会变成占位文字，加载失败时显示。如果不需要，就请设置为 jinrishici: false。social 的具体内容请在网站页脚部分设置。 文章目录部件blog/_config.volantis.yml123456789toc: class: toc display: [desktop, mobile] # [desktop, mobile] header: icon: fas fa-list title: 本文目录 list_number: false min_depth: 2 max_depth: 5 这个部件只能放置在侧边栏，并且在文章中有效。在移动设备中预览时，手指向上滑动时，导航栏右边会出现 TOC 按钮，点击即可展开 TOC 部件。如果您需要显示章节序号，请设置 list_number。 min_depth 和 max_depth 代表 TOC 支持的标题层级，最大范围是2～6。 文章分类部件blog/_config.volantis.yml1234567category: class: category display: [desktop] # [desktop, mobile] header: icon: fas fa-folder-open title: 文章分类 url: /blog/categories/ 这个部件可以直接显示所有文章分类，如果您希望有一个独立的页面来展示，需要自己创建一个文件，具体操作在「页面」部分文档中。 标签云部件blog/_config.volantis.yml123456789101112tagcloud: class: tagcloud display: [desktop] # [desktop, mobile] header: icon: fas fa-tags title: 热门标签 url: /blog/tags/ min_font: 14 max_font: 24 color: true start_color: &#x27;#999&#x27; end_color: &#x27;#555&#x27; 这个部件可以直接显示所有文章的标签，如果您希望有一个独立的页面来展示，需要自己创建一个文件，具体操作在「页面」部分文档中。 二维码部件blog/_config.volantis.yml1234567donate: class: qrcode display: [desktop, mobile] # [desktop, mobile] height: 64px # Automatic height if not set images: - https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png - https://cdn.jsdelivr.net/gh/volantis-x/cdn-org/blog/qrcode/github@volantis.png 您可以放置在文章页脚用于展示打赏图片，也可以放置在侧边栏。 通用文本部件blog/_config.volantis.yml123456789101112repos: class: text display: [desktop] # [desktop, mobile] header: icon: fab fa-github title: 点个赞吧 url: https://github.com/xaoxuu/ content: - &#x27;您的赞对我来说很重要，如果您喜欢本主题，希望能够给下面的项目点个赞来支持一下。&#x27; - &#x27;[&lt;img src=&quot;https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/proj/prohud/logo.png&quot; height=&quot;50px&quot;&gt;](https://github.com/xaoxuu/ProHUD)&#x27; - &#x27;[&lt;img src=&quot;https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/proj/valuex/logo.png&quot; height=&quot;50px&quot;&gt;](https://github.com/xaoxuu/ValueX)&#x27; - &#x27;[&lt;img src=&quot;https://cdn.jsdelivr.net/gh/xaoxuu/cdn-assets/proj/inspire/logo.png&quot; height=&quot;50px&quot;&gt;](https://github.com/xaoxuu/Inspire)&#x27; 您可以创建用于展示任何文本内容的文本部件。 通用列表部件blog/_config.volantis.yml123456789101112wiki-hexo-theme: class: list display: [desktop, mobile] # [desktop, mobile] header: icon: fas fa-chevron-left title: Hexo Themes url: /wiki/ rows: - name: Volantis for Hexo url: /wiki/volantis/ - name: Resume for Hexo url: /wiki/resume/ 您可以创建用于展示任何链接列表的列表部件。列表的 rows 中的每一项支持的属性有： name、url、icon、img、avatar，其中 img 是方形图片的链接，avatar 是圆形图片的链接。 组索引这个部件的布局继承自 list 部件，用于展示文章所属的分组的文章列表。请将您的 Volantis 升级至 2.5 版本以上使用。 blog/_config.volantis.yml1234567group-1: class: group display: [desktop, mobile] # [desktop, mobile] header: icon: fab fa-github title: Git url: /wiki/git/ 在文章的 front-matter 中设置： front-matter123group: group-1order: 16sidebar: [group-1, toc] 「group-1」卡片将会以列表的形式显示所有设置了 group: group-1 的文章，顺序按照 order 从小到大排列。 通用网格部件blog/_config.volantis.yml123456789101112131415161718feedback: class: grid display: [desktop, mobile] header: icon: fas fa-headset title: 联系开发者 url: https://github.com/volantis-x/hexo-theme-volantis fixed: true # 固定宽度 rows: - name: 反馈BUG icon: fas fa-bug url: https://github.com/volantis-x/hexo-theme-volantis/issues/ - name: 疑问求助 icon: fas fa-question-circle url: https://github.com/volantis-x/hexo-theme-volantis/issues/ - name: 提个建议 icon: fas fa-lightbulb url: https://github.com/volantis-x/hexo-theme-volantis/issues/ 您可以创建用于展示任何链接列表的网格部件。网格默认根据文字长度自动确定每一个格子的宽度，如果文字长短不一，建议通过设置 fixed: true 来固定宽度，此时文字过长的格子中的文字会换行显示。 通用页面部件blog/_config.volantis.yml12345test: class: page display: [desktop, mobile] pid: haha content: excerpt # excerpt, more, content 您可以把整个页面的md内容作为一个小部件渲染显示出来。只需要设置小部件里的 pid 属性和文章的 front-matter 中设置一样的 pid 即可。 content 代表这个部件显示的内容，可选 excerpt，more，content 分别对应文章的摘要、摘要后面的内容、全文。 音乐部件blog/_config.volantis.yml1234music: class: music display: [desktop, mobile] # [desktop, mobile] pjaxReload: false 选择评论系统目前共支持 14 款评论系统： artalk, giscus, beaudar, utterances, twikoo, waline, discuss, disqus, disqusjs, gitalk, vssue, livere, isso, hashover blog/_config.volantis.yml1234comments: title: &lt;i class=&#x27;fas fa-comments&#x27;&gt;&lt;/i&gt; 评论 subtitle: service: giscus GitHub Discussions 系列 giscus A comments system powered by GitHub Discussions. https://giscus.app/blog/_config.volantis.yml123456789101112131415161718192021comments: ... service: giscus ... # giscus # https://giscus.app # https://github.com/laymonage/giscus giscus: # 以下配置按照 yml 格式增删填写即可 # repo: xxx/xxx # repo-id: xxx # category: xxx # category-id: xxx # mapping: &quot;pathname&quot; # reactions-enabled: &quot;1&quot; # emit-metadata: &quot;0&quot; # lang: &quot;zh-CN&quot; # 以上配置按照 yml 格式增删填写即可 theme: light: &quot;light&quot; # https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/css/giscus/light.css dark: &quot;dark&quot; # https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@master/css/giscus/dark.css GitHub Issues 系列 beaudarutterancesVssueGitalk Beaudar 名称源于粤语“表达”的发音，是 Utterances 的中文版本。 https://beaudar.lipk.org/blog/_config.volantis.yml1234567891011121314151617comments: ... service: beaudar ... # beaudar # https://beaudar.lipk.org/ beaudar: repo: xxx/xxx issue-term: pathname issue-number: branch: main position: top order: desc theme: light: github-light dark: github-dark label: ✨💬✨ A lightweight comments widget built on GitHub issues. https://utteranc.es/blog/_config.volantis.yml1234567891011121314comments: ... service: utterances ... # utterances # https://utteranc.es/ utterances: repo: xxx/xxx issue-term: pathname issue-number: theme: light: github-light dark: github-dark label: ✨💬✨ Vue 驱动的、基于 Issue 的评论插件 https://vssue.js.org/zh/blog/_config.volantis.yml123456789comments: ... service: vssue ... vssue: owner: repo: clientId: clientSecret: A modern comment component based on Github Issue and Preact. https://gitalk.github.io/blog/_config.volantis.yml12345678910comments: ... service: gitalk ... gitalk: clientID: clientSecret: repo: owner: admin: # []clientID 和 clientSecret 的获取方法可自行搜索教程，这里仅简单描述一下步骤：点击 GitHub -&gt; Settings https://github.com/settings/profile点击 Developer settings https://github.com/settings/developers点击 New OAuth App https://github.com/settings/applications/new填写信息：Application name 随便填，我的是：xaoxuu.comHomepage URL 和 Authorization callback URL 都写你的网址，我的是：https://xaoxuu.com可以通过设置 gitalk.id 实现多个页面共用一个评论框。front-matter1234---gitalk: id: /wiki/volantis/--- Disqus 系列 DisqusDisqusJSIsso Disqus - The #1 way to build an audience on your website. https://disqus.com/blog/_config.volantis.yml123456comments: ... service: disqus ... disqus: shortname:可以通过设置 disqus.path 实现多个页面共用一个评论框。front-matter1234---disqus: path: /wiki/volantis/--- Render Disqus comments in Mainland China using Disqus API https://github.com/SukkaW/DisqusJSblog/_config.volantis.yml1234567891011121314comments: ... service: disqusjs ... # DisqusJS # https://github.com/SukkaW/DisqusJS disqusjs: path: # 全局评论地址 # 配置项按照yml格式继续填写即可 除了 [siteName url identifier] 选项 #shortname: #api: #apikey: #admin: #nesting: A commenting server similar to Disqus. https://posativ.org/isso/blog/_config.volantis.yml1234567comments: ... service: isso ... isso: url: https://example.com/(path/) src: https://example.com/(path/)js/embed.min.js Valine 衍生系列 Valine 在 5.0 版本被移除,具体原因可参考hexo-theme-next#188#issuecomment-766578906以下是在解决 valine 遗留问题同一时期产生的评论系统故归为一类, 然在其社区issue中也报告了类似的攻击事件(eg: twikoo#157 waline#424 waline#430),故请谨慎选择.discusstwikooWaline 一款简单，安全，免费的评论系统 | A simple, safe, free comment system https://discuss.js.orgblog/_config.volantis.yml12345678910comments: ... service: discuss ... # Discuss # https://discuss.js.org discuss: js: https://cdn.jsdelivr.net/npm/discuss/dist/Discuss.js # 建议锁定版本 serverURLs: # Discuss server address url # https://discuss.js.org/Quick-Start.html#path其中，placeholder 支持在 front-matter 中设置。front-matter1234---discuss: placeholder: 你觉得xxx怎么样呢？---也可以通过设置 discuss.path 实现多个页面共用一个评论框。front-matter1234---discuss: path: /--- 一个简洁、安全、免费的静态网站评论系统 | A simple, safe, free comment system. https://twikoo.js.org/blog/_config.volantis.yml123456789comments: ... service: twikoo ... twikoo: js: https://cdn.jsdelivr.net/npm/twikoo@latest # 建议锁定版本 path: # 全局评论地址 # 其他配置项按照yml格式继续填写即可 除了 [el path] 选项 envId: xxxxxxxxxxxxxxx # 腾讯云环境id其中，placeholder 支持在 front-matter 中设置。front-matter1234---twikoo: placeholder: 你觉得xxx怎么样呢？---也可以通过设置 twikoo.path 实现多个页面共用一个评论框。front-matter1234---twikoo: path: /--- 一个简洁、安全、免费的静态网站评论系统 | A simple, safe, free comment system. https://waline.js.org/blog/_config.volantis.yml1234567891011121314comments: ... service: waline ... # Waline # https://waline.js.org/ waline: js: https://cdn.jsdelivr.net/npm/@waline/client/dist/Waline.min.js path: # 全局评论地址 目前设置全局评论地址后visitor失效,这是waline的问题 placeholder: 快来评论吧~ # 评论占位提示 imageHosting: https://7bu.top/api/upload # 图床api（默认使用去不图床） # 其他配置项按照yml格式继续填写即可 除了 [el path placeholder uploadImage] 选项 serverURL: xxxxxxxxxxxxxxx # Waline 的服务端地址（必填） 测试用地址: https://waline-ruddy.vercel.app ... 可选配置项详见源码其中，placeholder 支持在 front-matter 中设置。front-matter1234---waline: placeholder: 你觉得xxx怎么样呢？---也可以通过设置 waline.path 实现多个页面共用一个评论框。front-matter1234---waline: path: /--- Others 其他系列 ArtalkLivereHashoverMore... 一款简洁的自托管评论系统 | A Selfhosted Comment System. https://artalk.js.org/blog/_config.volantis.yml12345678comments: ... service: artalk ... artalk: js: https://cdn.jsdelivr.net/npm/artalk@2.1.3/dist/Artalk.js css: https://cdn.jsdelivr.net/npm/artalk@2.1.3/dist/Artalk.css server: http://127.0.0.1:8080/api # 修改为自建的后端服务地址其中，placeholder 支持在 front-matter 中设置。front-matter1234---artalk: placeholder: 你觉得xxx怎么样呢？---也可以通过设置 artalk.path 实现多个页面共用一个评论框。front-matter1234---artalk: path: /--- Communication makes better world. https://www.livere.com/blog/_config.volantis.yml123456comments: ... service: livere ... livere: uid: #你的livere的uid在这里查看你的 uid：https://livere.com/insight/myCode，在【代码管理 -&gt; 一般网站】中找到如下这段代码，其中 data-uid 中的内容就是你的 livere_uid。123&lt;!-- 来必力City版安装代码 --&gt;&lt;div id=&quot;lv-container&quot; data-id=&quot;city&quot; data-uid=&quot;你的livere的uid&quot;&gt;... A free and open source PHP comment system designed to allow completely anonymous comments and easy theming. https://www.barkdull.org/software/hashoverblog/_config.volantis.yml123456comments: ... service: hashover ... hashover: src: https://example.com/(path/)comments.phpblog/themes/volantis/layout/_third-party/comments/评论系统名称/layout.ejs1这里写布局代码blog/themes/volantis/layout/_third-party/comments/评论系统名称/script.ejs1这里要写加载 js 的代码收录更多评论系统 可以通过在 front-matter 设置 config 实现在特定页面修改评论系统的相关配置。 支持的有(按字母顺序): discuss, giscus, gitalk, twikoo, waline front-matter12345---gitalk: config: id: /233/--- 站内搜索blog/_config.volantis.yml1234search: enable: true service: hexo # hexo js: https://cdn.jsdelivr.net/xxxxxxxx/js/search/hexo.js 默认配置为 Hexo 搜索，但是需要安装插件才能使用： 1npm i -S hexo-generator-json-content 原 google, algolia, azure, baidu 站内搜索 系祖传代码, 且文档丢失, 不便后续维护 在 5.0 版本移除 插件库概述Volantis 为丰富的插件提供了兼容性优化。大部分插件您只需开启和关闭，无需进行设置。 幻灯片背景(视差滚动效果)jquery.backstretch 在 5.0 版本 移除, 被 parallax 替代 blog/_config.volantis.yml1234567891011plugins: ... parallax: enable: true position: cover # cover: sticky on the cover. fixed: Fixed as background for the site. shuffle: true # shuffle playlist duration: 10000 # Duration (ms) fade: 1500 # fade duration (ms) (Not more than 1500) images: # For personal use only. At your own risk if used for commercial purposes !!! - https://cdn.jsdelivr.net/gh/volantis-x/cdn-wallpaper/abstract/41F215B9-261F-48B4-80B5-4E86E165259E.jpeg ... 幻灯片背景图片显示的位置可以选择粘贴在封面上，跟随封面一起滑动，也可以选择固定作为网页背景图片。 highlight.jsblog/_config.volantis.yml1234567891011plugins: ... # 代码高亮 code_highlight: highlightjs # highlightjs or prismjs # highlight.js highlightjs: copy_code: true # 如果开启 js, hexo.config.highlight.enable 需要设置为 false js: #https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.1.0/build/highlight.min.js # Please set hexo.config.highlight.enable = false !!! css: https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.1.0/build/styles/default.min.css # more: https://www.jsdelivr.com/package/npm/highlight.js?path=styles 如果需要使用 highlight.js 进行语法高亮，请将站点配置文件中的 highlight.enable 设置为 false 否则不会加载插件。您可以在 94 种 语法高亮主题 中挑选喜爱的主题，然后替换上面的 css 链接。 如果您使用 highlight.js 请确保没有使用 hexo 官方的 codeblock 标签，否则会报错。 经测试，使用 highlight.js 的情况下，部分容器内的代码可能仍然会被渲染甚至报错。 APlayer 音乐播放器blog/_config.volantis.yml12345678910111213141516171819202122plugins: ... # APlayer is only available in mainland China. # APlayer config: https://github.com/metowolf/MetingJS aplayer: enable: true js: aplayer: https://cdn.jsdelivr.net/npm/aplayer@1.10/dist/APlayer.min.js meting: https://cdn.jsdelivr.net/npm/meting@2.0/dist/Meting.min.js # Required server: netease # netease, tencent, kugou, xiami, baidu type: playlist # song, playlist, album, search, artist id: 3175833810 # song id / playlist id / album id / search keyword # Optional fixed: false # enable fixed mode theme: &#x27;#1BCDFC&#x27; # main color autoplay: false # audio autoplay order: list # player play order, values: &#x27;list&#x27;, &#x27;random&#x27; loop: all # player loop play, values: &#x27;all&#x27;, &#x27;one&#x27;, &#x27;none&#x27; volume: 0.7 # default volume, notice that player will remember user setting, default volume will not work after user set volume themselves list_max_height: 320px # list max height list_folded: true APlayer播放器只可以在中国大陆地区使用。相关文档： APlayer | MetingJS 暗黑模式blog/_config.volantis.yml123456789plugins: ... # 暗黑模式 darkmode # 开关按钮：在 navbar.menu 中添加： # - name: 暗黑模式 # 可自定义 # icon: fas fa-moon # 可自定义 # toggle: darkmode darkmode: enable: true 结束支持blog/_config.volantis.yml12345678910111213plugins: ... # 旧版 Internet Explorer 淘汰行动 # https://www.microsoft.com/zh-cn/WindowsForBusiness/End-of-IE-support # 本主题不支持Internet Explorer的任何版本!!! killOldVersionsOfIE: enable: true # 禁用JavaScript提示 # 本页面需要浏览器支持（启用）JavaScript # 主题中的某些插件必须启用JavaScript才能正常工作，例如开启scrollreveal如果禁用JavaScript会导致卡片消失 killNoScript: enable: true Artitalkblog/_config.volantis.yml1234567891011121314151617181920212223plugins: ... # Artitalk https://artitalk.js.org # 配置过程请参考：https://artitalk.js.org/doc.html # 使用过旧版本的请修改Leancloud shuoshuo class部分列名：https://artitalk.js.org/release.html # 除appID和appKEY外均为选填项 artitalk: # Set `plugins: [&quot;artitalk&quot;]` to enable in front-matter # 不支持 Pjax # 配置项按照yml格式继续填写即可 appId: ogP8qj3veMh0LFpFWMPOyF0X-MdYXbMMI # your appID appKey: nHXLd3N3Jgh460t2iRQKWAtr # your appKEY # serverURL: #leancloud绑定的api访问域名，使用国际版的话不需要填写 # lang: # 语言设置，zh为汉语，en为英语，es为西班牙语。默认为汉语 # pageSize: #每页说说的显示数量 # shuoPla: #在编辑说说的输入框中的占位符 # avatarPla: #自定义头像url的输入框的占位符 # motion: #加载动画的开关，1为开，0为关，默认为开 # bgImg: #说说输入框背景图片url # color1: #说说背景颜色1&amp;按钮颜色1 # color2: #说说背景颜色2&amp;按钮颜色2 # color3: #说说字体颜色 # cssUrl: #自定义css接口 BBtalkblog/_config.volantis.yml12345678910plugins: ... # BBtalk https://bb.js.org bbtalk: # Set `plugins: [&quot;bbtalk&quot;]` to enable in front-matter # 支持 Pjax js: https://cdn.jsdelivr.net/npm/bbtalk@0.1.5/dist/bbtalk.min.js # BBtalk.js appId: 0KzOX4vC7Jsk6vzUGNeEiUaI-gzGzoHsz # your appID appKey: HwCiWuxfpvKiLm4teCUgTIba # your appKEY serverURLs: https://bbapi.heson10.com # Request Api 域名 Tidioblog/_config.volantis.yml123456789plugins: ... # 聊天功能 chat_service: tidio # tidio or gitter # Tidio # https://www.tidio.com/ tidio: id: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx 友链朋友圈blog/_config.volantis.yml1234567891011121314plugins: ... # 友链朋友圈 hexo-circle-of-friends # https://github.com/Rock-Candy-Tea/hexo-circle-of-friends # https://zfe.space/post/friend-link-circle.html fcircle: # Set `plugins: [&quot;fcircle&quot;]` to enable in front-matter # 支持 Pjax api: &#x27;&#x27; # api 地址 max_number: 20 # 页面展示文章数量 add_number: 10 # 每次加载增加的篇数 opentype: &#x27;_blank&#x27; # &#x27;_blank&#x27;打开新标签,&#x27;_self&#x27;本窗口打开 nofollow: true # 禁止搜索引擎抓取 # loadingCutom: # 自定义loading图 例如: &lt;i class=&quot;fa fa-spinner fa-spin&quot;&gt;&lt;/i&gt; | &lt;img src=&quot;你的图片地址&quot; alt=&quot;加载中...&quot;&gt; 消息提示blog/_config.volantis.yml123456789101112131415161718192021222324252627282930313233plugins: ... # 消息提示 # izitoast@1.4.0 message: enable: true css: volantis-static/libs/izitoast/dist/css/iziToast.min.css js: volantis-static/libs/izitoast/dist/js/iziToast.min.js icon: # 默认图标，支持对图标添加颜色，可选值：see：/source/css/_style/_plugins/fontcolor.styl default: fa-solid fa-info-circle light-blue quection: fa-solid fa-question-circle light-blue time: # 默认持续时间 default: 5000 quection: 20000 position: &#x27;topRight&#x27; # 弹出位置 可选值：topRight, bottomRight, bottomLeft, topLeft, topCenter, bottomCenter, center transitionIn: &#x27;bounceInLeft&#x27; # 弹窗打开动画 可选值：bounceInLeft, bounceInRight, bounceInUp, bounceInDown, fadeIn, fadeInDown, fadeInUp, fadeInLeft, fadeInRight, flipInX transitionOut: &#x27;fadeOutRight&#x27; # 弹窗关闭动画 可选值：fadeOut, fadeOutUp, fadeOutDown, fadeOutLeft, fadeOutRight, flipOutX titleColor: &#x27;var(--color-text)&#x27; # 标题颜色 messageColor: &#x27;var(--color-text)&#x27; # 消息颜色 backgroundColor: &#x27;var(--color-card)&#x27; # 默认背景色 zindex: 2147483647 # 层级 copyright: # 是否在复制时弹出版权提示，影响范围：ctrl+c、代码块复制按钮、右键复制选项 enable: true title: &#x27;知识共享许可协议&#x27; message: &#x27;请遵守 CC BY-NC-SA 4.0 协议。&#x27; icon: &#x27;far fa-copyright light-blue&#x27; aplayer: # 是否开启音乐通知；播放、暂停、失败 时的图标 enable: true play: fa-solid fa-play pause: fa-solid fa-pause rightmenu: enable: true # 是否开启右键模块的消息通知 notice: true # 唤醒原右键菜单的通知 轮播标签使用方法参见：swiper blog/_config.volantis.yml1234swiper: enable: true css: https://unpkg.com/swiper@6/swiper-bundle.min.css js: https://unpkg.com/swiper@6/swiper-bundle.min.js","categories":[{"name":"Front-end","slug":"Front-end","permalink":"https://yaelcassini.github.io/categories/Front-end/"}],"tags":[{"name":"Github Pages","slug":"Github-Pages","permalink":"https://yaelcassini.github.io/tags/Github-Pages/"},{"name":"Hexo","slug":"Hexo","permalink":"https://yaelcassini.github.io/tags/Hexo/"},{"name":"Volantis","slug":"Volantis","permalink":"https://yaelcassini.github.io/tags/Volantis/"}]},{"title":"Github+Hexo+Volantis个人主页搭建流程","slug":"Website-Building-Tutorials","date":"2022-06-08T10:28:46.000Z","updated":"2024-01-03T09:47:09.362Z","comments":true,"path":"2022/06/08/Website-Building-Tutorials/","link":"","permalink":"https://yaelcassini.github.io/2022/06/08/Website-Building-Tutorials/","excerpt":"本网站建立依附于Github Pages，使用到的框架是Hexo（基于Node.js），使用的主题是Volantis，图床使用Github自行搭建。目前用到的外部支持有：Busuanzi、Giscus、Parallax等。","text":"本网站建立依附于Github Pages，使用到的框架是Hexo（基于Node.js），使用的主题是Volantis，图床使用Github自行搭建。目前用到的外部支持有：Busuanzi、Giscus、Parallax等。 后置教程： Github+Hexo+Volantis个人主页个性化搭建（进阶版）https://yaelcassini.github.io/2024/01/03/Website-Building-Tutotrials-Futher/ 搭建参考教程链接： https://zhuanlan.zhihu.com/p/60578464 https://zhuanlan.zhihu.com/p/111614119 主要步骤一. 安装Git和Node.js Git官网：https://nodejs.org/en/download/ 检查是否安装成功命令（cmd）：git--version Node.js官网：https://nodejs.org/en/download/ 检查是否安装成功命令（cmd）：node -v 和 npm -v 二. 本地部署Hexo博客1. 新建文件夹 空文件夹名：用户名.github.io（用户名为github用户名） 2. 安装Hexo 右键Git Bash Here，输入命令：$ npm install hexo-cli -g 检查是否安装成功命令：hexo -v 安装一键部署插件：npm install hexo-deployer-git --save 3. hexo初始化并安装依赖 hexo init npm install Hexo文件夹目录结构： 4. 生成页面并本地预览 hexo g &amp;&amp; hexo s 切换端口号预览：hexo server -p 5000 5. 修改_config中的主题为volantis1theme: volantis 6. 下载Volantis主题，编译查看效果 安装主题：npm i hexo-theme-volantis 安装 Hexo 搜索的依赖包：npm i hexo-generator-search hexo-generator-json-content 安装 Stylus 渲染器：npm i hexo-renderer-stylus 7. 创建Volantis主题所需要的页面 参考链接：https://blog.csdn.net/qq_44161695/article/details/117648144 创建分类：hexo new page “categories”，并修改内容为： 1234567---layout: categoryindex: truetitle: 所有分类sidebar: [blogger]date: 2022-06-08 18:09:42--- 创建标签：hexo new page “tags”，并修改内容为： 1234567---layout: tagindex: truetitle: 所有标签sidebar: [blogger]date: 2022-06-08 18:10:12--- 创建关于我：hexo new page “about”，并修改内容为： 123456789---layout: docsseo_title: 关于bottom_meta: falsesidebar: []valine:placeholder: 有什么想对我说的呢？date: 2022-06-08 18:10:36--- 创建友链：hexo new page “friends” 8. 主题样式配置 新建_config.volantis.yaml，参考Volantis官网源码修改_config.volantis. yaml文件：https://github.com/volantis-x/community/blob/main/_config.volantis.yml 9. 常用命令12345678hexo new &quot;name&quot; # 新建文章hexo new page &quot;name&quot; # 新建页面hexo g # 生成页面hexo d # 部署hexo g -d # 生成页面并部署hexo s # 本地预览hexo clean # 清除缓存和已生成的静态文件hexo help # 帮助 10. tips Hexo 设置显示文章摘要，首页不显示全文Hexo 主页文章列表默认会显示文章全文，浏览时很不方便，可以在文章中插入 &lt;!--more--&gt; 进行分段。该代码前面的内容会作为摘要显示，而后面的内容会替换为 “Read More” 隐藏起来。 连接不上Github： https://blog.csdn.net/sinat_32017511/article/details/115762643 https://blog.csdn.net/Sheyami/article/details/121631887 可以尝试在.git&#x2F;config中增加： 12[http] sslVerify = false 最终解决方案：重新Clone（orz 三. 部署到Github Github官网：https://github.com/1. 创建仓库：仓库名：用户名.github.io2. 本地配置git username和git useremail12git config --global user.name &quot;Name&quot;git config --global user.email &quot;Email&quot; 3. SSH-key配置 参考链接：https://zhuanlan.zhihu.com/p/111614119 本地生成密钥： 1ssh-keygen -t rsa -C &quot;Email&quot; 打开：C:&#x2F;Users&#x2F;用户名&#x2F;.ssh&#x2F;id_rsa.pub，并全选复制。 在Github-Settings新建SSH，并粘贴。 本地输入以下命令检查是否成功连接： 1ssh -T git@github.com 4. 在_config.yaml中加入deploy配置123456# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy:type: gitrepository: git@github.com:panakot/panakot.github.io.gitbranch: master 5. 部署网页并查看效果1hexo d 四. 使用github建立图床1. 新建Github仓库2. 下载图片并上传到Github仓库3. 通过链接访问图片格式示例：https://cdn.jsdelivr.net/gh/YaelCassini/MyGraphBed/note/202206141355.jpg 其中，YaelCassini为github的username，MyGraphBed为我创建的仓库名称，而note&#x2F;202206141355.jpg为仓库内图片的路径 五. 配置插件1. 配置计数busuanzi2. 配置插件giscus： 官网：https://giscus.app/zh-CN 参考资料： https://www.michaeltan.org/posts/giscus/ https://vuepress-theme-hope.github.io/v1/comment/zh/guide/giscus.html 六. 多设备管理源码 参考链接： https://www.zhihu.com/question/21193762/answer/103097754 https://blog.csdn.net/heimu24/article/details/81210640 https://zhangypcn.github.io/2020/07/04/Personal-Website-Hexo-Source-Management/ https://www.zhihu.com/question/21193762/answer/103097754旧设备： Github新建仓库YealCassini_BlogCode(可以私有)，以使用git管理Hexo源码 将源码传到Github仓库，gitignore参考设置如下： 1234567.DS_StoreThumbs.dbdb.json*.lognode_modules/public/.deploy*/ 新设备： 安装Git和Node.js 生成SSH key并添加到github 命令行clone源码并安装需要的库： git clone npm install npm install hexo-deployer-git –save 附录Icon网站 https://cdn.jsdelivr.net/gh/twitter/twemoji@13.0.0/assets/svg/ https://unpkg.com/browse/volantis-static@0.0.1649552113628/media/org.volantis/icon/1322024-social-media/ https://fontawesome.com/icons?d=gallery","categories":[{"name":"Front-end","slug":"Front-end","permalink":"https://yaelcassini.github.io/categories/Front-end/"}],"tags":[{"name":"Github Pages","slug":"Github-Pages","permalink":"https://yaelcassini.github.io/tags/Github-Pages/"},{"name":"Hexo","slug":"Hexo","permalink":"https://yaelcassini.github.io/tags/Hexo/"},{"name":"Volantis","slug":"Volantis","permalink":"https://yaelcassini.github.io/tags/Volantis/"}]},{"title":"Hello World","slug":"hello-world","date":"2022-06-08T10:00:00.000Z","updated":"2023-09-06T09:53:29.203Z","comments":true,"path":"2022/06/08/hello-world/","link":"","permalink":"https://yaelcassini.github.io/2022/06/08/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/"},{"name":"Rendering","slug":"Computer-Graphics/Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Rendering/"},{"name":"Front-end","slug":"Front-end","permalink":"https://yaelcassini.github.io/categories/Front-end/"},{"name":"Tool Development","slug":"Tool-Development","permalink":"https://yaelcassini.github.io/categories/Tool-Development/"},{"name":"Others","slug":"Others","permalink":"https://yaelcassini.github.io/categories/Others/"},{"name":"Relighting Project","slug":"Relighting-Project","permalink":"https://yaelcassini.github.io/categories/Relighting-Project/"},{"name":"Neural Rendering","slug":"Computer-Graphics/Neural-Rendering","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Neural-Rendering/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://yaelcassini.github.io/categories/Computer-Vision/"},{"name":"Design&Art","slug":"Design-Art","permalink":"https://yaelcassini.github.io/categories/Design-Art/"},{"name":"Virtual Reality","slug":"Computer-Graphics/Virtual-Reality","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Virtual-Reality/"},{"name":"Computer Animation","slug":"Computer-Graphics/Computer-Animation","permalink":"https://yaelcassini.github.io/categories/Computer-Graphics/Computer-Animation/"}],"tags":[{"name":"Blender","slug":"Blender","permalink":"https://yaelcassini.github.io/tags/Blender/"},{"name":"Rendering","slug":"Rendering","permalink":"https://yaelcassini.github.io/tags/Rendering/"},{"name":"BSDF","slug":"BSDF","permalink":"https://yaelcassini.github.io/tags/BSDF/"},{"name":"Computer Graphics","slug":"Computer-Graphics","permalink":"https://yaelcassini.github.io/tags/Computer-Graphics/"},{"name":"Github Pages","slug":"Github-Pages","permalink":"https://yaelcassini.github.io/tags/Github-Pages/"},{"name":"Hexo","slug":"Hexo","permalink":"https://yaelcassini.github.io/tags/Hexo/"},{"name":"Volantis","slug":"Volantis","permalink":"https://yaelcassini.github.io/tags/Volantis/"},{"name":"Physically Based Rendering","slug":"Physically-Based-Rendering","permalink":"https://yaelcassini.github.io/tags/Physically-Based-Rendering/"},{"name":"Microfacet","slug":"Microfacet","permalink":"https://yaelcassini.github.io/tags/Microfacet/"},{"name":"Materials","slug":"Materials","permalink":"https://yaelcassini.github.io/tags/Materials/"},{"name":"Camera","slug":"Camera","permalink":"https://yaelcassini.github.io/tags/Camera/"},{"name":"Monte Carlo","slug":"Monte-Carlo","permalink":"https://yaelcassini.github.io/tags/Monte-Carlo/"},{"name":"Quaternions","slug":"Quaternions","permalink":"https://yaelcassini.github.io/tags/Quaternions/"},{"name":"Math","slug":"Math","permalink":"https://yaelcassini.github.io/tags/Math/"},{"name":"Plugins","slug":"Plugins","permalink":"https://yaelcassini.github.io/tags/Plugins/"},{"name":"Pytroch","slug":"Pytroch","permalink":"https://yaelcassini.github.io/tags/Pytroch/"},{"name":"Python","slug":"Python","permalink":"https://yaelcassini.github.io/tags/Python/"},{"name":"Numpy","slug":"Numpy","permalink":"https://yaelcassini.github.io/tags/Numpy/"},{"name":"Vue.js","slug":"Vue-js","permalink":"https://yaelcassini.github.io/tags/Vue-js/"},{"name":"Element-UI","slug":"Element-UI","permalink":"https://yaelcassini.github.io/tags/Element-UI/"},{"name":"GPU","slug":"GPU","permalink":"https://yaelcassini.github.io/tags/GPU/"},{"name":"Machine Learing","slug":"Machine-Learing","permalink":"https://yaelcassini.github.io/tags/Machine-Learing/"},{"name":"Nerual Rendering","slug":"Nerual-Rendering","permalink":"https://yaelcassini.github.io/tags/Nerual-Rendering/"},{"name":"Neural Rendering","slug":"Neural-Rendering","permalink":"https://yaelcassini.github.io/tags/Neural-Rendering/"},{"name":"Artificial Intelligence","slug":"Artificial-Intelligence","permalink":"https://yaelcassini.github.io/tags/Artificial-Intelligence/"},{"name":"Games101","slug":"Games101","permalink":"https://yaelcassini.github.io/tags/Games101/"},{"name":"Notes","slug":"Notes","permalink":"https://yaelcassini.github.io/tags/Notes/"},{"name":"Homework","slug":"Homework","permalink":"https://yaelcassini.github.io/tags/Homework/"},{"name":"Computer Vision","slug":"Computer-Vision","permalink":"https://yaelcassini.github.io/tags/Computer-Vision/"},{"name":"Harris Corner","slug":"Harris-Corner","permalink":"https://yaelcassini.github.io/tags/Harris-Corner/"},{"name":"Real-Time Rendering","slug":"Real-Time-Rendering","permalink":"https://yaelcassini.github.io/tags/Real-Time-Rendering/"},{"name":"PBR","slug":"PBR","permalink":"https://yaelcassini.github.io/tags/PBR/"},{"name":"Art","slug":"Art","permalink":"https://yaelcassini.github.io/tags/Art/"},{"name":"Scene Degign","slug":"Scene-Degign","permalink":"https://yaelcassini.github.io/tags/Scene-Degign/"},{"name":"Modeling","slug":"Modeling","permalink":"https://yaelcassini.github.io/tags/Modeling/"},{"name":"Git","slug":"Git","permalink":"https://yaelcassini.github.io/tags/Git/"},{"name":"Submodule","slug":"Submodule","permalink":"https://yaelcassini.github.io/tags/Submodule/"},{"name":"Computer Animation","slug":"Computer-Animation","permalink":"https://yaelcassini.github.io/tags/Computer-Animation/"},{"name":"Design","slug":"Design","permalink":"https://yaelcassini.github.io/tags/Design/"},{"name":"Unity","slug":"Unity","permalink":"https://yaelcassini.github.io/tags/Unity/"},{"name":"Degign","slug":"Degign","permalink":"https://yaelcassini.github.io/tags/Degign/"},{"name":"Hand-painted","slug":"Hand-painted","permalink":"https://yaelcassini.github.io/tags/Hand-painted/"},{"name":"Hough Transformation","slug":"Hough-Transformation","permalink":"https://yaelcassini.github.io/tags/Hough-Transformation/"},{"name":"EyeTracking","slug":"EyeTracking","permalink":"https://yaelcassini.github.io/tags/EyeTracking/"},{"name":"Virtual Reality","slug":"Virtual-Reality","permalink":"https://yaelcassini.github.io/tags/Virtual-Reality/"},{"name":"ZBuffer","slug":"ZBuffer","permalink":"https://yaelcassini.github.io/tags/ZBuffer/"},{"name":"ScanLine ZBuffer","slug":"ScanLine-ZBuffer","permalink":"https://yaelcassini.github.io/tags/ScanLine-ZBuffer/"},{"name":"Octree","slug":"Octree","permalink":"https://yaelcassini.github.io/tags/Octree/"},{"name":"Computer Graphics History","slug":"Computer-Graphics-History","permalink":"https://yaelcassini.github.io/tags/Computer-Graphics-History/"},{"name":"Nvidia","slug":"Nvidia","permalink":"https://yaelcassini.github.io/tags/Nvidia/"},{"name":"Spline","slug":"Spline","permalink":"https://yaelcassini.github.io/tags/Spline/"},{"name":"KeyFrame","slug":"KeyFrame","permalink":"https://yaelcassini.github.io/tags/KeyFrame/"},{"name":"Relighting","slug":"Relighting","permalink":"https://yaelcassini.github.io/tags/Relighting/"},{"name":"Anaconda","slug":"Anaconda","permalink":"https://yaelcassini.github.io/tags/Anaconda/"},{"name":"Pytorch","slug":"Pytorch","permalink":"https://yaelcassini.github.io/tags/Pytorch/"},{"name":"Color Space","slug":"Color-Space","permalink":"https://yaelcassini.github.io/tags/Color-Space/"},{"name":"Gamma Correction","slug":"Gamma-Correction","permalink":"https://yaelcassini.github.io/tags/Gamma-Correction/"},{"name":"Tone Mapping","slug":"Tone-Mapping","permalink":"https://yaelcassini.github.io/tags/Tone-Mapping/"},{"name":"Color Gamut","slug":"Color-Gamut","permalink":"https://yaelcassini.github.io/tags/Color-Gamut/"},{"name":"Shadow","slug":"Shadow","permalink":"https://yaelcassini.github.io/tags/Shadow/"},{"name":"Shadow Map","slug":"Shadow-Map","permalink":"https://yaelcassini.github.io/tags/Shadow-Map/"},{"name":"PCF","slug":"PCF","permalink":"https://yaelcassini.github.io/tags/PCF/"},{"name":"PCSS","slug":"PCSS","permalink":"https://yaelcassini.github.io/tags/PCSS/"},{"name":"VSM","slug":"VSM","permalink":"https://yaelcassini.github.io/tags/VSM/"},{"name":"MSM","slug":"MSM","permalink":"https://yaelcassini.github.io/tags/MSM/"},{"name":"RayTracing","slug":"RayTracing","permalink":"https://yaelcassini.github.io/tags/RayTracing/"},{"name":"PathTracing","slug":"PathTracing","permalink":"https://yaelcassini.github.io/tags/PathTracing/"},{"name":"Deep Learing","slug":"Deep-Learing","permalink":"https://yaelcassini.github.io/tags/Deep-Learing/"},{"name":"Artificial Intelligent","slug":"Artificial-Intelligent","permalink":"https://yaelcassini.github.io/tags/Artificial-Intelligent/"},{"name":"Spherical Harmonics","slug":"Spherical-Harmonics","permalink":"https://yaelcassini.github.io/tags/Spherical-Harmonics/"},{"name":"Papers","slug":"Papers","permalink":"https://yaelcassini.github.io/tags/Papers/"},{"name":"ToolBag","slug":"ToolBag","permalink":"https://yaelcassini.github.io/tags/ToolBag/"},{"name":"GAN","slug":"GAN","permalink":"https://yaelcassini.github.io/tags/GAN/"},{"name":"Deep Fake","slug":"Deep-Fake","permalink":"https://yaelcassini.github.io/tags/Deep-Fake/"},{"name":"Subsurface Scattering","slug":"Subsurface-Scattering","permalink":"https://yaelcassini.github.io/tags/Subsurface-Scattering/"}]}